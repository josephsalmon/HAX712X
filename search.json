[
  {
    "objectID": "Bonus/README.html",
    "href": "Bonus/README.html",
    "title": "Bonus",
    "section": "",
    "text": "1 supplementary point on the final grade of the course can be obtained for contributions to improving the course material (practicals, Readme, etc.)."
  },
  {
    "objectID": "Bonus/README.html#bonus-conditions",
    "href": "Bonus/README.html#bonus-conditions",
    "title": "Bonus",
    "section": "Bonus conditions",
    "text": "Bonus conditions\n\nOnly .5 point is given for a contribution,\nOnly the first contribution proposed on a theme is rewarded (no point given for followers!),\nDocumented pull-requests (PR) are expected: details are expected to help to judge what the proposition improves/corrects,\nfor typos. At least 5 corrections are expected to receive .5 points. The corrections should be gathered in a single PR.\nEach student can only get 1 point (maximum) through bonuses."
  },
  {
    "objectID": "Bonus/README.html#pull-request-pr",
    "href": "Bonus/README.html#pull-request-pr",
    "title": "Bonus",
    "section": "Pull Request (PR)",
    "text": "Pull Request (PR)\nThe pull request system is a standard way of proposing improvements and modifications in open-source projects. Here we use it for the opportunity to improve the course material.\nThe principle is the following\n\nFork: Connect to your GitHub account (see Git course for details) and fork the current repository by clicking on the ‚ÄúFork‚Äù icon (note that HMMA238 was the old name of this course): \nGo to your Github account and find the HAX712X repository. In what follows you should substitute my_github_id with your GitHub identification; in the screenshots, the examples are with my_github_id=josephsalmon and they should be adapted according to yours. The URL is https://github.com/my_github_id/HAX712X.\nGet the cloning repository by clicking the ‚Äúclone‚Äù button and choose either the https or ssh protocol (the latter being recommended to avoid typing your password at each git pull/push):  .\nClone the repository on your local machine. On Linux this consists of typing the following line in a terminal:\n\n$ git clone git@github.com:my_github_id/HAX712X.git\n\nAdding a remote: You need to configure a remote that points to the upstream repository. Before you can sync your fork with an upstream repository, you must do this step\n\n$ git remote add upstream https://github.com/josephsalmon/HAX712X.git\n\nYou can check the remote available (yours and the class one) by typing:\n\n$ git remote -v\n\nCreate a new branch for instance called improving_git, and move to it\n\n$ git checkout -b improving_git\n\nMake local edits on some of the files in the project, and then commit and push the new branch improving_git:\n\n$ git commit -am \"I edited some typos\"\n$ git push --set-upstream origin improving_git\n\nCreate Pull Request: Go back in your browser to https://github.com/my_github_id/HAX712X and click on Pull Request.\nTo keep your fork up to date/sync:\n\n$ git fetch upstream\n\nTo come back to the main branch:\n\n$ git checkout main\n\nTo merge the upstream version (the one you see at https://github.com/josephsalmon/HAX712X.git)\n\n$ git pull upstream main"
  },
  {
    "objectID": "Bonus/README.html#additional-material",
    "href": "Bonus/README.html#additional-material",
    "title": "Bonus",
    "section": "Additional material",
    "text": "Additional material\n\nGitHub help for PRs\nwikiHow help for PRs\nGitHub help for syncing a fork"
  },
  {
    "objectID": "Projects/2022-2023/README.html",
    "href": "Projects/2022-2023/README.html",
    "title": "Project guidelines: 2022-2023",
    "section": "",
    "text": "Work in groups of 2, 3 or 4 students, assigned at random (list on the Moodle website)."
  },
  {
    "objectID": "Projects/2022-2023/README.html#intermediate-tasks",
    "href": "Projects/2022-2023/README.html#intermediate-tasks",
    "title": "Project guidelines: 2022-2023",
    "section": "Intermediate tasks",
    "text": "Intermediate tasks\n\ndata cleaning steps: removing missing values if need be."
  },
  {
    "objectID": "Projects/2022-2023/README.html#major-objectives",
    "href": "Projects/2022-2023/README.html#major-objectives",
    "title": "Project guidelines: 2022-2023",
    "section": "Major objectives:",
    "text": "Major objectives:\n\ndisplays interactive maps.\n\nUseful packages (non-exhaustive list): - osmnx - plotly - folium - networkx"
  },
  {
    "objectID": "Projects/2022-2023/README.html#timing",
    "href": "Projects/2022-2023/README.html#timing",
    "title": "Project guidelines: 2022-2023",
    "section": "Timing",
    "text": "Timing\n\nMid-term project snapshot: Due date November 15, 23:59. This will include the creation of a github repository (README.md, etc.), a short description of how the work is shared in the team and a detailed work program for the project including the tasks‚Äô attribution (coding).\nPreliminary presentation: An oral presentation with Beamer (duration: 5mn), in-person on date/place TBC (December 2, 11:30 to 13:00).\nDue date (final project): The github repository should be completed before Tuesday 6 December (23:59). Nothing pushed after the deadline will be taken into account. The oral presentation (max: 20mn) will be in-person Friday 9 December (8:00AM) (room: 36.4)."
  },
  {
    "objectID": "Projects/2022-2023/README.html#elements-expected-grading",
    "href": "Projects/2022-2023/README.html#elements-expected-grading",
    "title": "Project guidelines: 2022-2023",
    "section": "Elements expected / Grading",
    "text": "Elements expected / Grading\n\nSummary\n\n\n\n\n\n\n\n\nGeneral\nDetails\nPoints (out of 20)\n\n\n\n\nMid-term\nGit / branches\n1.5\n\n\n\nTask affectation\n1\n\n\n\nDataset creation\n1\n\n\nPreliminary-term\nBeamer (structure, spelling)\n0.5\n\n\nCode\nScience Technical Problem Resolution\n4.5\n\n\n\nReadme/Comments/Pep8\n1\n\n\n\nUnit Tests/CI/Deploy : wheel\n1\n\n\n\nClass (create at least 1 class)\n0.5\n\n\n\nReproducibility/Dataset loading\n1\n\n\n\nGraphical aspects: Widgets, clickable map, etc.\n2.5\n\n\n\nTime/Memory efficiency\n1\n\n\n\nDocumentation\n1.5\n\n\nOral\nBeamer (structure, spelling)\n1\n\n\n\nClarity / lively presentation / Rhythm / Show\n2\n\n\nTotal\n\n20\n\n\n\n\n\nDetails\n\nThe ultimate goal is to provide a Python module that can be imported with pip and contains your work. A description of the procedure will be needed (imagine you are addressing to a user not aware of your package). An example of a project made in 2020, is available at https://github.com/tanglef/chaoseverywhere.\nYour Python module should have two submodules corresponding to the two main tasks (prediction and visualization)\nThe project must be stored on a github repository.\nYou have to choose a name for your project. Hereafter, it is denoted by my_module_name.\nIt should contain all the aspects described below.\n\n\n\nScience\nSolve (even partially) the problem raised in your project description.\n\n\nProject structure\n\nAll the code will be placed in a subdirectory called /my_module_name (choosing your module name accordingly).\nA presentation (in an open source format: like Beamer, with TeX, see for instance some templates here https://github.com/josephsalmon/OrganizationFiles, or LibreOffice Impress) will be put in a /beamer directory. The later will be a short presentation of the work that will be orally presented during 15mn in front of a jury.\nA documentation (using sphinx) will be stored in a /doc subdirectory.\n\n\n\nGit aspects\n\nA (markdown) readme.md file introducing your work and the team member (first/last name + email).\nA .gitignore that prevents garbage files to be included in your project.\nEquilibrated commits in two branches should be done (e.g., in the development branch and the master one), and merged for the milestone day.\n\n\n\nObject programming aspects\n\nYou should code at least one Python class.\n\n\n\nDataset(s)\n\nThe data used should be available in a way that the end user does not need to perform a manual download of any kind (use the download package or variants for instance).\n\n\n\nGraphical aspects\nThe repository will contain code of the following nature:\n\nA code producing a (possibly interactive) map.\nhistograms/kde/swarmplots/etc. plots illustrating the data.\n\n\n\nTime/memory evaluation\n\nA full study of the time and memory footprint of the code produced will be provided for the whole pipeline used.\n\n\n\nDocumentation\n\nDocumentation should be added correctly for the functions written. Please use sphinx.\n\n\n\nTest and CI\n\nProvide unitary tests to check that the function you proposed satisfies the requirement you target.\nImplement a Continuous Integration solution with github that runs your unitary test at each commit.\n\n\n\nDeploy\n\nIt should be possible to package your Python module using wheel (i.e., you need to provide a setup.py, file)."
  },
  {
    "objectID": "Projects/README.html",
    "href": "Projects/README.html",
    "title": "Project guidelines",
    "section": "",
    "text": "Project guidelines\nThis section describes the project guidelines. The teams are made of 3 or 4 students, assigned at random; team compositions are available on Moodle for the group projects.\n\nDescription for each year is available here:\n\n2023-2024\n2022-2023\n2021-2022\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "Courses/Venv/tp.html",
    "href": "Courses/Venv/tp.html",
    "title": "Virtual Python Environment",
    "section": "",
    "text": "A venv is an isolated standalone python distribution with a specific version of modules. This is useful when one needs to run different python versions in a single system. Various commands can create a venv: venv, virtualenv, conda‚Ä¶ We are going to use Anaconda to set up various python virtual environments on our system.\nReferences: - Virtualenv - Python documentation on venv"
  },
  {
    "objectID": "Courses/Venv/tp.html#preamble",
    "href": "Courses/Venv/tp.html#preamble",
    "title": "Virtual Python Environment",
    "section": "",
    "text": "A venv is an isolated standalone python distribution with a specific version of modules. This is useful when one needs to run different python versions in a single system. Various commands can create a venv: venv, virtualenv, conda‚Ä¶ We are going to use Anaconda to set up various python virtual environments on our system.\nReferences: - Virtualenv - Python documentation on venv"
  },
  {
    "objectID": "Courses/Venv/tp.html#python-package-system",
    "href": "Courses/Venv/tp.html#python-package-system",
    "title": "Virtual Python Environment",
    "section": "Python package system",
    "text": "Python package system\nThe Python Package Index (PyPI) is a repository of software for the python programming language. PyPI helps you find and install software developed and shared by the python community.\nThe pip program allows you to install most standard packages:\n$ pip --version\n$ pip install numpy\nReferences: - Pypi - Installing Packages\n\n\n\n\n\n\nEXERCISE:\n\n\n\n\nDetermine which python version there is on your system using locate and which\nDetermine which version of python is used by the pip command\nList all the python modules installed with the pip command"
  },
  {
    "objectID": "Courses/Venv/tp.html#anaconda",
    "href": "Courses/Venv/tp.html#anaconda",
    "title": "Virtual Python Environment",
    "section": "Anaconda",
    "text": "Anaconda\nAnaconda is a package manager, an environment manager coming with a python/R data science distribution, and a large collection of open-source packages. It is cross-platform and is a very popular choice in the data scientist community. Nevertheless, it suffers from a main drawback: it is heavy. Moreover, it comes with its own package manager conda which allows you to install a python module (like pip) and other programs.\nOn the Linux box provided by the FdS, there is a terminal with the $PATH environment variable already configured (/net/apps/bin/init_anaconda3). You may launch it via the Graphical User Interface.\nYou can see also the mamba project https://github.com/mamba-org/mamba.\n\n\n\n\n\n\nEXERCISE:\n\n\n\n\nDisplay the $PATH variable in the Anaconda_init terminal\nType conda deactivate and (re)-display the $PATH variable\n\n\n\n\nCreating an environment\nUse the terminal or an Anaconda Prompt for the following steps:\n\nTo create an environment:\n$ conda create --name myenv\nReplace myenv with the environment name.\nWhen conda asks you to proceed, type y:\n  proceed ([y]/n)?\nBy default, environments are installed into the envs sub-directory in your conda directory. See conda create --help for information on specifying a different path. This creates the myenv environment in envs/. This environment uses the same version of python that you are currently using because you did not specify a version.\nTo create an environment with a specific version of python:\n$ conda create -n myenv python=3.9\nTo create an environment with a specific package:\n$ conda create -n myenv scipy\nor:\n$ conda create -n myenv python\n$ conda install -n myenv scipy\nTo create an environment with a specific version of a package:\n$ conda create -n myenv scipy=0.15.0\nor\n$ conda create -n myenv python\n$ conda install -n myenv scipy=0.15.0\nTo create an environment with a specific version of python and multiple packages:\n$ conda create -n myenv python=3.6 scipy=0.15.0 astroid babel\n\nSee: https://docs.conda.io/projects/conda/en/latest/user-guide/tasks/manage-environments.html#creating-an-environment-with-commands\n\n\n\n\n\n\nEXERCISE:\n\n\n\n\nCreate a new environment called toto with python3.5 and pandas version 0.23\nCreate another environment called tata with python3.7 and pandas version 1.0\n\n\n\n\n\nSwitch environment\nTo switch to an environment, it must be ‚Äúactivated‚Äù (in git we would have said ‚Äúto checkout‚Äù). Activation entails two primary functions: adding entries to PATH for the environment and running any activation scripts that the environment may contain. These activation scripts are how packages can set arbitrary environment variables that may be necessary for their operation. You can also use the config API to set environment variables. To activate an environment:\n$ conda activate myenv\nChange myenv with the name of your environment.\nSee: https://docs.conda.io/projects/conda/en/latest/user-guide/tasks/manage-environments.html#activating-an-environment\n\n\n\n\n\n\nEXERCISE:\n\n\n\n\nActivate the toto environment. Launch python and check the version of pandas\nActivate the tata environment. Launch python and check the version of pandas\nList all the available environments (look in the documentation by yourself)\nCome back to the base environment\n\n\n\n\n\nSave and export an environment\nReferences: Building identical conda environments\n\n\n\n\n\n\nEXERCISE:\n\n\n\nImagine that you are coding a python module and some users are not able to run your code due to some missing dependencies. How can you help them to set up the python venv?\n\n\n\n\nRemoving an environment and cleaning\nAnaconda is particularly greedy in terms of disk usage. It can be a good practice to remove an unused environment\n$ conda env remove -n myenv\nTo remove all cache and package run\n$ conda clean --all\n\n\n\n\n\n\nEXERCISE:\n\n\n\n\nRemove all the environments created during this session\nCreate an environment called hax712_env with matplotlib (this venv will be used in the next courses)\nClean the conda caches to free disk space."
  },
  {
    "objectID": "Courses/Test/tp.html",
    "href": "Courses/Test/tp.html",
    "title": "Unit Tests",
    "section": "",
    "text": "This lecture is adapted from"
  },
  {
    "objectID": "Courses/Test/tp.html#tests",
    "href": "Courses/Test/tp.html#tests",
    "title": "Unit Tests",
    "section": "Tests",
    "text": "Tests\nTests are small pieces of code ensuring that a part of a program is working as expected.\n\nWhy tests are useful\nThis is why we place the uttermost importance on implementing tests along the development steps. It will help you to ensure:\n\nthat code works correctly.\nthat changes do not break anything.\nthat bugs are not reintroduced.\nrobustness to user errors.\ncode is reachable (i.e., it will actually be executed)\n\n\n\nTypes of tests\nThere are different kinds of tests:\n\nUnit tests: They test whether a function does the right thing.\nIntegration tests: They test whether the system/process does the right thing.\nNon-regression tests: They test whether a bug got removed (and will not be reintroduced).\n\n\n\nHow to test?\nMany coding languages come with their own test framework. In python, we will focus on pytest. It is simple though powerful. pytest searches for all test*.py files and runs all test* methods found. It outputs a nice error report.\n\n\n\n\n\n\nEXERCISE: pytest\n\n\n\n\nInstall pytest with pip using the user scheme (--user option)\nTest if the command pytest is in your PATH (depending on your configuration you will have to add ~/.local/bin in PATH)\n\n\n\nGet the path to pytest binary\n&gt;&gt;&gt; import pytest\n&gt;&gt;&gt; pytest.__path__\n/path/to/pytest\nthen, in a terminal\n$ export PATH=$PATH:/path/to/pytest\n$ pytest --help\n\n\nExample\nLet us assume we have a file inc.py containing\ndef inc1(x):\n    return x + 1\n\ndef inc2(x):\n    return x + 2\nThence, the content of test_inc.py is\nfrom inc import inc1, inc2\n\n# This test will work\ndef test_inc1():\n    assert inc1(3) == 4\n\n# This test will fail\ndef test_inc2():\n    assert inc2(-1) == 4\nTo run these tests:\n$ pytest test_inc.py\n\n\n\n\n\n\nEXERCISE: documentation\n\n\n\n\nCorrect the test_inc2 test.\nDetermine the syntax to run any test in a directory.\nDetermine the syntax to run only the test called test_inc1."
  },
  {
    "objectID": "Courses/Test/tp.html#code-coverage",
    "href": "Courses/Test/tp.html#code-coverage",
    "title": "Unit Tests",
    "section": "Code coverage",
    "text": "Code coverage\npytest comes with some useful plugins. In particular, we will use the coverage report plugin.\nA test coverage is a measure used to describe the degree to which the source code of a program is executed when a particular test suite runs. A program with high test coverage, measured as a percentage, has had more of its source code executed during testing: this suggests it has a lower chance of containing undetected software bugs compared to a program with low test coverage.\nTo install the coverage plugin simply run\n$ pip install pytest-cov\nAssuming the inc_cov.py contains:\ndef inc(x):\n    if x &lt; 0:\n        return 0\n    return x + 1\n\ndef dec(x):\n     return x - 1\nand a single test is performed through the file test_inc_cov.py\nfrom inc_cov import inc\n\ndef test_inc():\n     assert inc(3) == 4\nthen\npytest test_inc_cov.py --cov\n============================= test session starts ==============================\nplatform linux -- Python 3.8.5, pytest-6.2.5, py-1.9.0, pluggy-0.13.1\nrootdir: /home/jsalmon/Documents/Mes_cours/Montpellier/HAX712X/Courses/Test\nplugins: tornasync-0.6.0.post2, cov-3.0.0, jupyter-server-1.0.9\ncollected 0 items\n\n\n----------- coverage: platform linux, python 3.8.5-final-0 -----------\nName         Stmts   Miss  Cover\n--------------------------------\ninc_cov.py       6      4    33%\n--------------------------------\nTOTAL            6      4    33%\n\n============================ no tests ran in 0.02s =============================\nTwo lines in inc_cov module were not used. See\npytest --cov --cov-report=html test_inc_cov.py\n\n============================= test session starts ==============================\nplatform linux -- Python 3.8.5, pytest-6.2.5, py-1.9.0, pluggy-0.13.1\nrootdir: /home/jsalmon/Documents/Mes_cours/Montpellier/HAX712X/Courses/Test\nplugins: tornasync-0.6.0.post2, cov-3.0.0, jupyter-server-1.0.9\ncollected 0 items\n\n\n----------- coverage: platform linux, python 3.8.5-final-0 -----------\nCoverage HTML written to dir htmlcov\nfor details.\nReferences:\n\nThe pytest documentation\nWikipedia: Code coverage\n\n\n\n\n\n\n\nEXERCISE:\n\n\n\n\nInstall the pytest‚Äôs coverage plugin.\nLoad the biketrauma package you can download at https://github.com/HMMA238-2020/biketrauma/\nAdd some unit tests to biketrauma in a new sub-directory ./biketrauma/tests/:\n\nCreate a first test_df() that test if the C√¥tes-d‚Äôor d√©partement has 459 accidents. Add a second test_df_log()¬†testing that the log of the number of accidents in the d√©partement 92 is close to 7.651120176.\nCreate a test_dl() function that tests the md5sum hash of the downloaded file (a.k.a. bicycle_db.csv). You may use the pooch package or you can use this piece of code to compute the md5sum:\n\n\n\n\nimport hashlib\ndef md5(fname):\n    hash_md5 = hashlib.md5()\n    with open(fname, \"rb\") as f:\n        for chunk in iter(lambda: f.read(4096), b\"\"):\n            hash_md5.update(chunk)\n    return hash_md5.hexdigest()\nYou should achieve a 92% of code coverage:\n----------- coverage: platform linux, python 3.7.6-final-0 -----------\nName                                    Stmts   Miss  Cover\n-----------------------------------------------------------\nbiketrauma/__init__.py                      4      0   100%\nbiketrauma/io/Load_db.py                    9      0   100%\nbiketrauma/io/__init__.py                   3      0   100%\nbiketrauma/preprocess/__init__.py           0      0   100%\nbiketrauma/preprocess/get_accident.py       9      0   100%\nbiketrauma/tests/test_biketrauma.py        21      0   100%\nbiketrauma/vis/__init__.py                  0      0   100%\nbiketrauma/vis/plot_location.py             6      4    33%\n-----------------------------------------------------------\nTOTAL                                      52      4    92%"
  },
  {
    "objectID": "Courses/ScipyNumpy/tp.html",
    "href": "Courses/ScipyNumpy/tp.html",
    "title": "SciPy",
    "section": "",
    "text": "Adapted from the notebooks by"
  },
  {
    "objectID": "Courses/ScipyNumpy/tp.html#introduction",
    "href": "Courses/ScipyNumpy/tp.html#introduction",
    "title": "SciPy",
    "section": "Introduction",
    "text": "Introduction\nSciPy is a scientific library that builds upon NumPy. Among others, SciPy deals with:\n\nIntegration (scipy.integrate)\nOptimization (scipy.optimize)\nInterpolation (scipy.interpolate)\nFourier Transform (scipy.fftpack)\nSignal Processing (scipy.signal)\nLinear Algebra (scipy.linalg)\nSparse matrices (scipy.sparse)\nStatistics (scipy.stats)\nImage processing (scipy.ndimage)\nIO (input/output) (scipy.io)\n\n\n%matplotlib inline\nfrom scipy import linalg\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib.animation import FuncAnimation\nfrom IPython.display import HTML, display"
  },
  {
    "objectID": "Courses/ScipyNumpy/tp.html#animation-display-with-python",
    "href": "Courses/ScipyNumpy/tp.html#animation-display-with-python",
    "title": "SciPy",
    "section": "Animation display with python",
    "text": "Animation display with python\n\nAnimation with matplotlib\nYou can use FuncAnimation to animate a sequence of images:\n\n%%capture\nfig, ax = plt.subplots()\nxdata, ydata = [], []\n(ln,) = plt.plot([], [], \"ro\")\n\n\ndef init():\n    ax.set_xlim(0, 2 * np.pi)\n    ax.set_ylim(-1, 1)\n    return (ln,)\n\n\ndef update(frame):\n    xdata.append(frame)\n    ydata.append(np.sin(frame))\n    ln.set_data(xdata, ydata)\n    return (ln,)\n\nani = FuncAnimation(\n    fig,\n    update,\n    interval=50,\n    frames=np.linspace(0, 2 * np.pi, 100),\n    init_func=init,\n    blit=True,\n)\n\n\ndisplay(HTML(ani.to_jshtml()))\n\n\n\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n\n\nAnother way of displaying video exists, using html5 video:\n\ndisplay(HTML(ani.to_html5_video()))\n\nReferences:\n\nMatplotlib Animations / JavaScript Widgets by Louis Tiao"
  },
  {
    "objectID": "Courses/ScipyNumpy/tp.html#animation-with-plotly",
    "href": "Courses/ScipyNumpy/tp.html#animation-with-plotly",
    "title": "SciPy",
    "section": "Animation with plotly",
    "text": "Animation with plotly\nmatplotlib works fine for advanced tuning, but is harder for simple tasks. So just try plotly for basic animations:\n\nimport plotly.express as px\nfrom plotly.offline import plot\n\ndf = px.data.gapminder()\nfig = px.scatter(\n    df,\n    x=\"gdpPercap\",\n    y=\"lifeExp\",\n    animation_frame=\"year\",\n    animation_group=\"country\",\n    size=\"pop\",\n    color=\"continent\",\n    hover_name=\"country\",\n    log_x=True,\n    size_max=55,\n    range_x=[100, 100000],\n    range_y=[25, 90],\n)\nfig.show(\"notebook\")"
  },
  {
    "objectID": "Courses/ScipyNumpy/tp.html#linear-algebra",
    "href": "Courses/ScipyNumpy/tp.html#linear-algebra",
    "title": "SciPy",
    "section": "Linear algebra",
    "text": "Linear algebra\nscipy for linear algebra : use linalg. It includes functions for solving linear systems, eigenvalues decomposition, SVD, Gaussian elimination (LU, Cholesky), etc.\nReferences:\n\nScipy documentation\n\n\nSolving linear systems:\nFind x such that: A x = b for specified matrix A and vector b.\n\nA = np.array([[1, 0, 3], [4, 5, 12], [7, 8, 9]], dtype=float)\nb = np.array([[1, 2, 3]], dtype=np.float64).T\n\nprint(A, b)\n\nx = linalg.solve(A, b)\nprint(x, x.shape, b.shape)\n\n[[ 1.  0.  3.]\n [ 4.  5. 12.]\n [ 7.  8.  9.]] [[1.]\n [2.]\n [3.]]\n[[ 0.8       ]\n [-0.4       ]\n [ 0.06666667]] (3, 1) (3, 1)\n\n\nCheck the result at a given precision (different from ==)\n\nnp.allclose(A @ x, b, atol=1e-14, rtol=1e-15)\n\nTrue\n\n\nRemark: NEVER (or you should really know why) invert a matrix. ALWAYS solve linear systems instead!\n\nEigenvalues/ Eigenvectors\nA v_n = \\lambda_n v_n with v_n the n-th eigen vector and \\lambda_n the n-th eigen value. The associated python functions are eigvals and eig:\n\nA = np.random.randn(3, 3)\nA = A + A.T\nevals, evecs = linalg.eig(A)\nprint(evals, \"\\n ------\\n\", evecs)\n\nnp.allclose(A, evecs @ np.diag(evals) @ evecs.T)\n\n[ 4.21735168+0.j -2.08629611+0.j -3.32796029+0.j] \n ------\n [[-0.87224733 -0.3616251  -0.3292596 ]\n [ 0.04178394 -0.72588427  0.68654653]\n [ 0.48727682 -0.58508061 -0.64826073]]\n\n\nTrue\n\n\n\n\n\n\n\n\nEXERCISE: Eigenvalues/Eigenvectors\n\n\n\nVerify numerically that the outputs from linalg.eig are indeed approximately eigenvalues and eigenvectors of matrix A above.\nHint: use Scipy documentation on allclose\n\n\n\n\nSymmetric matrices\nIf A is symmetric you should use eigvalsh (H for Hermitian) instead: This is more robust and leverages the structures (you know they are real!)\n\n\n\nMatrix operations\n\nlinalg.trace(A) # trace\nlinalg.det(A) # determinant\nlinalg.inv(A) # Inverse, consider NEVER using it though :)\n\n\n\nNorms\n\nprint(linalg.norm(A, ord=\"fro\"))  # fro for Frobenius\nprint((np.sum(A ** 2)) ** 0.5)\nprint(linalg.norm(A, ord=2))\nprint((linalg.eigvalsh(A.T @ A) ** 0.5))\nprint(linalg.norm(A, ord=np.inf))\n\n5.763159405524464\n5.763159405524464\n4.217351678810542\n[2.08629611 3.32796029 4.21735168]\n5.570185408013179\n\n\n\n\n\n\n\n\nEXERCISE: Norms computation\n\n\n\nCheck numerically what the instruction linalg.norm(A, ord=np.inf) is computing. Double check with the help and a numerical test.\n\n\n\nA = np.random.randn(3, 3)\nprint(linalg.norm(A, ord=np.inf))\n\n2.5882016210892678"
  },
  {
    "objectID": "Courses/ScipyNumpy/tp.html#random-generation-distributions-etc.",
    "href": "Courses/ScipyNumpy/tp.html#random-generation-distributions-etc.",
    "title": "SciPy",
    "section": "Random generation, distributions, etc.",
    "text": "Random generation, distributions, etc.\nReferences:\n\nGood practices with numpy random number generators by Albert Thomas\nNumpy documentation on RandomState\nRandom Widgets, by Joseph Salmon: Visualization of various popular distributions.\n\n\nseed = 12345\nrng = np.random.default_rng(seed)  # can be called without a seed\nrng.random()\n\n0.22733602246716966"
  },
  {
    "objectID": "Courses/ScipyNumpy/tp.html#optimization",
    "href": "Courses/ScipyNumpy/tp.html#optimization",
    "title": "SciPy",
    "section": "Optimization",
    "text": "Optimization\nGoal: find functions minima or maxima\nReferences:\n\nScipy Lectures on mathematical optimization.\n\n\nfrom scipy import optimize\n\n\nFinding (local!) minima\n\ndef f(x):\n    return 4 * x ** 3 + (x - 2) ** 2 + x ** 4\n\n\ndef mf(x):\n    return -(4 * x ** 3 + (x - 2) ** 2 + x ** 4)\n\n\nxs = np.linspace(-5, 3, 100)\nplt.figure()\nplt.plot(xs, f(xs))\nplt.show()\n\n\n\n\n\n\n\n\nDefault solver for minimization/maximization: fmin_bfgs (see Wikipedia on BFGS)\n\nx_min = optimize.fmin_bfgs(f, x0=-4)\nx_max = optimize.fmin_bfgs(mf, x0=-2)\nx_min2 = optimize.fmin_bfgs(f, x0=2)\n\n\nplt.figure()\nplt.plot(xs, f(xs))\nplt.plot(x_min, f(x_min), \"o\", markersize=10, color=\"orange\")\nplt.plot(x_min2, f(x_min2), \"o\", markersize=10, color=\"red\")\nplt.plot(x_max, f(x_max), \"|\", markersize=20)\nplt.show()\n\n\n\nOptimization terminated successfully.\n         Current function value: -3.506641\n         Iterations: 7\n         Function evaluations: 16\n         Gradient evaluations: 8\nOptimization terminated successfully.\n         Current function value: -6.201654\n         Iterations: 5\n         Function evaluations: 12\n         Gradient evaluations: 6\nOptimization terminated successfully.\n         Current function value: 2.804988\n         Iterations: 7\n         Function evaluations: 16\n         Gradient evaluations: 8\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEXERCISE: Basin of attraction\n\n\n\nDraw the points on the curves with two different colors :\n\norange: for the points leading to find the left local minima\nred: for the points leading to the right local minima.\n\n\n\n\n\nFind the zeros of a function\nFind x such that f(x) = 0, with fsolve.\n\nomega_c = 3.0\n\ndef f(omega):\n    return np.tan(2 * np.pi * omega) - omega_c / omega\n\n\nx = np.linspace(1e-8, 3.2, 1000)\ny = f(x)\n\n# Remove vertical lines when the function flips signs\nmask = np.where(np.abs(y) &gt; 50)\nx[mask] = y[mask] = np.nan\nplt.plot(x, y)\nplt.plot([0, 3.3], [0, 0], \"k\")\nplt.ylim(-5, 5)\n\noptimize.fsolve(f, 0.72)\noptimize.fsolve(f, 1.1)\noptimize.fsolve(f, np.linspace(0.001, 3, 20))\nnp.unique(np.round(optimize.fsolve(f, np.linspace(0.2, 3, 20)), 3))\n\nmy_zeros = (\n    np.unique((optimize.fsolve(f, np.linspace(0.2, 3, 20)) * 1000).astype(int)) / 1000.0\n)\nplt.figure()\nplt.plot(x, y, label=\"$f$\")\nplt.plot([0, 3.3], [0, 0], \"k\")\nplt.plot(my_zeros, np.zeros(my_zeros.shape), \"o\", label=\"$x : f(x)=0$\")\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameters estimation\n\nfrom scipy.optimize import curve_fit\n\n\ndef f(x, a, b, c):\n    \"\"\"f(x) = a exp(-bx) + c.\"\"\"\n    return a * np.exp(-b * x) + c\n\n\nx = np.linspace(0, 4, 50)\ny = f(x, 2.5, 1.3, 0.5)  # true signal\nyn = y + 0.2 * np.random.randn(len(x))  # noisy added\n\nplt.figure()\nplt.plot(x, yn, \".\")\nplt.plot(x, y, \"k\", label=\"$f$\")\nplt.legend()\nplt.show()\n\n(a, b, c), _ = curve_fit(f, x, yn)\nprint(a,\"\\n\", b,\"\\n\", c)\n\n\n\n\n\n\n\n\n2.552374008863647 \n 1.1513774889248538 \n 0.46011199628910815\n\n\n\n\nDisplaying\n\nplt.figure()\nplt.plot(x, yn, \".\", label=\"data\")\nplt.plot(x, y, \"k\", label=\"True $f$\")\nplt.plot(x, f(x, a, b, c), \"--k\", label=\"Estimated $\\hat{f}$\")\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\nFor polynomial fitting, one can directly use numpy functionsL\n\nx = np.linspace(0, 1, 10)\ny = np.sin(x * np.pi / 2.0)\nline = np.polyfit(x, y, deg=10)\nplt.figure()\nplt.plot(x, y, \".\", label=\"data\")\nplt.plot(x, np.polyval(line, x), \"k--\", label=\"polynomial approximation\")\nplt.legend()\nplt.show()\n\n/home/jsalmon/anaconda3/envs/peerannot/lib/python3.10/site-packages/IPython/core/interactiveshell.py:3505: RankWarning:\n\nPolyfit may be poorly conditioned"
  },
  {
    "objectID": "Courses/ScipyNumpy/tp.html#interpolation",
    "href": "Courses/ScipyNumpy/tp.html#interpolation",
    "title": "SciPy",
    "section": "Interpolation",
    "text": "Interpolation\n\nfrom scipy.interpolate import interp1d, CubicSpline\n\n\ndef f(x):\n    return np.sin(x)\n\n\nn = np.arange(0, 10)\nx = np.linspace(0, 9, 100)\n\ny_meas = f(n) + 0.1 * np.random.randn(len(n))  # add noise\ny_real = f(x)\n\nlinear_interpolation = interp1d(n, y_meas)\ny_interp1 = linear_interpolation(x)\n\ncubic_interpolation = CubicSpline(n, y_meas)\ny_interp2 = cubic_interpolation(x)\n\n\nplt.figure()\nplt.plot(n, y_meas, \"bs\", label=\"noisy data\")\nplt.plot(x, y_real, \"k\", lw=2, label=\"true function\")\nplt.plot(x, y_interp1, \"r\", label=\"linear interp\")\nplt.plot(x, y_interp2, \"g\", label=\"CubicSpline interp\")\nplt.legend(loc=3)\nplt.show()"
  },
  {
    "objectID": "Courses/ScipyNumpy/tp.html#images",
    "href": "Courses/ScipyNumpy/tp.html#images",
    "title": "SciPy",
    "section": "Images",
    "text": "Images\n\nfrom scipy import ndimage, datasets\n\nimg = datasets.face()\ntype(img), img.dtype, img.ndim, img.shape\n\n\nprint(2 ** 8)  # uint8-&gt; code sur 256 niveau.\n\nn_1, n_2, n_3 = img.shape\nnp.unique(img)\n\n\n# True image\nplt.figure()\nplt.imshow(img)\nplt.axis(\"off\")\nplt.show()\n\n\n\n256\n\n\n\n\n\n\n\n\n\n\nRGB decomposition\n\nfig, ax = plt.subplots(3, 2)\nfig.set_size_inches(7, 4.5)\nn_1, n_2, n_3 = img.shape\n\nax[0, 0].imshow(img[:, :, 0], cmap=plt.cm.Reds)\nax[0, 1].hist(img[:, :, 0].reshape(n_1 * n_2), np.arange(0, 256))\n\nax[1, 0].imshow(img[:, :, 1], cmap=plt.cm.Greens)\nax[1, 1].hist(img[:, :, 1].reshape(n_1 * n_2), np.arange(0, 256))\n\nax[2, 0].imshow(img[:, :, 2], cmap=plt.cm.Blues)\nax[2, 1].hist(img[:, :, 2].reshape(n_1 * n_2), np.arange(0, 256))\n\nplt.tight_layout()\n\n\n\n\n\n\n\n\n\nprint(img.flags)  # cannot edit...\nimg_compressed = img.copy()\nimg_compressed.setflags(write=1)\nprint(img_compressed.flags)  # can edit now\n\n\nimg_compressed[img_compressed &lt; 70] = 50\nimg_compressed[(img_compressed &gt;= 70) & (img_compressed &lt; 110)] = 100\nimg_compressed[(img_compressed &gt;= 110) & (img_compressed &lt; 180)] = 150\nimg_compressed[(img_compressed &gt;= 180)] = 200\nplt.figure()\nplt.imshow(img_compressed, cmap=plt.cm.gray)\nplt.axis(\"off\")\nplt.show()\n\n\n\n  C_CONTIGUOUS : True\n  F_CONTIGUOUS : False\n  OWNDATA : False\n  WRITEABLE : False\n  ALIGNED : True\n  WRITEBACKIFCOPY : False\n\n  C_CONTIGUOUS : True\n  F_CONTIGUOUS : False\n  OWNDATA : True\n  WRITEABLE : True\n  ALIGNED : True\n  WRITEBACKIFCOPY : False\n\n\n\n\n\n\n\n\n\n\n\n\nConvert a color image in grayscale\n\nplt.figure()\nplt.imshow(np.mean(img, axis=2), cmap=plt.cm.gray)\nplt.show()\n\n\n\n\n\n\n\n\n\n\nBlurring (üá´üá∑: floutage)\nimg_flou = ndimage.gaussian_filter(img, sigma=20)\nfix, ax = plt.subplots()\nax.imshow(img_flou, cmap=plt.cm.gray)\nax.axis(\"off\")\nplt.show()\nWidget on blurring bandwidth (cannot be rendered online for the moment, only locally)\n#| eval: false\n%matplotlib widget\nimport ipywidgets as widgets\n\n# set up plot\nimg_flou = ndimage.gaussian_filter(img, sigma=20)\nfix, ax = plt.subplots()\nax.axis(\"off\")\nplt.show()\n\n@widgets.interact(sigma=(0.1, 200, 0.1))\ndef update(sigma=2):\n    \"\"\"Remove old lines from plots and plot new ones.\"\"\"\n    # [l.remove() for l in ax.lines]\n    img_flou = ndimage.gaussian_filter(img, sigma)\n    ax.imshow(img_flou, cmap=plt.cm.gray)\n\n\nChanging colors in an image\n\nimport pooch\nimport os\n\nurl = \"https://upload.wikimedia.org/wikipedia/en/thumb/0/05/Flag_of_Brazil.svg/486px-Flag_of_Brazil.svg.png\"\nname_img =pooch.retrieve(url, known_hash=None)\n\nimg = (255 * plt.imread(name_img)).astype(int)\nimg = img.copy()\nplt.figure()\nplt.imshow(img[:, :, 2], cmap=plt.cm.gray)\n\n\nfig, ax = plt.subplots(3, 2)\nfig.set_size_inches(7, 4.5)\nn_1, n_2, n_3 = img.shape\n\nax[0, 0].imshow(img[:, :, 0], cmap=plt.cm.Reds)\nax[0, 1].hist(img[:, :, 0].reshape(n_1 * n_2), np.arange(0, 256), density=True)\n\nax[1, 0].imshow(img[:, :, 1], cmap=plt.cm.Greens)\nax[1, 1].hist(img[:, :, 1].reshape(n_1 * n_2), np.arange(0, 256), density=True)\n\nax[2, 0].imshow(img[:, :, 2], cmap=plt.cm.Blues)\nax[2, 1].hist(img[:, :, 2].reshape(n_1 * n_2), np.arange(0, 256), density=True)\n\nplt.tight_layout()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEXERCISE: Make the Brazilian italianer\n\n\n\nCreate a version of the Brazilian flag as follows:\n\n\n\n\n\n\n\n\n\nReferences:\n\nIntroduction to geopandas\nCourse on images/slides by Joseph Salmon\nOfficial SciPy web page\nSciPy User Guide\nScipy lectures\nThe SciPy source code"
  },
  {
    "objectID": "Courses/Pandas/tp.html",
    "href": "Courses/Pandas/tp.html",
    "title": "Pandas",
    "section": "",
    "text": "This lecture is extracted and adapted from the Pandas tutorial by Joris Van den Bossche.\nFor R users, you might also want to read Pandas: Comparison with R / R libraries for a smooth start in Pandas.\n%matplotlib inline\nimport os\nimport numpy as np\nimport calendar\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pooch  # download data / avoid re-downloading\nfrom IPython import get_ipython\n\n\nsns.set_palette(\"colorblind\")\npd.options.display.max_rows = 8"
  },
  {
    "objectID": "Courses/Pandas/tp.html#dataset-1-titanic-dataset",
    "href": "Courses/Pandas/tp.html#dataset-1-titanic-dataset",
    "title": "Pandas",
    "section": "Dataset 1: Titanic dataset",
    "text": "Dataset 1: Titanic dataset\nFirst, it is important to download automatically remote files for reproducibility (and avoid typing names manually)\n\nurl = \"http://josephsalmon.eu/enseignement/datasets/titanic.csv\"\npath_target = \"./titanic.csv\"\npath, fname = os.path.split(path_target)\npooch.retrieve(url, path=path, fname=fname, known_hash=None)  # if needed `pip install pooch`\n\n'/home/jsalmon/Documents/Mes_cours/Montpellier/HAX712X/Courses/Pandas/titanic.csv'\n\n\nReading the file as a pandas dataframe:\n\ndf_titanic_raw = pd.read_csv(\"titanic.csv\")\n\nVisualize the end of the dataset:\n\ndf_titanic_raw.tail(n=3)\n\n\n\n\n\n\n\n\nPassengerId\nSurvived\nPclass\nName\nSex\nAge\nSibSp\nParch\nTicket\nFare\nCabin\nEmbarked\n\n\n\n\n888\n889\n0\n3\nJohnston, Miss. Catherine Helen \"Carrie\"\nfemale\nNaN\n1\n2\nW./C. 6607\n23.45\nNaN\nS\n\n\n889\n890\n1\n1\nBehr, Mr. Karl Howell\nmale\n26.0\n0\n0\n111369\n30.00\nC148\nC\n\n\n890\n891\n0\n3\nDooley, Mr. Patrick\nmale\n32.0\n0\n0\n370376\n7.75\nNaN\nQ\n\n\n\n\n\n\n\nVisualize the beginning of the dataset:\n\ndf_titanic_raw.head(n=5)\n\n\n\n\n\n\n\n\nPassengerId\nSurvived\nPclass\nName\nSex\nAge\nSibSp\nParch\nTicket\nFare\nCabin\nEmbarked\n\n\n\n\n0\n1\n0\n3\nBraund, Mr. Owen Harris\nmale\n22.0\n1\n0\nA/5 21171\n7.2500\nNaN\nS\n\n\n1\n2\n1\n1\nCumings, Mrs. John Bradley (Florence Briggs Th...\nfemale\n38.0\n1\n0\nPC 17599\n71.2833\nC85\nC\n\n\n2\n3\n1\n3\nHeikkinen, Miss. Laina\nfemale\n26.0\n0\n0\nSTON/O2. 3101282\n7.9250\nNaN\nS\n\n\n3\n4\n1\n1\nFutrelle, Mrs. Jacques Heath (Lily May Peel)\nfemale\n35.0\n1\n0\n113803\n53.1000\nC123\nS\n\n\n4\n5\n0\n3\nAllen, Mr. William Henry\nmale\n35.0\n0\n0\n373450\n8.0500\nNaN\nS\n\n\n\n\n\n\n\n\nMissing values\nIt is common to encounter features/covariates with missing values. In pandas they were mostly handled as np.nan (not a number). In the future, they will be treated as NA (Not Available), in a similar way as in R; see the Pandas documentation on missing data for standard behavior and details.\nNote that the main difference between pd.NA and np.nan is that pd.NA propagates even for comparisons:\n\npd.NA == 1\n\n&lt;NA&gt;\n\n\nwhereas\n\nnp.nan == 1\n\nFalse\n\n\nTesting the presence of missing values\n\npd.isna(pd.NA)\npd.isna(np.nan)\n\nTrue\n\n\nThe simplest strategy (when you can / when you have enough samples) consists of removing all nans/NAs.\n\ndf_titanic = df_titanic_raw.dropna()\ndf_titanic.tail(3)\n\n\n\n\n\n\n\n\nPassengerId\nSurvived\nPclass\nName\nSex\nAge\nSibSp\nParch\nTicket\nFare\nCabin\nEmbarked\n\n\n\n\n879\n880\n1\n1\nPotter, Mrs. Thomas Jr (Lily Alexenia Wilson)\nfemale\n56.0\n0\n1\n11767\n83.1583\nC50\nC\n\n\n887\n888\n1\n1\nGraham, Miss. Margaret Edith\nfemale\n19.0\n0\n0\n112053\n30.0000\nB42\nS\n\n\n889\n890\n1\n1\nBehr, Mr. Karl Howell\nmale\n26.0\n0\n0\n111369\n30.0000\nC148\nC\n\n\n\n\n\n\n\n\n# Useful info on the dataset (especially missing values!)\ndf_titanic.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nIndex: 183 entries, 1 to 889\nData columns (total 12 columns):\n #   Column       Non-Null Count  Dtype  \n---  ------       --------------  -----  \n 0   PassengerId  183 non-null    int64  \n 1   Survived     183 non-null    int64  \n 2   Pclass       183 non-null    int64  \n 3   Name         183 non-null    object \n 4   Sex          183 non-null    object \n 5   Age          183 non-null    float64\n 6   SibSp        183 non-null    int64  \n 7   Parch        183 non-null    int64  \n 8   Ticket       183 non-null    object \n 9   Fare         183 non-null    float64\n 10  Cabin        183 non-null    object \n 11  Embarked     183 non-null    object \ndtypes: float64(2), int64(5), object(5)\nmemory usage: 18.6+ KB\n\n\n\n# Check that the `Cabin` information is mostly missing; the same hold for `Age`\ndf_titanic_raw.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 891 entries, 0 to 890\nData columns (total 12 columns):\n #   Column       Non-Null Count  Dtype  \n---  ------       --------------  -----  \n 0   PassengerId  891 non-null    int64  \n 1   Survived     891 non-null    int64  \n 2   Pclass       891 non-null    int64  \n 3   Name         891 non-null    object \n 4   Sex          891 non-null    object \n 5   Age          714 non-null    float64\n 6   SibSp        891 non-null    int64  \n 7   Parch        891 non-null    int64  \n 8   Ticket       891 non-null    object \n 9   Fare         891 non-null    float64\n 10  Cabin        204 non-null    object \n 11  Embarked     889 non-null    object \ndtypes: float64(2), int64(5), object(5)\nmemory usage: 83.7+ KB\n\n\n\n\nDescription of the titanic.csv dataset\nDetails of the dataset are given here\n\nSurvived: Survival 0 = No, 1 = Yes\nPclass: Ticket class 1 = 1st, 2 = 2nd, 3 = 3rd\nSex: Sex male/female\nAge: Age in years\nSibsp: # of siblings/spouses aboard the Titanic\nParch: # of parents/children aboard the Titanic\nTicket: Ticket number\nFare: Passenger fare\nCabin: Cabin number\nEmbarked: Port of Embarkation C = Cherbourg, Q = Queenstown, S = Southampton\nName: Name of the passenger\nPassengerId: Number to identify passenger\n\n\n\n\n\n\n\nNote\n\n\n\nFor those interested, an extended version of the dataset is available here https://biostat.app.vumc.org/wiki/pub/Main/DataSets/titanic.txt.\n\n\n\n\nSimple descriptive statistics\n\ndf_titanic.describe()\n\n\n\n\n\n\n\n\nPassengerId\nSurvived\nPclass\nAge\nSibSp\nParch\nFare\n\n\n\n\ncount\n183.000000\n183.000000\n183.000000\n183.000000\n183.000000\n183.000000\n183.000000\n\n\nmean\n455.366120\n0.672131\n1.191257\n35.674426\n0.464481\n0.475410\n78.682469\n\n\nstd\n247.052476\n0.470725\n0.515187\n15.643866\n0.644159\n0.754617\n76.347843\n\n\nmin\n2.000000\n0.000000\n1.000000\n0.920000\n0.000000\n0.000000\n0.000000\n\n\n25%\n263.500000\n0.000000\n1.000000\n24.000000\n0.000000\n0.000000\n29.700000\n\n\n50%\n457.000000\n1.000000\n1.000000\n36.000000\n0.000000\n0.000000\n57.000000\n\n\n75%\n676.000000\n1.000000\n1.000000\n47.500000\n1.000000\n1.000000\n90.000000\n\n\nmax\n890.000000\n1.000000\n3.000000\n80.000000\n3.000000\n4.000000\n512.329200\n\n\n\n\n\n\n\n\n\nVisualization\n\nHistograms (please avoid‚Ä¶often useless)\n\n\nfig, ax = plt.subplots(1, 1, figsize=(5, 5))\nax.hist(df_titanic['Age'], density=True, bins=25)\nplt.xlabel('Age')\nplt.ylabel('Proportion')\nplt.title(\"Passager age histogram\")\nplt.show()\n\n\n\n\n\n\n\n\n\nKernel Density Estimate (KDE): :\n\n\nfig, ax = plt.subplots(1, 1, figsize=(5, 5))\nsns.kdeplot(\n    df_titanic[\"Age\"], ax=ax, fill=True, cut=0, bw_adjust=0.1\n)\nplt.xlabel(\"Proportion\")\nplt.ylabel(\"Age\")\nplt.title(\"Passager age kernel density estimate\")\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nNote: the bandwidth parameter (here encoded as bw_adjust) controls the smoothing level. It is a common parameter in kernel smoothing, investigated thoroughly in the non-parametric statistics literature.\n\n\n\nSwarmplot:\n\n\nfig, ax = plt.subplots(1, 1, figsize=(5, 5))\nsns.swarmplot(\n    data=df_titanic_raw,\n    ax=ax,\n    x=\"Sex\",\n    y=\"Age\",\n    hue=\"Survived\",\n    palette={0: \"r\", 1: \"k\"},\n    order=[\"female\", \"male\"],\n)\nplt.title(\"Passager age by gender/survival\")\nplt.legend(labels=[\"Died\", \"Survived\"], loc=\"upper left\")\nplt.tight_layout()\nplt.show()\n\n/home/jsalmon/anaconda3/envs/peerannot/lib/python3.10/site-packages/seaborn/categorical.py:3544: UserWarning:\n\n6.8% of the points cannot be placed; you may want to decrease the size of the markers or use stripplot.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEXERCISE density over histogram\n\n\n\nPlot the density estimate over the histogram\n\n\n\n\nWidgets\nInteractive interaction with codes and output is nowadays easier and easier (see also Shiny app in R-software). In Python, one can use widgets and the interact package for this purpose. We are going to visualize that on the simple KDE and histogram examples.\n\n\nXXX -&gt; to pyplot\ndef hist_explore(\n    dataset=df_titanic,\n    variable=df_titanic.columns,\n    n_bins=24,\n    alpha=0.25,\n    density=False,\n):\n    fig, ax = plt.subplots(1, 1, figsize=(5, 5))\n    ax.hist(\n        dataset[variable], density=density, bins=n_bins, alpha=alpha\n    )  # standardization\n    plt.ylabel(\"Density level\")\n    plt.title(f\"Dataset {dataset.attrs['name']}:\\n Histogram for passengers' age\")\n    plt.tight_layout()\n    plt.show()\n\n\ninteract(\n    hist_explore,\n    dataset=fixed(df_titanic),\n    n_bins=(1, 50, 1),\n    alpha=(0, 1, 0.1),\n    density=False,\n)\ndef kde_explore(dataset=df_titanic, variable=df_titanic.columns, bw=5):\n    fig, ax = plt.subplots(1, 1, figsize=(5, 5))\n    sns.kdeplot(dataset[variable], bw_adjust=bw, shade=True, cut=0, ax=ax)\n    plt.ylabel(\"Density level\")\n    plt.title(f\"Dataset {dataset.attrs['name']}:\\n KDE for passengers'  {variable}\")\n    plt.tight_layout()\n    plt.show()\n\ninteract(kde_explore, dataset=fixed(df_titanic), bw=(0.001, 2, 0.01))\n\n\nGroupby function\nHow does the survival rate change w.r.t. to sex?\n\ndf_titanic_raw.groupby('Sex')[['Survived']].aggregate(lambda x: x.mean())\n\n\n\n\n\n\n\n\nSurvived\n\n\nSex\n\n\n\n\n\nfemale\n0.742038\n\n\nmale\n0.188908\n\n\n\n\n\n\n\nHow does the survival rate change w.r.t. the class?\n\ndf_titanic.columns\n\nIndex(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'],\n      dtype='object')\n\n\n\nfig, ax = plt.subplots(1, 1, figsize=(5, 5))\n\ndf_titanic.groupby('Pclass')['Survived'].aggregate(lambda x:\n                                                   x.mean()).plot(ax=ax,kind='bar')\nplt.xlabel('Classe')\nplt.ylabel('Taux de survie')\nplt.title('Taux de survie par classe')\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEXERCISE median by class\n\n\n\nPerform a similar analysis with the median for the price per class in pounds.\n\n\n\n\ncatplot: a visual groupby\n\nax=sns.catplot(\n    x=\"Pclass\",\n    y=\"Age\",\n    hue=\"Sex\",\n    palette={'female': 'red', 'male': 'b'},\n    data=df_titanic_raw,\n    jitter = '0.2',\n    s=8,\n)\nsns.move_legend(ax, \"upper left\", bbox_to_anchor=(0.8, 0.8))\nplt.show()\n\n\n\n\n\n\n\n\n\nax=sns.catplot(\n    x=\"Pclass\",\n    y=\"Age\",\n    hue=\"Sex\",\n    palette={'female': 'red', 'male': 'b'},\n    alpha=0.8,\n    data=df_titanic_raw,\n    kind='swarm',\n    s=11,\n)\nsns.move_legend(ax, \"upper left\", bbox_to_anchor=(0.8, 0.8))\nplt.show()\n\n\n\n\n\n\n\n\n\nax=sns.catplot(\n    x=\"Sex\",\n    y=\"Age\",\n    hue=\"Sex\",\n    palette={'female': 'red', 'male': 'b'},\n    col='Pclass',\n    alpha=0.8,\n    data=df_titanic_raw,\n    kind='swarm',\n    s=6,\n    height=5,\n    aspect=0.35\n)\nplt.show()\n\n\n\n\n\n\n\n\n\nax=sns.catplot(x='Pclass',\n            y='Age',\n            hue=\"Sex\",\n            palette={'female': 'red', 'male': 'b'},\n            data=df_titanic_raw,\n            kind=\"violin\",\n            alpha=0.8,\n)\nsns.move_legend(ax, \"upper left\", bbox_to_anchor=(0.8, 0.8))\nplt.show()\n\n\n\n\n\n\n\n\nBeware: large difference in sex ratio by class\n\ndf_titanic_raw.groupby(['Sex', 'Pclass'])[['Sex']].count()\ndf_titanic_raw.groupby(['Sex'])[['Sex']].count()\n\n\n\n\n\n\n\n\nSex\n\n\nSex\n\n\n\n\n\nfemale\n314\n\n\nmale\n577\n\n\n\n\n\n\n\nConsider checking the raw data, as often boxplots or simple statistics are not enough to understand the diversity inside the data; see for instance the discussion here: https://sigmoid.social/@ct_bergstrom@fediscience.org/110267907203021857\nReferences:\n\nPractical Business Python, Comprehensive Guide to Grouping and Aggregating with Pandas, by Chris Moffitt\n\n\n\npd.crosstab\n\npd.crosstab(\n    df_titanic_raw[\"Sex\"],\n    df_titanic_raw[\"Pclass\"],\n    values=df_titanic_raw[\"Sex\"],\n    aggfunc=\"count\",\n    normalize=False,\n)\n\n\n\n\n\n\n\nPclass\n1\n2\n3\n\n\nSex\n\n\n\n\n\n\n\nfemale\n94\n76\n144\n\n\nmale\n122\n108\n347\n\n\n\n\n\n\n\n\ndf_titanic\n\n\n\n\n\n\n\n\nPassengerId\nSurvived\nPclass\nName\nSex\nAge\nSibSp\nParch\nTicket\nFare\nCabin\nEmbarked\n\n\n\n\n1\n2\n1\n1\nCumings, Mrs. John Bradley (Florence Briggs Th...\nfemale\n38.0\n1\n0\nPC 17599\n71.2833\nC85\nC\n\n\n3\n4\n1\n1\nFutrelle, Mrs. Jacques Heath (Lily May Peel)\nfemale\n35.0\n1\n0\n113803\n53.1000\nC123\nS\n\n\n6\n7\n0\n1\nMcCarthy, Mr. Timothy J\nmale\n54.0\n0\n0\n17463\n51.8625\nE46\nS\n\n\n10\n11\n1\n3\nSandstrom, Miss. Marguerite Rut\nfemale\n4.0\n1\n1\nPP 9549\n16.7000\nG6\nS\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n872\n873\n0\n1\nCarlsson, Mr. Frans Olof\nmale\n33.0\n0\n0\n695\n5.0000\nB51 B53 B55\nS\n\n\n879\n880\n1\n1\nPotter, Mrs. Thomas Jr (Lily Alexenia Wilson)\nfemale\n56.0\n0\n1\n11767\n83.1583\nC50\nC\n\n\n887\n888\n1\n1\nGraham, Miss. Margaret Edith\nfemale\n19.0\n0\n0\n112053\n30.0000\nB42\nS\n\n\n889\n890\n1\n1\nBehr, Mr. Karl Howell\nmale\n26.0\n0\n0\n111369\n30.0000\nC148\nC\n\n\n\n\n183 rows √ó 12 columns\n\n\n\n\ndf_titanic.index\n\nIndex([  1,   3,   6,  10,  11,  21,  23,  27,  52,  54,\n       ...\n       835, 853, 857, 862, 867, 871, 872, 879, 887, 889],\n      dtype='int64', length=183)\n\n\n\ndf_titanic.columns\n\nIndex(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'],\n      dtype='object')\n\n\n\npd.options.display.max_rows = 12\ndf_titanic.dtypes\n\ndf_titanic['Name'].astype(str)\n\n1      Cumings, Mrs. John Bradley (Florence Briggs Th...\n3           Futrelle, Mrs. Jacques Heath (Lily May Peel)\n6                                McCarthy, Mr. Timothy J\n10                       Sandstrom, Miss. Marguerite Rut\n11                              Bonnell, Miss. Elizabeth\n                             ...                        \n871     Beckwith, Mrs. Richard Leonard (Sallie Monypeny)\n872                             Carlsson, Mr. Frans Olof\n879        Potter, Mrs. Thomas Jr (Lily Alexenia Wilson)\n887                         Graham, Miss. Margaret Edith\n889                                Behr, Mr. Karl Howell\nName: Name, Length: 183, dtype: object\n\n\n\n\nExtract numpy arrays from dataframes\nuseful for using packages on top of pandas (e.g., sklearn, though nowadays it works out of the box with pandas)\n\narray_titanic = df_titanic.values  # associated numpy array\narray_titanic\n\narray([[2, 1, 1, ..., 71.2833, 'C85', 'C'],\n       [4, 1, 1, ..., 53.1, 'C123', 'S'],\n       [7, 0, 1, ..., 51.8625, 'E46', 'S'],\n       ...,\n       [880, 1, 1, ..., 83.1583, 'C50', 'C'],\n       [888, 1, 1, ..., 30.0, 'B42', 'S'],\n       [890, 1, 1, ..., 30.0, 'C148', 'C']], dtype=object)\n\n\n\n\n\n\n\n\nEXERCISE: dropna\n\n\n\nPerform the following operation: remove the columns Cabin from the raw dataset, and then remove the rows with the variable Age missing.\nHint: check the ‚Äòdropna‚Äô documentation.\n\n\n\n\n1D dataset: Series (a column of a DataFrame)\nA Series is a labeled 1D column of a kind.\n\nfare = df_titanic['Fare']\nfare\n\n1      71.2833\n3      53.1000\n6      51.8625\n10     16.7000\n11     26.5500\n        ...   \n871    52.5542\n872     5.0000\n879    83.1583\n887    30.0000\n889    30.0000\nName: Fare, Length: 183, dtype: float64\n\n\n\n\nAttributes Series: indices and values\n\nfare.values[:10]\n\narray([ 71.2833,  53.1   ,  51.8625,  16.7   ,  26.55  ,  13.    ,\n        35.5   , 263.    ,  76.7292,  61.9792])\n\n\nContrarily to numpy arrays, you can index with other formats than integers:\n\n# Be careful, what follows changes the indexing\ndf_titanic_raw = df_titanic_raw.set_index('Name')\ndf_titanic_raw\n\n\n\n\n\n\n\n\nPassengerId\nSurvived\nPclass\nSex\nAge\nSibSp\nParch\nTicket\nFare\nCabin\nEmbarked\n\n\nName\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBraund, Mr. Owen Harris\n1\n0\n3\nmale\n22.0\n1\n0\nA/5 21171\n7.2500\nNaN\nS\n\n\nCumings, Mrs. John Bradley (Florence Briggs Thayer)\n2\n1\n1\nfemale\n38.0\n1\n0\nPC 17599\n71.2833\nC85\nC\n\n\nHeikkinen, Miss. Laina\n3\n1\n3\nfemale\n26.0\n0\n0\nSTON/O2. 3101282\n7.9250\nNaN\nS\n\n\nFutrelle, Mrs. Jacques Heath (Lily May Peel)\n4\n1\n1\nfemale\n35.0\n1\n0\n113803\n53.1000\nC123\nS\n\n\nAllen, Mr. William Henry\n5\n0\n3\nmale\n35.0\n0\n0\n373450\n8.0500\nNaN\nS\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\nMontvila, Rev. Juozas\n887\n0\n2\nmale\n27.0\n0\n0\n211536\n13.0000\nNaN\nS\n\n\nGraham, Miss. Margaret Edith\n888\n1\n1\nfemale\n19.0\n0\n0\n112053\n30.0000\nB42\nS\n\n\nJohnston, Miss. Catherine Helen \"Carrie\"\n889\n0\n3\nfemale\nNaN\n1\n2\nW./C. 6607\n23.4500\nNaN\nS\n\n\nBehr, Mr. Karl Howell\n890\n1\n1\nmale\n26.0\n0\n0\n111369\n30.0000\nC148\nC\n\n\nDooley, Mr. Patrick\n891\n0\n3\nmale\n32.0\n0\n0\n370376\n7.7500\nNaN\nQ\n\n\n\n\n891 rows √ó 11 columns\n\n\n\n\nage = df_titanic_raw['Age']\nage['Behr, Mr. Karl Howell']\n\n26.0\n\n\n\nage.mean()\n\n29.69911764705882\n\n\n\ndf_titanic_raw[age &lt; 2]\n\n\n\n\n\n\n\n\nPassengerId\nSurvived\nPclass\nSex\nAge\nSibSp\nParch\nTicket\nFare\nCabin\nEmbarked\n\n\nName\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCaldwell, Master. Alden Gates\n79\n1\n2\nmale\n0.83\n0\n2\n248738\n29.0000\nNaN\nS\n\n\nPanula, Master. Eino Viljami\n165\n0\n3\nmale\n1.00\n4\n1\n3101295\n39.6875\nNaN\nS\n\n\nJohnson, Miss. Eleanor Ileen\n173\n1\n3\nfemale\n1.00\n1\n1\n347742\n11.1333\nNaN\nS\n\n\nBecker, Master. Richard F\n184\n1\n2\nmale\n1.00\n2\n1\n230136\n39.0000\nF4\nS\n\n\nAllison, Master. Hudson Trevor\n306\n1\n1\nmale\n0.92\n1\n2\n113781\n151.5500\nC22 C26\nS\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\nHamalainen, Master. Viljo\n756\n1\n2\nmale\n0.67\n1\n1\n250649\n14.5000\nNaN\nS\n\n\nDean, Master. Bertram Vere\n789\n1\n3\nmale\n1.00\n1\n2\nC.A. 2315\n20.5750\nNaN\nS\n\n\nThomas, Master. Assad Alexander\n804\n1\n3\nmale\n0.42\n0\n1\n2625\n8.5167\nNaN\nC\n\n\nMallet, Master. Andre\n828\n1\n2\nmale\n1.00\n0\n2\nS.C./PARIS 2079\n37.0042\nNaN\nC\n\n\nRichards, Master. George Sibley\n832\n1\n2\nmale\n0.83\n1\n1\n29106\n18.7500\nNaN\nS\n\n\n\n\n14 rows √ó 11 columns\n\n\n\n\n# You can come back to the original indexing\ndf_titanic_raw = df_titanic_raw.reset_index()"
  },
  {
    "objectID": "Courses/Pandas/tp.html#third-example-explore-a-dataset-on-bike-accidents-in-france",
    "href": "Courses/Pandas/tp.html#third-example-explore-a-dataset-on-bike-accidents-in-france",
    "title": "Pandas",
    "section": "Third example: explore a dataset on bike accidents in France",
    "text": "Third example: explore a dataset on bike accidents in France\nReferences:\n\nData original source\nPossible visualization\n\n\nurl = \"https://koumoul.com/s/data-fair/api/v1/datasets/accidents-velos/raw\"\npath_target = \"./bicycle_db.csv\"\npath, fname = os.path.split(path_target)\npooch.retrieve(url, path=path, fname=fname, known_hash=None)\n\n'/home/jsalmon/Documents/Mes_cours/Montpellier/HAX712X/Courses/Pandas/bicycle_db.csv'\n\n\n\n# df: data frame\ndf_bikes = pd.read_csv(\"bicycle_db.csv\", na_values=\"\", low_memory=False,\n                       dtype={'data': str, 'heure': str, 'departement': str})\n\nIn June 2023, the author decided to change the name of the columns, hence we had to define a dictionary to come back to legacy names:\n\nnew2old = {\n\"hrmn\": \"heure\",\n\"secuexist\": \"existence securite\",\n\"grav\": \"gravite accident\",\n\"dep\": \"departement\"\n}\n\ndf_bikes.rename(columns=new2old, inplace=True)\n\n\nget_ipython().system('head -5 ./bicycle_db.csv')\n\n\npd.options.display.max_columns = 40\ndf_bikes.head()\n\n\n\n\n\n\n\n\nidentifiant accident\ndate\nmois\njour\nheure\ndepartement\ncommune\nlat\nlon\nen agglomeration\ntype intersection\ntype collision\nluminosite\nconditions atmosperiques\ntype route\ncirculation\nnb voies\nprofil long route\ntrace plan route\nlargeur TPC\nlargeur route\netat surface\namenagement\nsituation\ncategorie usager\ngravite accident\nsexe\nage\nmotif deplacement\nexistence securite\nusage securite\nobstacle fixe heurte\nobstacle mobile heurte\nlocalisation choc\nmanoeuvre avant accident\nidentifiant vehicule\ntype autres vehicules\nmanoeuvre autres vehicules\nnombre autres vehicules\n\n\n\n\n0\n200500000030\n2005-01-13\n01 - janvier\n3 - jeudi\n19\n62\n62331\n50.300\n2.840\noui\nHors intersection\nDeux v√©hicules - par le cot√©\nNuit avec √©clairage public allum√©\nNormale\nRoute D√©partementale\nNaN\nNaN\nNaN\nPartie rectiligne\nNaN\n50.0\nnormale\nNaN\nSur chauss√©e\nConducteur\n1 - Bless√© l√©ger\nM\n57-58\nPromenade - loisirs\nNaN\nNaN\nNaN\nV√©hicule\nC√¥t√© gauche\nChangeant de file √† gauche\n200500000030B02\nTransport en commun\nD√©passant √† gauche\n1.0\n\n\n1\n200500000034\n2005-01-19\n01 - janvier\n2 - mercredi\n10\n62\n62022\n0.000\n0.000\nnon\nHors intersection\nDeux v√©hicules - frontale\nPlein jour\nTemps √©blouissant\nRoute D√©partementale\nNaN\nNaN\nPlat\nEn courbe √† droite\nNaN\n50.0\nnormale\nNaN\nSur chauss√©e\nConducteur\n2 - Bless√© hospitalis√©\nM\n19-20\nPromenade - loisirs\nNaN\nNaN\nNaN\nV√©hicule\nAvant\nSans changement de direction\n200500000034B02\nVU seul 1,5T &lt;= PTAC &lt;= 3,5T avec ou sans remo...\nTournant √† gauche\n1.0\n\n\n2\n200500000078\n2005-01-26\n01 - janvier\n2 - mercredi\n13\n02\n02173\n0.000\n0.000\nnon\nAutre intersection\nDeux v√©hicules - par le cot√©\nPlein jour\nNormale\nRoute D√©partementale\nNaN\n2.0\nPente\nPartie rectiligne\nNaN\nNaN\nnormale\nNaN\nSur chauss√©e\nConducteur\n1 - Bless√© l√©ger\nM\n70-71\nPromenade - loisirs\nCasque\nNon\nNaN\nV√©hicule\nAvant\nSans changement de direction\n200500000078B02\nVL seul\nTournant √† gauche\n1.0\n\n\n3\n200500000093\n2005-01-03\n01 - janvier\n0 - lundi\n13\n02\n02810\n49.255\n3.094\noui\nHors intersection\nDeux v√©hicules - frontale\nPlein jour\nNormale\nRoute D√©partementale\nNaN\nNaN\nPlat\nEn courbe √† gauche\nNaN\n52.0\nnormale\nNaN\nSur chauss√©e\nConducteur\n2 - Bless√© hospitalis√©\nF\n50-51\nUtilisation professionnelle\nNaN\nNaN\nNaN\nV√©hicule\nAvant gauche\nMan≈ìuvre d‚Äô√©vitement\n200500000093B02\nVL seul\nMan≈ìuvre d‚Äô√©vitement\n1.0\n\n\n4\n200500000170\n2005-01-29\n01 - janvier\n5 - samedi\n18\n76\n76196\n0.000\n0.000\nnon\nHors intersection\nDeux v√©hicules - par l‚Äôarri√®re\nNuit sans √©clairage public\nNormale\nRoute D√©partementale\nNaN\n2.0\nPlat\nPartie rectiligne\nNaN\n50.0\nnormale\nNaN\nSur chauss√©e\nConducteur\n1 - Bless√© l√©ger\nM\n73-74\nPromenade - loisirs\nAutre\nOui\nNaN\nV√©hicule\nArri√®re\nM√™me sens, m√™me file\n200500000170A01\nVU seul 1,5T &lt;= PTAC &lt;= 3,5T avec ou sans remo...\nM√™me sens, m√™me file\n1.0\n\n\n\n\n\n\n\n\ndf_bikes['existence securite'].unique()\n\narray([nan, 'Casque', 'Autre', 'Equipement r√©fl√©chissant', 'Ceinture',\n       'Dispositif enfants'], dtype=object)\n\n\n\ndf_bikes['gravite accident'].unique()\n\narray(['1 - Bless√© l√©ger', '2 - Bless√© hospitalis√©', '3 - Tu√©',\n       '0 - Indemne'], dtype=object)\n\n\n\nHandle missing values in heure\n\ndf_bikes['date'].hasnans\ndf_bikes['heure'].hasnans\n\nTrue\n\n\n\npd.options.display.max_rows = 20\ndf_bikes.iloc[400:402]\n\n\n\n\n\n\n\n\nidentifiant accident\ndate\nmois\njour\nheure\ndepartement\ncommune\nlat\nlon\nen agglomeration\ntype intersection\ntype collision\nluminosite\nconditions atmosperiques\ntype route\ncirculation\nnb voies\nprofil long route\ntrace plan route\nlargeur TPC\nlargeur route\netat surface\namenagement\nsituation\ncategorie usager\ngravite accident\nsexe\nage\nmotif deplacement\nexistence securite\nusage securite\nobstacle fixe heurte\nobstacle mobile heurte\nlocalisation choc\nmanoeuvre avant accident\nidentifiant vehicule\ntype autres vehicules\nmanoeuvre autres vehicules\nnombre autres vehicules\n\n\n\n\n400\n200500008935\n2005-02-13\n02 - f√©vrier\n6 - dimanche\nNaN\n75\n75018\n0.0\n0.0\noui\nIntersection en X\nDeux v√©hicules - par le cot√©\nNuit avec √©clairage public allum√©\nVent fort - temp√™te\nVoie Communale\nNaN\n4.0\nPlat\nPartie rectiligne\nNaN\n120.0\nnormale\nNaN\nSur chauss√©e\nConducteur\n1 - Bless√© l√©ger\nM\n32-33\nDomicile - travail\nCasque\nOui\nNaN\nV√©hicule\nAvant gauche\nDans le couloir bus, dans le m√™me sens\n200500008935B01\nVL seul\nTournant a droite\n1.0\n\n\n401\n200500008941\n2005-02-14\n02 - f√©vrier\n0 - lundi\n15\n75\n75007\n0.0\n0.0\noui\nHors intersection\nDeux v√©hicules - par le cot√©\nPlein jour\nNormale\nVoie Communale\nNaN\n4.0\nPlat\nPartie rectiligne\nNaN\n120.0\nnormale\nNaN\nSur chauss√©e\nConducteur\n1 - Bless√© l√©ger\nF\n21-22\nPromenade - loisirs\nCasque\nOui\nNaN\nV√©hicule\nAvant droit\nSans changement de direction\n200500008941A01\nVL seul\nEn s‚Äôins√©rant\n1.0\n\n\n\n\n\n\n\nRemove missing hours cases by np.nan:\n\ndf_bikes['heure'] = df_bikes['heure'].replace('', np.nan)\ndf_bikes.iloc[400:402]\n\n\n\n\n\n\n\n\nidentifiant accident\ndate\nmois\njour\nheure\ndepartement\ncommune\nlat\nlon\nen agglomeration\ntype intersection\ntype collision\nluminosite\nconditions atmosperiques\ntype route\ncirculation\nnb voies\nprofil long route\ntrace plan route\nlargeur TPC\nlargeur route\netat surface\namenagement\nsituation\ncategorie usager\ngravite accident\nsexe\nage\nmotif deplacement\nexistence securite\nusage securite\nobstacle fixe heurte\nobstacle mobile heurte\nlocalisation choc\nmanoeuvre avant accident\nidentifiant vehicule\ntype autres vehicules\nmanoeuvre autres vehicules\nnombre autres vehicules\n\n\n\n\n400\n200500008935\n2005-02-13\n02 - f√©vrier\n6 - dimanche\nNaN\n75\n75018\n0.0\n0.0\noui\nIntersection en X\nDeux v√©hicules - par le cot√©\nNuit avec √©clairage public allum√©\nVent fort - temp√™te\nVoie Communale\nNaN\n4.0\nPlat\nPartie rectiligne\nNaN\n120.0\nnormale\nNaN\nSur chauss√©e\nConducteur\n1 - Bless√© l√©ger\nM\n32-33\nDomicile - travail\nCasque\nOui\nNaN\nV√©hicule\nAvant gauche\nDans le couloir bus, dans le m√™me sens\n200500008935B01\nVL seul\nTournant a droite\n1.0\n\n\n401\n200500008941\n2005-02-14\n02 - f√©vrier\n0 - lundi\n15\n75\n75007\n0.0\n0.0\noui\nHors intersection\nDeux v√©hicules - par le cot√©\nPlein jour\nNormale\nVoie Communale\nNaN\n4.0\nPlat\nPartie rectiligne\nNaN\n120.0\nnormale\nNaN\nSur chauss√©e\nConducteur\n1 - Bless√© l√©ger\nF\n21-22\nPromenade - loisirs\nCasque\nOui\nNaN\nV√©hicule\nAvant droit\nSans changement de direction\n200500008941A01\nVL seul\nEn s‚Äôins√©rant\n1.0\n\n\n\n\n\n\n\n\ndf_bikes.dropna(subset=['heure'], inplace=True)\ndf_bikes.iloc[399:402]\n\n\n\n\n\n\n\n\nidentifiant accident\ndate\nmois\njour\nheure\ndepartement\ncommune\nlat\nlon\nen agglomeration\ntype intersection\ntype collision\nluminosite\nconditions atmosperiques\ntype route\ncirculation\nnb voies\nprofil long route\ntrace plan route\nlargeur TPC\nlargeur route\netat surface\namenagement\nsituation\ncategorie usager\ngravite accident\nsexe\nage\nmotif deplacement\nexistence securite\nusage securite\nobstacle fixe heurte\nobstacle mobile heurte\nlocalisation choc\nmanoeuvre avant accident\nidentifiant vehicule\ntype autres vehicules\nmanoeuvre autres vehicules\nnombre autres vehicules\n\n\n\n\n399\n200500008875\n2005-02-10\n02 - f√©vrier\n3 - jeudi\n15\n75\n75016\n0.0\n0.0\noui\nHors intersection\nDeux v√©hicules - par l‚Äôarri√®re\nPlein jour\nNormale\nVoie Communale\nNaN\n4.0\nPlat\nPartie rectiligne\nNaN\n120.0\nnormale\nNaN\nSur chauss√©e\nConducteur\n1 - Bless√© l√©ger\nM\n53-54\nPromenade - loisirs\nNaN\nNaN\nNaN\nV√©hicule\nArri√®re\nSans changement de direction\n200500008875B01\nBicyclette\nSans changement de direction\n1.0\n\n\n401\n200500008941\n2005-02-14\n02 - f√©vrier\n0 - lundi\n15\n75\n75007\n0.0\n0.0\noui\nHors intersection\nDeux v√©hicules - par le cot√©\nPlein jour\nNormale\nVoie Communale\nNaN\n4.0\nPlat\nPartie rectiligne\nNaN\n120.0\nnormale\nNaN\nSur chauss√©e\nConducteur\n1 - Bless√© l√©ger\nF\n21-22\nPromenade - loisirs\nCasque\nOui\nNaN\nV√©hicule\nAvant droit\nSans changement de direction\n200500008941A01\nVL seul\nEn s‚Äôins√©rant\n1.0\n\n\n402\n200500008961\n2005-02-11\n02 - f√©vrier\n4 - vendredi\n12\n75\n75005\n0.0\n0.0\noui\nIntersection en T\nDeux v√©hicules - par le cot√©\nPlein jour\nNormale\nVoie Communale\nNaN\n2.0\nPlat\nPartie rectiligne\nNaN\n60.0\nmouill√©e\nNaN\nSur chauss√©e\nConducteur\n1 - Bless√© l√©ger\nF\n27-28\nAutre\nCasque\nOui\nNaN\nV√©hicule\nAvant gauche\nSans changement de direction\n200500008961A01\nScooter immatricul√©\nSans changement de direction\n1.0\n\n\n\n\n\n\n\n::: {.callout-important appearance=‚Äòdefault‚Äô icon=‚Äúfalse‚Äù} ## EXERCISE: start/end of the study\nCan you find the starting day and the ending day of the study automatically?\nHint: Sort the data! You can sort the data by time for instance, say with df.sort('Time').\n\ndf_bikes['date'] + ' ' + df_bikes['heure']\n\n0        2005-01-13 19\n1        2005-01-19 10\n2        2005-01-26 13\n3        2005-01-03 13\n4        2005-01-29 18\n             ...      \n65976     2018-09-27 8\n65977    2018-03-21 18\n65978    2018-03-31 17\n65979    2018-03-31 17\n65980    2018-07-31 11\nLength: 65515, dtype: object\n\n\n\n# ADAPT OLD to create the df_bikes['Time']\n\ntime_improved = pd.to_datetime(df_bikes['date'] +\n                               ' ' + df_bikes['heure'],\n                               format='%Y-%m-%d %H',\n                               errors='coerce')\n\n# Where d = day, m=month, Y=year, H=hour, M=minutes\n\n\ndf_bikes['Time'] = time_improved\n# remove rows with NaT\ndf_bikes.dropna(subset=[\"Time\"], inplace=True)\n# set new index \ndf_bikes.set_index('Time', inplace=True)\n# remove useless columns\ndf_bikes.drop(columns=['heure', 'date'], inplace=True)\n\n\ndf_bikes.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nDatetimeIndex: 65515 entries, 2005-01-13 19:00:00 to 2018-07-31 11:00:00\nData columns (total 37 columns):\n #   Column                      Non-Null Count  Dtype  \n---  ------                      --------------  -----  \n 0   identifiant accident        65515 non-null  int64  \n 1   mois                        65515 non-null  object \n 2   jour                        65515 non-null  object \n 3   departement                 65515 non-null  object \n 4   commune                     65515 non-null  object \n 5   lat                         65515 non-null  float64\n 6   lon                         65249 non-null  float64\n 7   en agglomeration            65515 non-null  object \n 8   type intersection           65513 non-null  object \n 9   type collision              65511 non-null  object \n 10  luminosite                  65515 non-null  object \n 11  conditions atmosperiques    65512 non-null  object \n 12  type route                  65504 non-null  object \n 13  circulation                 143 non-null    object \n 14  nb voies                    57417 non-null  float64\n 15  profil long route           60966 non-null  object \n 16  trace plan route            59460 non-null  object \n 17  largeur TPC                 5142 non-null   float64\n 18  largeur route               39991 non-null  float64\n 19  etat surface                63000 non-null  object \n 20  amenagement                 7231 non-null   object \n 21  situation                   61378 non-null  object \n 22  categorie usager            65515 non-null  object \n 23  gravite accident            65515 non-null  object \n 24  sexe                        65515 non-null  object \n 25  age                         65489 non-null  object \n 26  motif deplacement           51958 non-null  object \n 27  existence securite          60160 non-null  object \n 28  usage securite              58292 non-null  object \n 29  obstacle fixe heurte        1434 non-null   object \n 30  obstacle mobile heurte      52601 non-null  object \n 31  localisation choc           56474 non-null  object \n 32  manoeuvre avant accident    58859 non-null  object \n 33  identifiant vehicule        65515 non-null  object \n 34  type autres vehicules       56827 non-null  object \n 35  manoeuvre autres vehicules  52643 non-null  object \n 36  nombre autres vehicules     56827 non-null  float64\ndtypes: float64(6), int64(1), object(30)\nmemory usage: 19.0+ MB\n\n\n\ndf_bike2 = df_bikes.loc[\n    :, [\"gravite accident\", \"existence securite\", \"age\", \"sexe\"]\n]\ndf_bike2[\"existence securite\"].replace({\"Inconnu\": np.nan}, inplace=True)\ndf_bike2.dropna(inplace=True)\n\n\n\n\n\n\n\nEXERCISE: Is the helmet saving your life?\n\n\n\nPerform an analysis so that you can check the benefit or not of wearing a helmet to save your life. Beware: Preprocessing is needed to use pd.crosstab, pivot_table to avoid issues.\n\n\n\n\n\n\n\n\n\n\n\n\nage\n\n\n\nexistence securite\nAutre\nCasque\nCeinture\nDispositif enfants\nEquipement r√©fl√©chissant\nAll\n\n\ngravite accident\nsexe\n\n\n\n\n\n\n\n\n\n\n0 - Indemne\nF\n187.0\n298.0\n8.0\n1.0\n33.0\n527\n\n\nM\n1121.0\n1952.0\n47.0\n6.0\n189.0\n3315\n\n\n1 - Bless√© l√©ger\nF\n3949.0\n5143.0\n48.0\n21.0\n815.0\n9976\n\n\nM\n9180.0\n13892.0\n171.0\n52.0\n1912.0\n25207\n\n\n2 - Bless√© hospitalis√©\nF\n1409.0\n1977.0\n236.0\n9.0\n310.0\n3941\n\n\nM\n4022.0\n9241.0\n781.0\n24.0\n1147.0\n15215\n\n\n3 - Tu√©\nF\n87.0\n164.0\n32.0\nNaN\n37.0\n320\n\n\nM\n291.0\n1062.0\n117.0\n3.0\n160.0\n1633\n\n\nAll\n\n20246.0\n33729.0\n1440.0\n116.0\n4603.0\n60134\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ngravite accident\n0 - Indemne\n1 - Bless√© l√©ger\n2 - Bless√© hospitalis√©\n3 - Tu√©\n\n\nexistence securite\n\n\n\n\n\n\n\n\nAutre\n6.460535\n64.847377\n26.825052\n1.867035\n\n\nCasque\n6.670817\n56.435115\n33.259213\n3.634854\n\n\nCeinture\n3.819444\n15.208333\n70.625000\n10.347222\n\n\nDispositif enfants\n6.034483\n62.931034\n28.448276\n2.586207\n\n\nEquipement r√©fl√©chissant\n4.822942\n59.243971\n31.653270\n4.279818\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ngravite accident\n0 - Indemne\n1 - Bless√© l√©ger\n2 - Bless√© hospitalis√©\n3 - Tu√©\n\n\nexistence securite\n\n\n\n\n\n\n\n\nAutre\n6.460535\n64.847377\n26.825052\n1.867035\n\n\nCasque\n6.670817\n56.435115\n33.259213\n3.634854\n\n\nCeinture\n3.819444\n15.208333\n70.625000\n10.347222\n\n\nDispositif enfants\n6.034483\n62.931034\n28.448276\n2.586207\n\n\nEquipement r√©fl√©chissant\n4.822942\n59.243971\n31.653270\n4.279818\n\n\n\n\n\n\n\n\n\n\n\n\n\nEXERCISE: Are men and women dying equally on a bike?\n\n\n\nPerform an analysis to check differences between men‚Äôs and women‚Äôs survival.\n\n\n\n\nsexe\nF    0.172278\nM    0.827722\ndtype: float64\n\n\n\n\nsexe\nF    0.248477\nM    0.751523\ndtype: float64\n\n\n\n\n\n\n\n\n\n\ngravite accident\n0 - Indemne\n1 - Bless√© l√©ger\n2 - Bless√© hospitalis√©\n3 - Tu√©\nAll\n\n\nsexe\n\n\n\n\n\n\n\n\n\nF\n13.716814\n28.354603\n20.573189\n16.385049\n24.551834\n\n\nM\n86.283186\n71.645397\n79.426811\n83.614951\n75.448166\n\n\n\n\n\n\n\n\n\nTo conclude\nNote that in the dataset, the information on the level of bike practice by gender is missing.\n\n\n\n\n\n\nEXERCISE: Accident during the week?\n\n\n\nPerform an analysis to check when the accidents are occurring during the week.\n\n\n\ndf_bikes\n\n\n\n\n\n\n\n\nidentifiant accident\nmois\njour\ndepartement\ncommune\nlat\nlon\nen agglomeration\ntype intersection\ntype collision\nluminosite\nconditions atmosperiques\ntype route\ncirculation\nnb voies\nprofil long route\ntrace plan route\nlargeur TPC\nlargeur route\netat surface\namenagement\nsituation\ncategorie usager\ngravite accident\nsexe\nage\nmotif deplacement\nexistence securite\nusage securite\nobstacle fixe heurte\nobstacle mobile heurte\nlocalisation choc\nmanoeuvre avant accident\nidentifiant vehicule\ntype autres vehicules\nmanoeuvre autres vehicules\nnombre autres vehicules\n\n\nTime\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n2005-01-13 19:00:00\n200500000030\n01 - janvier\n3 - jeudi\n62\n62331\n50.30000\n2.84000\noui\nHors intersection\nDeux v√©hicules - par le cot√©\nNuit avec √©clairage public allum√©\nNormale\nRoute D√©partementale\nNaN\nNaN\nNaN\nPartie rectiligne\nNaN\n50.0\nnormale\nNaN\nSur chauss√©e\nConducteur\n1 - Bless√© l√©ger\nM\n57-58\nPromenade - loisirs\nNaN\nNaN\nNaN\nV√©hicule\nC√¥t√© gauche\nChangeant de file √† gauche\n200500000030B02\nTransport en commun\nD√©passant √† gauche\n1.0\n\n\n2005-01-19 10:00:00\n200500000034\n01 - janvier\n2 - mercredi\n62\n62022\n0.00000\n0.00000\nnon\nHors intersection\nDeux v√©hicules - frontale\nPlein jour\nTemps √©blouissant\nRoute D√©partementale\nNaN\nNaN\nPlat\nEn courbe √† droite\nNaN\n50.0\nnormale\nNaN\nSur chauss√©e\nConducteur\n2 - Bless√© hospitalis√©\nM\n19-20\nPromenade - loisirs\nNaN\nNaN\nNaN\nV√©hicule\nAvant\nSans changement de direction\n200500000034B02\nVU seul 1,5T &lt;= PTAC &lt;= 3,5T avec ou sans remo...\nTournant √† gauche\n1.0\n\n\n2005-01-26 13:00:00\n200500000078\n01 - janvier\n2 - mercredi\n02\n02173\n0.00000\n0.00000\nnon\nAutre intersection\nDeux v√©hicules - par le cot√©\nPlein jour\nNormale\nRoute D√©partementale\nNaN\n2.0\nPente\nPartie rectiligne\nNaN\nNaN\nnormale\nNaN\nSur chauss√©e\nConducteur\n1 - Bless√© l√©ger\nM\n70-71\nPromenade - loisirs\nCasque\nNon\nNaN\nV√©hicule\nAvant\nSans changement de direction\n200500000078B02\nVL seul\nTournant √† gauche\n1.0\n\n\n2005-01-03 13:00:00\n200500000093\n01 - janvier\n0 - lundi\n02\n02810\n49.25500\n3.09400\noui\nHors intersection\nDeux v√©hicules - frontale\nPlein jour\nNormale\nRoute D√©partementale\nNaN\nNaN\nPlat\nEn courbe √† gauche\nNaN\n52.0\nnormale\nNaN\nSur chauss√©e\nConducteur\n2 - Bless√© hospitalis√©\nF\n50-51\nUtilisation professionnelle\nNaN\nNaN\nNaN\nV√©hicule\nAvant gauche\nMan≈ìuvre d‚Äô√©vitement\n200500000093B02\nVL seul\nMan≈ìuvre d‚Äô√©vitement\n1.0\n\n\n2005-01-29 18:00:00\n200500000170\n01 - janvier\n5 - samedi\n76\n76196\n0.00000\n0.00000\nnon\nHors intersection\nDeux v√©hicules - par l‚Äôarri√®re\nNuit sans √©clairage public\nNormale\nRoute D√©partementale\nNaN\n2.0\nPlat\nPartie rectiligne\nNaN\n50.0\nnormale\nNaN\nSur chauss√©e\nConducteur\n1 - Bless√© l√©ger\nM\n73-74\nPromenade - loisirs\nAutre\nOui\nNaN\nV√©hicule\nArri√®re\nM√™me sens, m√™me file\n200500000170A01\nVU seul 1,5T &lt;= PTAC &lt;= 3,5T avec ou sans remo...\nM√™me sens, m√™me file\n1.0\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n2018-09-27 08:00:00\n201800057521\n09 - septembre\n3 - jeudi\n974\n97416\n-21.29643\n55.46052\nnon\nHors intersection\nDeux v√©hicules - par le cot√©\nPlein jour\nNormale\nVoie Communale\nNaN\n2.0\nPlat\nPartie rectiligne\nNaN\nNaN\nnormale\nNaN\nSur bande d‚Äôarr√™t d‚Äôurgence\nConducteur\n1 - Bless√© l√©ger\nM\n25-26\nDomicile - travail\nCasque\nOui\nNaN\nV√©hicule\nAvant\nM√™me sens, m√™me file\n201800057521B01\nVL seul\nTournant √† gauche\n1.0\n\n\n2018-03-21 18:00:00\n201800057582\n03 - mars\n2 - mercredi\n976\n97611\n-12.76833\n45.22532\noui\nAutre intersection\nDeux v√©hicules - par l‚Äôarri√®re\nCr√©puscule ou aube\nNormale\nRoute Nationale\nNaN\n2.0\nPlat\nPartie rectiligne\nNaN\nNaN\nnormale\nNaN\nSur chauss√©e\nConducteur\n1 - Bless√© l√©ger\nM\n30-31\nAutre\nCasque\nOui\nNaN\nV√©hicule\nAvant gauche\nEn s‚Äôins√©rant\n201800057582B01\nVL seul\nM√™me sens, m√™me file\n1.0\n\n\n2018-03-31 17:00:00\n201800057587\n03 - mars\n5 - samedi\n976\n97611\n-12.78604\n45.22107\noui\nHors intersection\nDeux v√©hicules - par le cot√©\nCr√©puscule ou aube\nNormale\nVoie Communale\nNaN\n2.0\nSommet de c√¥te\nPartie rectiligne\nNaN\nNaN\nnormale\nNaN\nSur chauss√©e\nConducteur\n1 - Bless√© l√©ger\nM\n12-13\nAutre\nAutre\nNon d√©terminable\nNaN\nV√©hicule\nC√¥t√© gauche\nNaN\n201800057587B01\nVL seul\nD√©passant √† gauche\n1.0\n\n\n2018-03-31 17:00:00\n201800057587\n03 - mars\n5 - samedi\n976\n97611\n-12.78604\n45.22107\noui\nHors intersection\nDeux v√©hicules - par le cot√©\nCr√©puscule ou aube\nNormale\nVoie Communale\nNaN\n2.0\nSommet de c√¥te\nPartie rectiligne\nNaN\nNaN\nnormale\nNaN\nSur chauss√©e\nPassager\n1 - Bless√© l√©ger\nM\n4-5\nAutre\nAutre\nNon d√©terminable\nNaN\nV√©hicule\nC√¥t√© gauche\nNaN\n201800057587B01\nVL seul\nD√©passant √† gauche\n1.0\n\n\n2018-07-31 11:00:00\n201800057676\n07 - juillet\n1 - mardi\n976\n97611\n-12.77302\n45.22106\noui\nHors intersection\nAutre\nPlein jour\nNormale\nVoie Communale\nNaN\n2.0\nPlat\nPartie rectiligne\nNaN\nNaN\nnormale\nNaN\nSur accotement\nPi√©ton\n1 - Bless√© l√©ger\nM\n3-4\nNaN\nDispositif enfants\nNaN\nNaN\nPi√©ton\nAvant\nNaN\n201800057676A01\nNaN\nNaN\nNaN\n\n\n\n\n65515 rows √ó 37 columns\n\n\n\n\n# Chargement des couleurs\nsns.set_palette(\"GnBu_d\", n_colors=7)\n\ndf_bikes['weekday'] = df_bikes.index.day_of_week  # Monday=0, Sunday=6\n\naccidents_week = df_bikes.groupby(['weekday', df_bikes.index.hour])[\n    'sexe'].count().unstack(level=0)\n\nfig, axes = plt.subplots(1, 1, figsize=(7, 7))\naccidents_week.plot(ax=axes)\naxes.set_ylabel(\"Accidents\")\naxes.set_xlabel(\"Heure de la journ√©e\")\naxes.set_title(\n    \"Profil journalier des accidents: effet du weekend?\")\naxes.set_xticks(np.arange(0, 24))\naxes.set_xticklabels(np.arange(0, 24), rotation=45)\naxes.legend(\n    labels=[day for day in calendar.day_name],\n    loc='upper left',\n    )\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\ndf_bikes.groupby(['weekday', df_bikes.index.hour])[\n    'sexe'].count()\n\nweekday  Time\n0        1        20\n         2         4\n         3         3\n         4        20\n         5        41\n                ... \n6        19      340\n         20      217\n         21      122\n         22       67\n         23       59\nName: sexe, Length: 161, dtype: int64\n\n\n\n\n\n\n\n\nEXERCISE: Accident during the year\n\n\n\nPerform an analysis to check when the accidents are occurring during the week.\n\n\n\ndf_bikes['month'] = df_bikes.index.month  # Janvier=0, .... Decembre=11\ndf_bikes['month'] = df_bikes['month'].apply(lambda x: calendar.month_abbr[x])\ndf_bikes.head()\n\nsns.set_palette(\"GnBu_d\", n_colors=12)  # sns.set_palette(\"colorblind\",...)\n\ndf_bikes_month = df_bikes.groupby(['month', df_bikes.index.hour])[\n    'age'].count().unstack(level=0)\n\nfig, axes = plt.subplots(1, 1, figsize=(7, 7), sharex=True)\n\ndf_bikes_month.plot(ax=axes)\naxes.set_ylabel(\"Concentration (¬µg/m¬≥)\")\naxes.set_xlabel(\"Heure de la journ√©e\")\naxes.set_title(\n    \"Profil journalier de la pollution au NO2: effet du weekend?\")\naxes.set_xticks(np.arange(0, 24))\naxes.set_xticklabels(np.arange(0, 24), rotation=45)\naxes.legend(labels=calendar.month_name[1:], loc='upper left')\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEXERCISE: Accidents by department\n\n\n\nPerform an analysis to check when the accidents are occurring for each department, relative to population size.\n\n\n\npath_target = \"./dpt_population.csv\"\nurl = \"https://public.opendatasoft.com/explore/dataset/population-francaise-par-departement-2018/download/?format=csv&timezone=Europe/Berlin&lang=en&use_labels_for_header=true&csv_separator=%3B\"\npath, fname = os.path.split(path_target)\npooch.retrieve(url, path=path, fname=fname, known_hash=None)\n\n'/home/jsalmon/Documents/Mes_cours/Montpellier/HAX712X/Courses/Pandas/dpt_population.csv'\n\n\n\ndf_dtp_pop = pd.read_csv(\"dpt_population.csv\", sep=\";\", low_memory=False)\n\ndf_dtp_pop['Code D√©partement'].replace('2A', '20A',inplace=True)\ndf_dtp_pop['Code D√©partement'].replace('2B', '20B',inplace=True)\ndf_dtp_pop.sort_values(by=['Code D√©partement'], inplace=True)\n\ndf_bikes['departement'].replace('2A', '20A',inplace=True)\ndf_bikes['departement'].replace('2B', '20B',inplace=True)\ndf_bikes.sort_values(by=['departement'], inplace=True)\n# Clean extra departements\ndf_bikes = df_bikes.loc[df_bikes['departement'].isin(df_dtp_pop['Code D√©partement'].unique())]\n\ngd = df_bikes.groupby(['departement'], as_index=True, sort=True).size()\n\ndata = {'code': gd.index,\n        '# Accidents per million': gd.values}\ndf = pd.DataFrame(data)\ndf['# Accidents per million'] = df['# Accidents per million'].values * 10000./ df_dtp_pop['Population'].values\n\n\npath_target = \"./departements-avec-outre-mer.geojson\"\nurl = \"https://raw.githubusercontent.com/gregoiredavid/france-geojson/master/departements-avec-outre-mer.geojson\"\npath, fname = os.path.split(path_target)\npooch.retrieve(url, path=path, fname=fname, known_hash=None)\n\n'/home/jsalmon/Documents/Mes_cours/Montpellier/HAX712X/Courses/Pandas/departements-avec-outre-mer.geojson'\n\n\n\nimport plotly.express as px\nimport geopandas\n\ndepartement = geopandas.read_file('departements-avec-outre-mer.geojson')\ndepartement['code'].replace('2A', '20A', inplace=True)\ndepartement['code'].replace('2B', '20B', inplace=True)\n\ndepartement.sort_values(by=['code'], inplace=True)\n\na = ['0'+ str(i) for i in range(1, 10)]\nb = [str(i) for i in range(1, 10)]\ndict_replace = dict(zip(a, b))\n\ndepartement['code'].replace(dict_replace, inplace=True)\ndf['code'].replace(dict_replace, inplace=True)\n\ndepartement['code'].replace('20A', '2A', inplace=True)\ndepartement['code'].replace('20B', '2B', inplace=True)\ndf['code'].replace('20A', '2A',inplace=True)\ndf['code'].replace('20B', '2B',inplace=True)\n\ndepartement.set_index('code', inplace=True)\n\nfig = px.choropleth_mapbox(\n    df,\n    geojson=departement,\n    locations=\"code\",\n    color=\"# Accidents per million\",\n    range_color=(0, df['# Accidents per million'].max()),\n    color_continuous_scale=\"rdbu\",\n    center={'lat': 47, 'lon': 2},\n    zoom=3.25,\n    mapbox_style=\"white-bg\",\n)\nfig.update_traces(colorbar_orientation='h', selector=dict(type='choroplethmapbox'))\nfig.update_layout(\n    title_text = 'Accidents per million inhabitants by department',\n)\nfig.layout.coloraxis.colorbar.thickness = 20\nfig.layout.coloraxis.colorbar.orientation = 'h'\nfig.layout.coloraxis.colorbar.y = -0.2\nfig.layout.coloraxis.colorbar.x = 0.2\n\nfig.show()\n\n\n\n\n                                                \n\n\n\n\n\n\n\n\n\n\nEXERCISE: Accidents by department\n\n\n\nPerform an analysis to check when the accidents are occurring for each department, relative to the area of the departements.\n\n\nReferences:\n\nOther interactive tools for data visualization: Altair, Bokeh. See comparisons by Aarron Geller: link\nAn interesting tutorial: Altair introduction\nIntroduction on geopandas\nNotebook on French departememen/womennts issues\nChoropleth Maps in practice with Plotly and Python by Thibaud Lamothe\nEuropean data on France geography"
  },
  {
    "objectID": "Courses/Git/tp.html",
    "href": "Courses/Git/tp.html",
    "title": "Version control with Git",
    "section": "",
    "text": "On a terminal, specify the email address with which you will make your commits:\n$ git config --global user.email \"prenom.nom@domaine.fr\"\nOf course Adapt the email address prenom.nom@domaine.fr to your case!.\nYou may also (optional) configure another option (yet mysterious)\n$ git config --global pull.rebase false"
  },
  {
    "objectID": "Courses/Git/tp.html#setting-your-git-environment",
    "href": "Courses/Git/tp.html#setting-your-git-environment",
    "title": "Version control with Git",
    "section": "",
    "text": "On a terminal, specify the email address with which you will make your commits:\n$ git config --global user.email \"prenom.nom@domaine.fr\"\nOf course Adapt the email address prenom.nom@domaine.fr to your case!.\nYou may also (optional) configure another option (yet mysterious)\n$ git config --global pull.rebase false"
  },
  {
    "objectID": "Courses/Git/tp.html#create-an-ssh-key",
    "href": "Courses/Git/tp.html#create-an-ssh-key",
    "title": "Version control with Git",
    "section": "Create an SSH key",
    "text": "Create an SSH key\n\nUnix system\nThe SSH is needed to get a smooth authentication to the remote repository. In a terminal:\n$ ssh-keygen -t rsa -b 4096 -C prenom.nom@domaine.fr\nAccept the default option (keys saved in ~/.ssh and no passphrase)\nssh-add\nReference: Github docs on connecting with SSH.\n\n\nWindows\nReference: The Server Side: How to SSH into GitHub on Windows example, by Cameron McKenzie"
  },
  {
    "objectID": "Courses/Git/tp.html#create-a-remote-repository",
    "href": "Courses/Git/tp.html#create-a-remote-repository",
    "title": "Version control with Git",
    "section": "Create a remote repository",
    "text": "Create a remote repository\nLet us create a remote repository hosted on your GitHub account.\nOn GitHub, click on the + symbol at the top right of the page, then New repository. Give the name FirstRepo to your new project and a short description.\nCreate a public repository, meaning that everyone can access your code (read-only). Finish by clicking on Create repository.\nFollow the instructions provided by GitHub to create your local copy of the repository:\n\nCreate a new folder called FirstRepo in your home directory and cd to it\nThen execute the following command changing the XXXXXXXXXXX with the relevent URL.\necho \"# FirstRepo\" &gt;&gt; README.md\ngit init\ngit add README.md\ngit commit -m \"first commit\"\ngit branch -M main\ngit remote add origin git@github.com:XXXXXXXXXXXXXXXXXX/FirstRepo.git\ngit push --set-upstream  origin main\n\n\n\n\n\n\n\nEXERCISE: gitignore\n\n\n\n\nCreate a text file called .gitignore¬†with the following content:\n\n*.pdf\n*~\n\nCreate a commit and push it to your repository. What is the purpose of this file? See https://github.com/github/gitignore"
  },
  {
    "objectID": "Courses/Git/tp.html#using-an-existing-repository",
    "href": "Courses/Git/tp.html#using-an-existing-repository",
    "title": "Version control with Git",
    "section": "Using an existing repository",
    "text": "Using an existing repository\nBrowse the repository at https://github.com/bcharlier/HAX712X_2023. What is this module able to do?\n\n\n\n\n\n\nEXERCISE: Forking a Git repo\n\n\n\nFork the repository by following these steps:\n\nOn GitHub, click on the fork icon.\nA copy is added to your GitHub space. Clone it (this copy!) to get a local repository.\nIn a terminal, inspect the output of the command git remote get-url origin"
  },
  {
    "objectID": "Courses/Git/tp.html#debugging",
    "href": "Courses/Git/tp.html#debugging",
    "title": "Version control with Git",
    "section": "Debugging",
    "text": "Debugging\nA bug has appeared in the Python module after a commit. An issue has been opened in the bug tracking system at https://github.com/bcharlier/HAX712X_2023/issues/. Your goal is to find the problem‚Ä¶ and then fix it on your forked repository. Finally, you will be able to submit a Pull Request to the original repository to share your fix.\n\nIdentification of the bad commit\nYour goal is to identify the commit(s) that caused the bug. Use git log, git diff, git checkout to identify the commit responsible for the problem.\nReference: Git Bisect\n\n\nCreate a new branch to fix the problem\nTo fix a complex bug or add a new feature, it is often necessary to modify several parts of the code. We create a branch, where we make all the commits dedicated to solving the bug. The idea is to maintain a stable version, in the branch main, separated from the developing version, which may contain bugs.\n\n\n\n\n\n\nEXERCISE: branches\n\n\n\n\nCreate a local branch Fix_EOL_Error\nPush this local branch to your remote repo.\nSwitch to the Fix_EOL_Error branch, and fix the bugs. The branch main will not be affected.\nMerge the fix into the branch main\nDelete the local branch Fix_EOL_Error and the remote origin/Fix_EOL_Error branch\n\n\n\n\n\nPull request\nYour work about bug fixing may interest the original author of the project. On GitHub, open a pull-request (PR). PRs are a set of commits that can be integrated directly by the author of the project in its repository and are thus a powerful tool for working with others."
  },
  {
    "objectID": "Courses/Git/tp.html#branch-merging-and-solving-conflicts",
    "href": "Courses/Git/tp.html#branch-merging-and-solving-conflicts",
    "title": "Version control with Git",
    "section": "Branch Merging and Solving conflicts",
    "text": "Branch Merging and Solving conflicts\n\n\n\n\n\n\nEXERCISE: Conflicts identification\n\n\n\n\nSwitch to the branch NonGaussian. Try to figure out what has changed compared to the main branch.\nTry to merge the branch NonGaussian to the branch main.\nWhere are located the conflicts? They are shown with the following decorator.\n\n&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD\nSome code on the current branch\n=======\n\nSome code on the branch to be merged\n&gt;&gt;&gt;&gt;&gt;&gt;&gt; NonGaussian\n\nResolve them by plotting the two histograms on the same plot. Namely, produce a figure like this:"
  },
  {
    "objectID": "Courses/CI/tp.html",
    "href": "Courses/CI/tp.html",
    "title": "Continuous Integration",
    "section": "",
    "text": "In software engineering, continuous integration (CI) is the practice of merging all developers‚Äô working copies to a shared mainline regularly. It is often split into 3 steps:\n\nautomate the tests: run command on each commit (or each Pull Request), typically unit tests and integration tests.\nautomate the build: when dealing with a compiled language, compile the source to generate binaries. I can also build the documentation.\nautomate the deployment: send the binaries to the repository or generate a website, etc‚Ä¶\n\nA CI pipeline runs commands on some virtual machine automatically.\nReferences:\n\nGithub actions doc\n\n\nBenefits of CI\n\nOne can not forget to run tests and immediate feedback is provided: it runs at each commit or Pull Request. A report is sent to the author of the commit.\nProtects the master branch: commit or PR can be rejected if the test does not pass.\nContributor doesn‚Äôt need to know details: only the project maintainers need to know how the system works.\nCan enforce style: A linter can run to check PEP8.\nCan check the code on many systems: virtual machines can run Linux, Windows or MacOs systems.\n\n\n\nWhat do you need?\nMany solutions exist to run CI pipelines (Gitlab, Github, Jenkins, TravisCI, Appveyor, Azure Pipelines, CircleCI‚Ä¶). They all:\n\nRun a test when a web-hook is triggered (usually at each push or PR).\nCan act as a build-farm (for binaries or documentation) on a ‚Äúbuild matrix‚Äù (i.e., run on many environments).\nRequires clear declaration of dependencies and a set-up virtual machine (that should be maintained).\nReports success/Failure to the CSV.\n\n\n\nExample\nGitHub has recently developed a high-level solution of CI. Before digging into the process, please make sure that your test file is working locally. You should have something like:\n$ pytest\n=========================== test session starts ============================\nplatform linux -- Python 3.7.6, pytest-5.3.5, py-1.8.1, pluggy-0.13.1\nrootdir: /home/bcharlier/packaging_tutorial\nplugins: cov-2.8.1\ncollected 3 items\n\nbiketrauma/tests/test_biketrauma.py ...                                  [100%]\n\n============================ warnings summary ==============================\n/home/bcharlier/.local/lib/python3.7/site-packages/pygal/_compat.py:23\n  /home/bcharlier/.local/lib/python3.7/site-packages/pygal/_compat.py:23: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working\n    from collections import Iterable\n\n-- Docs: https://docs.pytest.org/en/latest/warnings.html\n======================= 3 passed, 1 warning in 1.56s ======================\n\nAdd a .github/workflows file\nSetting up a CI is rather easy. It is sufficient to add a single text file .github/workflows in your project. Github has developed a graphical user interface to do it:\n\nIn your GitHub project repository: Go to the Actions menu and then select python package workflow.\nCustomize the workflows file depending on your needs. Beware: getting a correct configuration file is sometimes tedious with CI system‚Ä¶\nYou can add a badge showing the result of CI to the end-user directly in your Readme.md.\n\n\n\n\n\n\n\nEXERCISE: Setting up CI tools.\n\n\n\n\nFork the biketrauma project https://github.com/HMMA238-2020/biketrauma\nSetup a CI with github on biketrauma\n\n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "HAX712X: Software development for data science",
    "section": "",
    "text": "(Almost) everything you need to know as an applied mathematician/statistician concerning coding and system administration.\n\n\n\nJoseph Salmon: joseph.salmon@umontpellier.fr,\nBenjamin Charlier: benjamin.charlier@umontpellier.fr\n\nThis course material was improved with the help of some students including:\n\nAmelie Vernay\nTanguy Lefort\n\n\n\n\nStudents are expected to know basic notions of probabilities, optimization, linear algebra and statistics for this course. Some rudiments in coding are also expected (if, for, while, functions) but not mandatory.\n\n\n\nThis course focuses on discovering good coding practices (the language used is Python, but some elements of bash and git will also be useful) for professional coding. A special focus on data processing and visualization will be at the heart of the course. We will mostly focus on basic programming concepts, as well as on discovering the Python scientific libraries, including numpy, scipy, pandas, matplotlib, seaborn. Beyond pandas ninja skills, we will also introduce modern practices for coders: (unitary) tests, version control, documentation generation, etc.\n\n\n\n\nDate\nTeacher\nDetails\n\n\n\n\n11/09/2023\nBC\nCommand-line tools\n\n\n22/09/2023\nBC\nVersion control with Git\n\n\n29/09/2023\nBC\nIDE / Python virtual environment\n\n\n06/10/2023\nBC+JS\nCreating a Python Module, Classes & Exceptions\n\n\n13/10/2023\nJS\nMarkdown to html (Quarto, Sphinx,‚Ä¶), Continuous Integration (CI)\n\n\n20/10/2023\nJS\nPandas\n\n\n27/10/2023\nBC\nUnit Tests\n\n\n10/11/2023\nJS\nSciPy\n\n\n17/11/2023\nJS\nTime & memory efficiency\n\n\n20/11/2023\nJS\nGraphs\n\n\n15/12/2023\nBC+JS\nThe end: Project presentations\n\n\n\n\n\n\nFor this course, the grading consists of two projects: one group project (group composition available on Moodle) and a personal one.\nPlease carefully read the projects description page.\n\n\n1 supplementary point on the final grade of the course can be obtained for contributions to improve the course material (practicals, Readme, etc.). See the Bonus section for more details on how to proceed.\n\n\n\n\nThe resources for the course are available on the present GitHub repository. Additional elementary elements (in French) on Python are available in the course HLMA310 and the associated lecture notes IntroPython.pdf.\n\n\nThe Moodle web page is available to registered students only.\n\n\n\n\n(General): The Missing Semester of Your CS Education\n(Algorithmic basis): Algorithms, by Jeff Erickson\n(Data Science): Python Data Science Handbook, With Application to Understanding Data by J. Van DerPlas, 2016; videos: Reproducible Data Analysis in Jupyter\n(General) Skiena, The algorithm design manual, 1998\n(General) Courant et al., Informatique pour tous en classes pr√©paratoires aux grandes √©coles: Manuel d‚Äôalgorithmique et programmation structur√©e avec Python, 2013, (french)\n(General/data science) Guttag, Introduction to Computation and Programming, 2016\n(Code and style) Boswell et Foucher, The Art of Readable Code, 2011\n(Scientific computing tools for Python) Scipy lectures notes\n(Datasets) Open Climate Data"
  },
  {
    "objectID": "index.html#teachers",
    "href": "index.html#teachers",
    "title": "HAX712X: Software development for data science",
    "section": "",
    "text": "Joseph Salmon: joseph.salmon@umontpellier.fr,\nBenjamin Charlier: benjamin.charlier@umontpellier.fr\n\nThis course material was improved with the help of some students including:\n\nAmelie Vernay\nTanguy Lefort"
  },
  {
    "objectID": "index.html#prerequisite",
    "href": "index.html#prerequisite",
    "title": "HAX712X: Software development for data science",
    "section": "",
    "text": "Students are expected to know basic notions of probabilities, optimization, linear algebra and statistics for this course. Some rudiments in coding are also expected (if, for, while, functions) but not mandatory."
  },
  {
    "objectID": "index.html#course-description",
    "href": "index.html#course-description",
    "title": "HAX712X: Software development for data science",
    "section": "",
    "text": "This course focuses on discovering good coding practices (the language used is Python, but some elements of bash and git will also be useful) for professional coding. A special focus on data processing and visualization will be at the heart of the course. We will mostly focus on basic programming concepts, as well as on discovering the Python scientific libraries, including numpy, scipy, pandas, matplotlib, seaborn. Beyond pandas ninja skills, we will also introduce modern practices for coders: (unitary) tests, version control, documentation generation, etc.\n\n\n\n\nDate\nTeacher\nDetails\n\n\n\n\n11/09/2023\nBC\nCommand-line tools\n\n\n22/09/2023\nBC\nVersion control with Git\n\n\n29/09/2023\nBC\nIDE / Python virtual environment\n\n\n06/10/2023\nBC+JS\nCreating a Python Module, Classes & Exceptions\n\n\n13/10/2023\nJS\nMarkdown to html (Quarto, Sphinx,‚Ä¶), Continuous Integration (CI)\n\n\n20/10/2023\nJS\nPandas\n\n\n27/10/2023\nBC\nUnit Tests\n\n\n10/11/2023\nJS\nSciPy\n\n\n17/11/2023\nJS\nTime & memory efficiency\n\n\n20/11/2023\nJS\nGraphs\n\n\n15/12/2023\nBC+JS\nThe end: Project presentations"
  },
  {
    "objectID": "index.html#grading",
    "href": "index.html#grading",
    "title": "HAX712X: Software development for data science",
    "section": "",
    "text": "For this course, the grading consists of two projects: one group project (group composition available on Moodle) and a personal one.\nPlease carefully read the projects description page.\n\n\n1 supplementary point on the final grade of the course can be obtained for contributions to improve the course material (practicals, Readme, etc.). See the Bonus section for more details on how to proceed."
  },
  {
    "objectID": "index.html#books-and-other-resources",
    "href": "index.html#books-and-other-resources",
    "title": "HAX712X: Software development for data science",
    "section": "",
    "text": "The resources for the course are available on the present GitHub repository. Additional elementary elements (in French) on Python are available in the course HLMA310 and the associated lecture notes IntroPython.pdf.\n\n\nThe Moodle web page is available to registered students only.\n\n\n\n\n(General): The Missing Semester of Your CS Education\n(Algorithmic basis): Algorithms, by Jeff Erickson\n(Data Science): Python Data Science Handbook, With Application to Understanding Data by J. Van DerPlas, 2016; videos: Reproducible Data Analysis in Jupyter\n(General) Skiena, The algorithm design manual, 1998\n(General) Courant et al., Informatique pour tous en classes pr√©paratoires aux grandes √©coles: Manuel d‚Äôalgorithmique et programmation structur√©e avec Python, 2013, (french)\n(General/data science) Guttag, Introduction to Computation and Programming, 2016\n(Code and style) Boswell et Foucher, The Art of Readable Code, 2011\n(Scientific computing tools for Python) Scipy lectures notes\n(Datasets) Open Climate Data"
  },
  {
    "objectID": "Courses/Bash/tp.html",
    "href": "Courses/Bash/tp.html",
    "title": "Command-line tools",
    "section": "",
    "text": "Every Operating System (Linux, MacOS, Windows, ‚Ä¶) comes with a program able to interpret and run command lines.\n\nThe shell is the program that processes commands and returns output, e.g., Bash, zsh, etc‚Ä¶\nA terminal refers to a wrapper program that runs a shell.\nThe console is a special sort of terminal (low-level).\n\nReference: super user: shell, console and terminal\n\n\n\nAs you already know, the bash prompt is a $ sign when you are a standard user. When you are an administrator (often called root user) the prompt is a #.\n\n\n\n\n\n\nEXERCISE: recognize different prompts\n\n\n\nFind the different prompts for R, Python and the terminal on Windows"
  },
  {
    "objectID": "Courses/Bash/tp.html#preamble",
    "href": "Courses/Bash/tp.html#preamble",
    "title": "Command-line tools",
    "section": "",
    "text": "Every Operating System (Linux, MacOS, Windows, ‚Ä¶) comes with a program able to interpret and run command lines.\n\nThe shell is the program that processes commands and returns output, e.g., Bash, zsh, etc‚Ä¶\nA terminal refers to a wrapper program that runs a shell.\nThe console is a special sort of terminal (low-level).\n\nReference: super user: shell, console and terminal\n\n\n\nAs you already know, the bash prompt is a $ sign when you are a standard user. When you are an administrator (often called root user) the prompt is a #.\n\n\n\n\n\n\nEXERCISE: recognize different prompts\n\n\n\nFind the different prompts for R, Python and the terminal on Windows"
  },
  {
    "objectID": "Courses/Bash/tp.html#the-unix-directory-structure",
    "href": "Courses/Bash/tp.html#the-unix-directory-structure",
    "title": "Command-line tools",
    "section": "The Unix directory structure",
    "text": "The Unix directory structure\nReference: The Linux Directory Structure, Explained, by Chris Hoffman.\nSome aliases:\n\n~ is an alias to your home directory.\n. is an alias to the current directory.\n.. is an alias to the parent directory.\n\nFor instance,\n$ cd ~\n$ pwd\n$ cd ../../home/../etc/../home/\n$ pwd\n\n\n\n\n\n\nEXERCISE:\n\n\n\n\nWhat is the difference between cd ./toto/tata, cd toto/tata, cd ~/toto/tata and cd /toto/tata\nUse the which command to determine which instance of Python is used when you use the python command. Same question with python2."
  },
  {
    "objectID": "Courses/Bash/tp.html#getting-help",
    "href": "Courses/Bash/tp.html#getting-help",
    "title": "Command-line tools",
    "section": "Getting help",
    "text": "Getting help\nTo get some help on a command, please use the man command. You may also use the --help option as in\n$ man ls\n$ ls --help"
  },
  {
    "objectID": "Courses/Bash/tp.html#paging-programs",
    "href": "Courses/Bash/tp.html#paging-programs",
    "title": "Command-line tools",
    "section": "Paging programs",
    "text": "Paging programs\nA paging program displays, one windowful at a time, the contents of a file on a terminal. It pauses after each windowful and prints on the window status line, the screen, the file name, the current line number, and the percentage of the file so far displayed. This is not an editor (no modification of the file can be done).\nmore (deprecated) less (best choice) most (default on your machine, more features than less, but bad keybindings).\n$ man less\n$ man most\nUseful tips:\n\nTo search for a word type s. To go to the next (resp. previous) occurrence type n (resp. N).\n[less only]¬†to go down type j, to go up type k.\nTo go to the beginning of a file, type g, to the end G.\nTo quit type q.\nto change the default paging program to less.\n$ export MANPAGER=less\n\nReference: What are the differences between most, more and less? on StackExchange."
  },
  {
    "objectID": "Courses/Bash/tp.html#pattern-matching-part-i-pathname-expansion-a.k.a.-globbing",
    "href": "Courses/Bash/tp.html#pattern-matching-part-i-pathname-expansion-a.k.a.-globbing",
    "title": "Command-line tools",
    "section": "Pattern matching (part I): Pathname expansion (a.k.a. globbing)",
    "text": "Pattern matching (part I): Pathname expansion (a.k.a. globbing)\nIt is often very useful to select some files whose filename contains (or not!) a specific pattern. Shells (bash, zsh, etc.) come with a ‚Äúpattern matching‚Äù syntax allowing us to express such constraints on the filenames.\nThis syntax is commonly called globs and is quite simple (more advanced syntaxes called regexp will be introduced later on). globs are shell commands and can be transmitted to various programs (ls, grep, find, etc‚Ä¶). For instance to display all the files with an extension in .txt in the current directory:\n$ ls *.txt\nMost shells have similar glob rules, and they usually consist of:\n\nA marker for zero-or-more characters: *\nA marker for exactly one character: ?\nA way to express one of a certain set of characters: [...]\nA way to express a choice of one or more strings: {...,...}\nA way to escape any of the above special characters: \\\n\n\n\n\n\n\n\nEXERCISE: listing\n\n\n\n\nGo to /usr/lib/R/bin/ and list every file starting with the letter R and containing i\nGo to /usr/lib/R/bin/ and list every file containing the letter c, then any character, and then an n (e.g.¬†config or javareconf)\nGo to /var/log/ and list every file with a double extension: the former one is a dot followed by a number, and the last one is .log (e.g.¬†Xorg.3.log or Xorg.0.log)\nGot to /var/log/ and list every file with a name starting with an a and containing at least a digit"
  },
  {
    "objectID": "Courses/Bash/tp.html#listing-files",
    "href": "Courses/Bash/tp.html#listing-files",
    "title": "Command-line tools",
    "section": "Listing files",
    "text": "Listing files\nTo list the files in a folder use the command ls.\n\n\n\n\n\n\nEXERCISE: ls options\n\n\n\n\nDescribe the option -a.\nDescribe the option -R.\nDescribe the option -lh.\nList all the files in the directory /usr/lib/ without cd in it.\n\n\n\nThe file command can be used to display the information of a file (if not given by the extension itself).\n\n\n\n\n\n\nEXERCISE: ls on a directory\n\n\n\n\nList all the files in the directory /usr/lib/R/bin and sort them by size.\nDisplay the type information of the files in /var/log/ with one call to file."
  },
  {
    "objectID": "Courses/Bash/tp.html#symbolic-links",
    "href": "Courses/Bash/tp.html#symbolic-links",
    "title": "Command-line tools",
    "section": "Symbolic links",
    "text": "Symbolic links\nA symbolic link or symlink is a special file containing a link to another file or directory. For instance, try\n$ ls -l /usr/bin\nA symlink can be created with the command ln.\n$ ln -s target_path link_path\nObviously, replace target_path and link_path by their corresponding values.\n\n\n\n\n\n\nEXERCISE: symlink\n\n\n\n\nCreate a symlink called my_etc_dir_link pointing to /etc in your home directory.\nThen compare the output of ls /etc and ls ~/my_etc_dir_link"
  },
  {
    "objectID": "Courses/Bash/tp.html#users",
    "href": "Courses/Bash/tp.html#users",
    "title": "Command-line tools",
    "section": "Users",
    "text": "Users\nTo list the groups you belong to, in a terminal use the command\n$ groups\nTo list the connected user on your machine\n$ w\n$ who"
  },
  {
    "objectID": "Courses/Bash/tp.html#file-permissions",
    "href": "Courses/Bash/tp.html#file-permissions",
    "title": "Command-line tools",
    "section": "File permissions",
    "text": "File permissions\nEach file has an owner (a user) and a group (a group of users). To change the user that owns use chown and to change the group use chgrp. There are 3 types of permissions:\n\nread r\nwrite w\nexecute x\n\nThere are three permissions triads\n\nFirst triad: what the user can do (the letter u)\nSecond triad: what the group members can do (the letter g)\nThird triad: what other users can do (the letter o)\n\nEach triad\n\nTirst character r: readable\nSecond character w: writable\nThird character x: executable\n\nTo change the permissions of a file, use the chmod. For instance, to add execution x right to the owner u:\n$ chmod u+x toto.txt\n\n\n\n\n\n\nEXERCISE: permissions\n\n\n\n\nCreate an empty file called foo.py in the current directory\nDisplay its owner, group and permissions\nChange the group of foo.py to pulse\nAdd read and write permissions to users in the group pulse\n\n\n\nReference: File system permission on Wikipedia. See also chown and chgrp."
  },
  {
    "objectID": "Courses/Bash/tp.html#environment-variables",
    "href": "Courses/Bash/tp.html#environment-variables",
    "title": "Command-line tools",
    "section": "Environment variables",
    "text": "Environment variables\nAn environment variable (in short env or envs) is a dynamic-named value that can affect the way running processes will behave on a computer. Many options of bash may be changed with the command envs. To print all the defined envs:\n$ printenv\nTo display a single variable, you may use the prefix $. For instance, to display the content of PATH\n$ echo ${PATH}\nTo set a new variable (in bash)\n$ export ENV_NAME=toto:tata\nLists are often separated by :. To append a new value at the end\n$ export ENV_NAME=${ENV_NAME}:tutu\n$ echo ${ENV_NAME}\nReference: How To Read and Set Environmental and Shell Variables on Linux by Justin Ellingwood.\n\n\n\n\n\n\nEXERCISE: path\n\n\n\n\nDisplay the PATH env\nIs the order of the list important?\n\n\n\nUseful tips: To avoid setting up an env every time you open a terminal, you can append the export MYENV=xxxxx command to the ~/.bashrc¬†file.\n\nText editor\nIn bash, many configuration files are in fact text files. You may need to choose a text editor to modify them. Very powerful (and thus complicated) text editors exist: emacs, vim, but we will focus on nano (gedit is another alternative):\n$ nano\nor joe (default on your system).\n\n\n\n\n\n\nEXERCISE: default editor\n\n\n\n\nSet nano as your default text editor\n\n\n\n\n\nUseful unix commands\n\nList files and get information: ls, file, find\nDisplay text content: echo, cat, head, tail, grep, fgrep, rgrep\nFile handling: touch, mv, cp, rsync, rename\nUnix admin: which, who, top, htop, kill, pkill, killall"
  },
  {
    "objectID": "Courses/Bash/tp.html#system",
    "href": "Courses/Bash/tp.html#system",
    "title": "Command-line tools",
    "section": "System",
    "text": "System\n\nGetting system information\nTo display the system information\n$ uname -a\nTo show the system hostname you may use hostname command.\nTo show information about your processor use lscpu and to list the devices connected to your machine use lspci.\n\n\n\n\n\n\nEXERCISE: hardware info\n\n\n\n\nDetermine how many physical cores you have on your machine.\nDetermine the vendor of the network card of your machine.\n\n\n\n\n\nProcess\nHere we learn how to use ps, top, htop, kill, pkill, etc.\nReference: Tutorials Point: Unix/Linux - Process management\n\n\n\n\n\n\nEXERCISE: Linux shortcuts\n\n\n\n\nDescribe the effect of Ctrl+C in a terminal\nDescribe the effect of Ctrl+Z in a terminal\nDescribe the effect of Ctrl+D in a terminal"
  },
  {
    "objectID": "Courses/Bash/tp.html#display-text-content",
    "href": "Courses/Bash/tp.html#display-text-content",
    "title": "Command-line tools",
    "section": "Display text content",
    "text": "Display text content\n\nGet the data\nThe dataset we are going to use is a modified version of the dataset available on the data.gouv.fr platform. We will focus on bicycle accidents in France between 2011 and 2018.\n\n\n\n\n\n\nEXERCISE: downloading using command lines\n\n\n\n\nCreate a folder data_bicycle and cd to it.\nDownload the compressed database (this is a .xz file) available at the following URL: as bicycle_db.csv.xz (use the option -O of wget).\nUncompress the .xz file using the xz command (use documentation!)\n\n\n\n\n\nText commands: tail, head, cat, wc and split\nPlease read the manual of tail, head, cat, wc and split\n\n\n\n\n\n\nEXERCISE: data analysis in bash\n\n\n\n\nUse the word count wc command to display the number of lines of bicycle_db.csv\nDisplay the 53 first line with the head command. Same with the 30 last lines (see tail)\nUse the split command and its options -d -l and --additional-suffix to create files with a maximum number of lines of 10000 (e.g., : if the number of lines is 55379, you should get only 6 files with names bike00.csv, ‚Ä¶, bike05.csv)\n\n\n\n\n\nThe grep command\ngrep prints lines of a file matching a pattern (regex).\n$ man grep\n\n\n\n\n\n\nEXERCISE: grep\n\n\n\n\nCount the number of accidents in 2015 using the command grep (hint: remarks that each line starts with the string \"YYYY where YYYY is the year)\nDisplay the line number of the accident occurring on a Wednesday, in October 2017 using a regular expression.\n\n\n\n\n\nThe find command\nThe find command searches for files in a directory hierarchy. Read the manual. For instance, the following command lists all the files in /usr/lib/ containing the qt5 string in its name:\n$ find /usr/lib/ -name \"*qt5*\" -type f\n\n\n\n\n\n\nEXERCISE: permission on files\n\n\n\n\nWhat is the aim of the -exec option?\nChange the permissions of any file with extensions .csv in your home to 777\n\n\n\nReference: TecMint, 35 Practical Examples of Linux Find Command"
  },
  {
    "objectID": "Courses/Bash/tp.html#pipes-and-redirections",
    "href": "Courses/Bash/tp.html#pipes-and-redirections",
    "title": "Command-line tools",
    "section": "Pipes and redirections",
    "text": "Pipes and redirections\n\n\n\nstream image\n\n\nThe I/O of any program launch through the bash is organized in three data streams:\n\nSTDIN (0): standard input (input)\nSTDOUT (1): standard output (data output by the command and printed in the terminal)\nSTDERR (2): standard error (reserved for error messages, also printed in the terminal)\n\nPiping and redirection is the process used to connect these streams between programs and files.\nReference: Piping and Redirection! by Ryan Chadwick.\n\nPipes\nIn bash, the pipe operator is denoted |. It allows one to compose (mathematically) the output of a program as an input of another one. For instance to display the 10 largest files given by du (disk use)\n$ du | sort -nr | head\nor display it in a pager\n$ du | sort -nr | less\n\n\n\n\n\n\nEXERCISE: head and tail\n\n\n\n\nDisplay the last 15 accidents occurring with Vent fort condition\nDisplay the lines with type of crossing being Intersection en X or Intersection en T of the accident occurring¬†in 2015.\n\n\n\n\n\nRedirection\nThe operator &gt; redirects the stdout of a command (LHS) into a file (RHS). Warning! it erases the file content. The operator &gt;&gt; appends the output of the LHS to a file.\n$ ls /etc &gt; toto.txt\n$ cat toto.txt\n$ wc -l toto.txt &gt;&gt; toto.txt\n$ cat toto.txt\nFinally, the operator &lt; reads from the file (RHS) and sends the content to stdin (LHS)\n$ wc -l &lt; toto.txt\n\n\n\n\n\n\nEXERCISE: CSV creation\n\n\n\n\nCreate a single file bike2016.csv containing all the accidents that occurred in 2016.\nAppend the accidents from 2017 to the previous file and then rename it bike2016_17.csv.\n\n\n\n\n\nThe xargs command\nA Unix killer feature! xargs reads items from the standard input and executes a command given by the user on each component of this list. For instance, this command\necho 'one two three' | xargs mkdir\ncreates 3 folders named one, two and three. Caveat: If the list items contain spaces or newline characters, it may behave badly with the xargs command. There is a special option -0 or -d to help the end user deal with this.\nThe most common usage of xargs is to use it with the find command. This uses find to search for files or directories and then uses xargs to operate on the results. Typical examples of this are changing the ownership of files or moving files.\nfind and xargs can be used together to operate on files that match certain attributes. In the following example files older than two weeks in the temp folder are found and then piped to the xargs command which runs the rm command on each file and removes them.\nfind /tmp -mtime +14 | xargs rm\nReference: Examples with xargs"
  },
  {
    "objectID": "Courses/Bash/tp.html#pattern-matching-part-ii-regexp",
    "href": "Courses/Bash/tp.html#pattern-matching-part-ii-regexp",
    "title": "Command-line tools",
    "section": "Pattern matching (part II): Regexp",
    "text": "Pattern matching (part II): Regexp\nA regular expression (shortened as regex or regexp; also referred to as rational expression) is a sequence of characters that define a search pattern. Many languages implement such syntaxes (beware, there may be some differences!). Some of the most common regular expressions (shared by almost all implementations) are\n\n\\ escape character\n^ start of a line\n. any single character\n$ end of line\nx* zero or more occurrence of character x\nx+ one or more occurrences of character x\nx? zero or one occurrence of character x\nx{n} exactly n occurrence of character x\n[...] range of characters (e.g.¬†[a-z], [A-Z], [a-zA-Z], [0-9], etc‚Ä¶)\n[^...] forbidden characters range\n(...) marked subexpression. The string matched within the parentheses can be recalled later (see the next entry, ). A marked subexpression is also called a block or capturing group. ‚Ä¶\n\nFor instance, to capture all the words starting with a capital letter in a text, you may use the regexp:\n([A-Z][a-zA-Z0-9_]*)+\nReferences:\n\nregexr.\nWikipedia on regular expressions.\nThe sed, awk programs and the perl language documentations.\n\n\n\n\n\n\n\nEXERCISE: regexp\n\n\n\n\nGo to https://regex101.com/ and copy/paste the following list (in the TEST STRING frame):\n\n'01 !!!!!!!.flac'\n'02 bad guy.flac'\n'03 xanny.flac'\n'04 you should see me in a crown.flac'\n'05 all the good girls go to hell.flac'\n'06 wish you were gay.flac'\n\"07 when the party's over.flac\"\n'08 8.flac'\n'09 my strange addiction.flac'\n'10 bury a friend.flac'\n'11 ilomilo.flac'\n'12 listen before i go.flac'\n'13 i love you.flac'\n'14 goodbye.flac'\n\nWhy the name of the 7th song is double-quoted (‚Äù instead of ‚Äô)?\nCapture with a regexp all the song names (between the track number and the extension). You should get this in the MATCH INFORMATION frame on the right:\n\n\n\n\nresult of regexp capture"
  },
  {
    "objectID": "Courses/Bash/tp.html#secure-shell",
    "href": "Courses/Bash/tp.html#secure-shell",
    "title": "Command-line tools",
    "section": "Secure Shell",
    "text": "Secure Shell"
  },
  {
    "objectID": "Courses/Docs/tp.html",
    "href": "Courses/Docs/tp.html",
    "title": "Documentation with Sphinx",
    "section": "",
    "text": "Before starting a description of Sphinx, we first start by introducing, markdown, quarto and reStructuredText files."
  },
  {
    "objectID": "Courses/Docs/tp.html#markdown",
    "href": "Courses/Docs/tp.html#markdown",
    "title": "Documentation with Sphinx",
    "section": "Markdown",
    "text": "Markdown\nMarkdown is a lightweight markup language developed by John Gruber and Aaron Swartz1 .1¬†Aaron Swartz: hacktivist (1986-2013) who also helped develop Creative Commons licenses, RSS, Reddit, etc. For more on his epic life, see Brian Knappenberger‚Äô documentary The Internet‚Äôs Own Boy: The Story of Aaron Swartz (2014) \nHence Markdown is an easy-to-read markup language, popular for simple text formatting, creating documentation for software projects, but also for writing nice emails (for Thunderbird, or any browser, etc.).\nThe extension for a Mardkown file is .md. To render such a file in VSCode or Codium, and possibly export a .pdf or .html file, you need to install a package for that (for instance the Markdown All in One could be installed with Ctrl+Shift+p, and looking for the right name in Extensions: Install Extensions).\n\n\nLeft: Markdown code\n\n# Title level 1\n\n## Title level 2\n\n\n\n\n# Title level 1\n\n## Title level 2\n\n\nThis would be a paragraph. You can use **bold font** but also *italic* or  ~~strikethrough~~.\n\nOther elements are list :\n\n- item 1\n- item 2\n  - sub-item 1\n  - sub-item 2\n\n\n\nRight: rendered\n\nTitle level 1\n\nTitle level 2\n\n\n\nTitle level 1\n\nTitle level 2\nThis would be a paragraph. You can use bold font but also italic or strikethrough.\nOther elements are list :\n\nitem 1\nitem 2\n\nsub-item 1\nsub-item 2\n\n\n\n\n\n\netc.\nA full description can be found here: https://www.markdownguide.org/basic-syntax/; a nice cheatsheet is also available here: https://www.markdownguide.org/cheat-sheet/."
  },
  {
    "objectID": "Courses/Docs/tp.html#title-level-2",
    "href": "Courses/Docs/tp.html#title-level-2",
    "title": "Documentation with Sphinx",
    "section": "Title level 2",
    "text": "Title level 2"
  },
  {
    "objectID": "Courses/Docs/tp.html#title-level-2-1",
    "href": "Courses/Docs/tp.html#title-level-2-1",
    "title": "Documentation with Sphinx",
    "section": "Title level 2",
    "text": "Title level 2\nThis would be a paragraph. You can use bold font but also italic or strikethrough.\nOther elements are list :\n\nitem 1\nitem 2\n\nsub-item 1\nsub-item 2"
  },
  {
    "objectID": "Courses/Docs/tp.html#quarto",
    "href": "Courses/Docs/tp.html#quarto",
    "title": "Documentation with Sphinx",
    "section": "Quarto",
    "text": "Quarto\nquarto is an open-source scientific and technical publishing system. For instance, we have used it for creating the website you are reading right now. We describe here its main usage. quarto allows rendering markdown elements and creating a website easily, that can run some code (R, Python, etc.) and display the results (tables, figures, etc.). The extension is .qmd for quarto markdown. We provide an example below:\n\n\nLeft: Quarto code\n```{python}\nimport numpy as np\nprint(np.sum(np.ones(12)))\n```\n\n\n\nRight: Rendered\n\nimport numpy as np\nprint(np.sum(np.ones(12)))\n\n12.0\n\n\n\n\nDocumentation for Python: https://quarto.org/docs/computations/python.html"
  },
  {
    "objectID": "Courses/Docs/tp.html#restructuredtext",
    "href": "Courses/Docs/tp.html#restructuredtext",
    "title": "Documentation with Sphinx",
    "section": "reStructuredText",
    "text": "reStructuredText\n\nIntroduction\nSphinx is an extension of reStructuredText. reStructuredText (.RST, .ReST, or .reST) is a file format for textual data used primarily in the Python programming language community for technical documentation and is similar to the Markdown format.\nIt is part of the Docutils project of the Python Doc-SIG (Documentation Special Interest Group), aimed at creating a set of tools for Python similar to Javadoc for Java or Plain Old Documentation (pod) for Perl or vignette for R.\nDocutils can extract comments and information from Python programs, and format them into various forms of program documentation.\nIn this sense, reStructuredText is a lightweight markup language designed to be both:\n\nProcessable by documentation-processing software such as Docutils,\neasily readable by human programmers who are reading and writing Python source code.\n\nReferences:\n\nWikipedia on ReStructuredText\nMarkup languages\nDocumentation generators\n\n\n\nSyntax\nA ReST file is a plain text file with a .rst extension. Like Markdown, it allows you to easily write formatted text.\n\nHeaders\nSection Header\n==============\n\nSubsection Header\n-----------------\n\n\nLists\n- A bullet list item\n- Second item\n\n  - A sub-item (indentation matters!)\n\n- Spacing between items creates separate lists\n\n- Third item\n\n1) An enumerated list item\n\n2) Second item\n\n   a) Sub-item that goes on at length and thus needs\n      to be wrapped. Note the indentation that must\n      match the beginning of the text, not the\n      enumerator.\n\n      i) List items can even include\n\n         paragraph breaks.\n\n3) Third item\n\n#) Another enumerated list item\n\n#) Second item\n\n\nImages\n\n.. image:: /path/to/image.jpg\n   :height: 100\n   :width: 200\n   :scale: 50\n   :align: center\n   :alt: ordinateur\n\n   Caption text rendered below the image...\n\n\nNamed links and anonymous links\nA sentence with links to `Wikipedia`_ and the `Linux kernel archive`_.\n.. _Wikipedia: https://www.wikipedia.org/\n.. _Linux kernel archive: https://www.kernel.org/\nAnother sentence with an `anonymous link to the Python website`__.\n__ https://www.python.org/\n\n\n\n\n\n\nNote\n\n\n\nNamed links and anonymous links are enclosed in grave accents (`), and not in apostrophes (‚Äô).\n\n\n\n\n\n\n\n\nNote\n\n\n\nIt is possible to create references to labels linked to an image, a section, in the .rst file, etc.\n\n\n\n\nLiteral blocks\n::\n  some literal text\n\nThis may also be used inline at the end of a paragraph, like so::\nSome more literal text:\n.. code:: python\n\n   print(\"A literal block directive explicitly marked as python code\")"
  },
  {
    "objectID": "Courses/Docs/tp.html#set-up-the-doc",
    "href": "Courses/Docs/tp.html#set-up-the-doc",
    "title": "Documentation with Sphinx",
    "section": "Set up the doc",
    "text": "Set up the doc\nReferences: This page is mainly inspired by the Sphinx documentation http://www.sphinx-doc.org/en/stable/.\nThe documentation is usually located in a docs or doc folder located at the root of a project. For instance, in the biketrauma module we have:\npackaging_tutorial/\n    biketrauma/\n        __init__.py\n        data/\n        vis/\n        io\n        tests/\n    doc/\n    setup.py\n    .gitignore\nIn the Sphinx terminology, this doc folder is called the source directory. It contains:\n\nA configuration file conf.py¬†with all the information needed to read the sources and build the doc. By building, it is meant the process of generating the doc (usually in html, pdf, etc.) from the ReST files.\nA directory structure containing .md or .rst files with the doc.\n\nTo help you, Sphinx comes with a script called sphinx-quickstart that sets up a source directory and creates a default conf.py with the most useful configuration values from a few questions it asks you. To use this, run:\n$ sphinx-quickstart\nAnswer each question asked. Be sure to say yes to the autodoc extension, as we will use this later. There is also an automatic API documentation (API: Application Programming Interface) generator called sphinx-apidoc; see sphinx-apidoc for details.\n\n\n\n\n\n\nEXERCISE: Setting up your documentation\n\n\n\nSet up the documentation for the biketrauma Python module.\n\nInstall the sphinx package with pip\nCreate a doc folder and cd into it\nLaunch sphinx-quickstart --sep."
  },
  {
    "objectID": "Courses/Docs/tp.html#defining-documentation-structure",
    "href": "Courses/Docs/tp.html#defining-documentation-structure",
    "title": "Documentation with Sphinx",
    "section": "Defining documentation structure",
    "text": "Defining documentation structure\nLet us assume you have run sphinx-quickstart. It has created a source directory with conf.py and a master document, index.rst (if you accepted the default parameters).\nThe main function of the master document is to serve as a welcome page and to contain the root of the ‚Äútable of contents tree‚Äù (or toctree). This is one of the main things that Sphinx adds to reStructuredText, a way to connect multiple files to a single hierarchy of documents.\nThe toctree directive initially is empty and looks like so:\n.. toctree::\n   :maxdepth: 2\nYou add documents listing them in the content of the directive:\n.. toctree::\n   :maxdepth: 2\n\n   usage/installation\n   usage/quickstart\n   ...\nThis is exactly how the toctree for this documentation looks. The documents to include are given as document names, which in short means that you leave off the file name extension and use forward slashes (/) as directory separators.\n\n\n\n\n\n\nEXERCISE: installing a documentation\n\n\n\n\nUpdate the index.rst: by adding an image located here just below the title of the page\nInstall the read_the_doc theme following details given here. Additional themes are available on sphinx-doc themes.\nCreate the corresponding directory and files to add:\n\nAn Installation section with a few sentences and code snippets that explain how to install biketrauma\nA Documentation section with subsections io and visu each one containing a title and a few lines of text."
  },
  {
    "objectID": "Courses/Docs/tp.html#building-the-doc",
    "href": "Courses/Docs/tp.html#building-the-doc",
    "title": "Documentation with Sphinx",
    "section": "Building the doc",
    "text": "Building the doc\nDuring the configuration of Sphinx, a text file called MakeFile was created: In software development, Make is a build automation tool that automatically builds executable programs and libraries from source code by reading files called Makefiles which specify how to derive the target program.\nReferences:\n\nWikipedia on Make Software\n\n$ make html\nThen to access the web pages created:\n$ firefox _build/html/index.html\n\n\n\n\n\n\nNote\n\n\n\nThere is also a sphinx-build tool that can help you to build without make.\n\n\n\n\n\n\n\n\nEXERCISE: Makefiles\n\n\n\n\nList all the target defined in the Makefiles\nBuild your doc and visualize it with a navigator"
  },
  {
    "objectID": "Courses/Docs/tp.html#api-doc-autodoc",
    "href": "Courses/Docs/tp.html#api-doc-autodoc",
    "title": "Documentation with Sphinx",
    "section": "API doc (autodoc)",
    "text": "API doc (autodoc)\nWhen documenting Python code, it is common to put a lot of documentation in the source files, in documentation strings. Sphinx supports the inclusion of docstrings from your modules with an extension (an extension is a Python module that provides additional features for Sphinx projects) called autodoc.\nIn order to use autodoc, you need to activate it in conf.py by putting the string 'sphinx.ext.autodoc' into the list assigned to the extensions config value. Then, you have a few additional directives at your disposal.\nFor example, to document the function io.open(), reading its signature and docstring from the source file, you‚Äôd write this:\n.. autofunction:: io.open\nYou can also document whole classes or even modules automatically, using member options for the auto directives, like\n.. automodule:: io\n   :members:\nautodoc needs to import your modules in order to extract the docstrings. Therefore, you must add the appropriate path to sys.path in your conf.py.\n\n\n\n\n\n\nEXERCISE: docstring\n\n\n\n\nWrite a docstring for the class biketrauma.io.Load_db and the function plot_location\nIntegrate this documentation in a section called API in the Sphinx toctree."
  },
  {
    "objectID": "Courses/Docs/tp.html#sphinx-gallery",
    "href": "Courses/Docs/tp.html#sphinx-gallery",
    "title": "Documentation with Sphinx",
    "section": "Sphinx-Gallery",
    "text": "Sphinx-Gallery\nSphinx-Gallery is an extension able to create galleries of examples in the html documentation directly from the script files of your project.\nReferences: Sphinx Gallery\n\nConfiguration\nConfiguration and customization of sphinx-gallery are done primarily with a dictionary specified in your conf.py file. A typical sample is:\nfrom sphinx_gallery.sorting import FileNameSortKey\nsphinx_gallery_conf = {\n     # path to your examples scripts\n    'examples_dirs': ['../script',],\n     # path where to save gallery-generated examples\n    'gallery_dirs': ['_auto_scripts'],\n    # Order of the Gallery\n    'within_subsection_order': FileNameSortKey,\n}\nA list of the possible keys can be found on Sphinx Galleries.\n\n\n\n\n\n\nEXERCISE: Spinx gallery\n\n\n\n\nInstall the sphinx-gallery extension with pip.\nUpdate the conf.py of the biketrauma package with the dictionary containing the configuration of the sphinx-gallery.\n\n\n\n\n\nStructure your example files\nSphinx-Gallery parses the folder listed in the key examples_dirs. It expects each Python file to have two things:\n\nA docstring, written in rST, that defines the header for the example. It must begin by defining a .rST title. The title may contain any punctuation mark but cannot start with the same punctuation mark repeated more than 3 times. For example:\n\n    \"\"\"\n    \"This\" is my example-script\n    ===========================\n\n    This example doesn't do much, it just makes a simple plot\n    \"\"\"\n\nPython code. This can be any valid Python code that you wish. Any matplotlib images that are generated will be saved to disk, and the ‚Äò.rST‚Äô generated will display these images with the built examples. By default, only images generated by matplotlib, or packages based on matplotlib (e.g., seaborn or yellowbrick) are saved and displayed. However, you can change this to include other packages, see for instance Image scrapers (XXX TODO: add details on Image scrapers).\n\nWarning: With default options, Sphinx-Gallery only executes the script files with a filename starting with plot_.\nWarning: Sphinx-Gallery expects to find a README.txt (or README.rst) file in every folder containing examples.\n\n\nInclude examples in your toc-tree\nFor instance, you can add those lines in the index.rst\n.. toctree::\n   :maxdepth: 2\n   :caption: Previsions:\n\n   _auto_scripts/index\nto add a section containing all the examples.\n\n\n\n\n\n\nEXERCISE: auto-build\n\n\n\n\nTransform the script.py examples into an auto-build example."
  },
  {
    "objectID": "Courses/IDE/tp.html",
    "href": "Courses/IDE/tp.html",
    "title": "Integrated Development Environment",
    "section": "",
    "text": "An Integrated Development Environment (IDE) is a software application that provides comprehensive facilities to computer programmers for software development. An IDE normally consists of at least a source code editor, build automation tools and a debugger."
  },
  {
    "objectID": "Courses/IDE/tp.html#pythons-specific-ide",
    "href": "Courses/IDE/tp.html#pythons-specific-ide",
    "title": "Integrated Development Environment",
    "section": "Python‚Äôs specific IDE",
    "text": "Python‚Äôs specific IDE\nThere are many IDEs for Python, but none are perfect, and there is no consensus in the Python community. There is no real ‚Äúcanonical‚Äù choice as Rstudio is the one for R users.\nAs Python is a real jackknife programming language, depending on your goal (data scientific program, web development, etc.) you may choose a specific IDE for a particular task.\n\nScientific computing: Pyzo, Spyder\nGeneric: PyCharm, VSCode\n\nWe warmly recommend you use an IDE, and we will mostly describe VSCode in what follows."
  },
  {
    "objectID": "Courses/IDE/tp.html#vscodecodium",
    "href": "Courses/IDE/tp.html#vscodecodium",
    "title": "Integrated Development Environment",
    "section": "VSCode/Codium",
    "text": "VSCode/Codium\nFor instance, you can use VSCode. This is a powerful, cross-platform IDE that comes with many extensions.\nOn the FdS-Linux box, there is a fork of VSCode called vscodium. You may launch it via the GUI or through the following command line\n$ vscodium\nor\n$ code\n\nInstall a VSCode extension\nWe will install the Python extension. To install it:\n\nOpen VSCode.\nOpen the Extensions tab (left bar of the VSCode window or simply press Ctrl+Shift+X)\nType Python to find the Python extension from Microsoft\nClick the Install button, then the Enable button\n\nor\n\nOpen VSCode\nPress Ctrl+P to open the Quick Open dialog\nType ext install ms-python.python to find the extension\nClick the Install button, then the Enable button\n\nor\n\nRun in a terminal\n\n$ vscodium --install-extension ms-python.python\n\n\n\n\n\n\nEXERCISE: Installation on your machine\n\n\n\n\nInstall the Python extension in your VSCode\n\n\n\n\n\nAn advanced text editor\nThe keyboard shortcuts Reference guide is available in the help menu (or with Ctrl+K Ctrl+R shortcut). It can be very useful to learn some shortcuts. For instance:\n\nLearn how multicursors work (e.g., search for an occurrence with Ctrl+d)\nCreate aligned multicursors with Ctrl+Shift\nLearn how to move an entire line with Alt+up\netc.\n\n\n\nUsing VSCode as a Python IDE\nReference: VSCode docs for Python\nThis part is dedicated to setting up VSCode to use it as a Python IDE. You should have a working VSCode (with Python extension) and anaconda program.\n\n\n\n\n\n\nEXERCISE: VSCode and Python\n\n\n\n\nStart VSCode in a project (workspace) folder: Using a command prompt or terminal, create an empty folder called test_dir, navigate into it, and open VSCode (vscodium) in that folder (.) by entering the following commands:\ncd ~\nmkdir test_dir\ncd hello\ncode\nNote: If you‚Äôre using an Anaconda distribution, be sure to use an Anaconda command prompt.\nBy starting VSCode in a folder, that folder becomes your ‚Äúworkspace‚Äù. VSCode stores settings that are specific to that workspace in the (hidden) subfolder .vscode/settings.json, which are separate from user settings that are stored globally.\nAlternatively, you can run VSCode through the operating system UI, then use File &gt; Open Folder to open the project folder.\nSelect a Python interpreter: Python is an interpreted language; to run Python code, you must tell VSCode which interpreter to use.\nFrom within VSCode, select a Python 3 interpreter by opening the Command Palette (Ctrl+Shift+P), start typing the Python: Select Interpreter command to search, then select the command. You can also use the Select Python Environment option on the Status Bar if available\nOpen the terminal in VSCode and download with wget or curl the file test_python.py here. Run it through the IDE.\nNext, you have to learn how to debug a simple Python script, see the VSCode help on debugging for that."
  },
  {
    "objectID": "Courses/IDE/tp.html#recommended-extensions-for-vs-code",
    "href": "Courses/IDE/tp.html#recommended-extensions-for-vs-code",
    "title": "Integrated Development Environment",
    "section": "Recommended extensions for VS Code",
    "text": "Recommended extensions for VS Code\n\nlinter/flake8: cornflakes\nSpell check: SpellChecker or Grammarly or LTex\nLive Share to collaboratively edit and debug with others in real-time, regardless of your programming language.\nTODO: complete!"
  },
  {
    "objectID": "Courses/Python-modules/tp.html",
    "href": "Courses/Python-modules/tp.html",
    "title": "Creating a python module",
    "section": "",
    "text": "You already know it: this is a set of python functions and statements, and this is what you import at the beginning of your python functions.\n\n\nIndeed, a module can simply be a single file:\n\nimport fibo\n\nThis does not enter the names of the functions defined in fibo directly in the current symbol table though; it only enters the module name fibo there. Using the module name you can access the functions:\n\nfibo.fib(1000)\n\n0 1 1 2 3 5 8 13 21 34 55 89 144 233 377 610 987 \n\n\n\nfibo.fib2(100)\n\n[0, 1, 1, 2, 3, 5, 8, 13, 21, 34, 55, 89]\n\n\nWhen importing a module, several methods are (automatically) defined. Their names are usually prefixed and suffixed by the symbol __, e.g.,\n\nfibo.__name__\n\n'fibo'\n\n\n\nfibo.__file__\n\n'/home/jsalmon/Documents/Mes_cours/Montpellier/HAX712X/Courses/Python-modules/fibo.py'\n\n\n\n\n\nYou can also import a full directory (containing many python files stored in a sub-folder). python looks for a folder located in sys.path list. You have already imported the numpy module, for numerical analysis with python:\n\nimport numpy as np\nprint(np.array([0, 1, 2, 3]).reshape(2, 2))\nprint(np.array([0, 1, 2, 3]).mean())\n\n[[0 1]\n [2 3]]\n1.5\n\n\nIn fact, you have imported the following folder:\nnp.__path__\nDepending on your installation you might obtain ['/usr/lib/python3.9/site-packages/numpy'] or ['/home/username/anaconda3/lib/python3.7/site-packages/numpy'] if you installed with Anaconda.\nMore precisely this file\n&gt;&gt;&gt; np.__file__\n'/usr/lib/python3.9/site-packages/numpy/__init__.py'\nor\n&gt;&gt;&gt; np.__file__\n['/home/username/anaconda3/lib/python3.7/site-packages/numpy/__init__.py']\nAny (sub-)directory of your python module should contain an __init__.py file!\n\n\n\n\n\n\nUseful tips\n\n\n\n\nThe __init__.py file can contain a list of functions to be loaded when the module is imported. It allows to expose functions to users in a concise way.\nYou can also import modules with relative paths, using ., .., ..., etc.\n\n\n\nReference: Absolute vs Relative Imports in Python by Mbithe Nzomo.\n\n\n\nThe built-in function dir() is used to find out which names a module defines. It returns a sorted list of strings:\n\nimport fibo, numpy\ndir(fibo)\n\n['__builtins__',\n '__cached__',\n '__doc__',\n '__file__',\n '__loader__',\n '__name__',\n '__package__',\n '__spec__',\n 'fib',\n 'fib2']\n\n\n\nfibo.__dir__\n\n&lt;function __dir__&gt;\n\n\n\ndir(numpy)\n\n['ALLOW_THREADS',\n 'AxisError',\n 'BUFSIZE',\n 'CLIP',\n 'ComplexWarning',\n 'DataSource',\n 'ERR_CALL',\n 'ERR_DEFAULT',\n 'ERR_IGNORE',\n 'ERR_LOG',\n 'ERR_PRINT',\n 'ERR_RAISE',\n 'ERR_WARN',\n 'FLOATING_POINT_SUPPORT',\n 'FPE_DIVIDEBYZERO',\n 'FPE_INVALID',\n 'FPE_OVERFLOW',\n 'FPE_UNDERFLOW',\n 'False_',\n 'Inf',\n 'Infinity',\n 'MAXDIMS',\n 'MAY_SHARE_BOUNDS',\n 'MAY_SHARE_EXACT',\n 'ModuleDeprecationWarning',\n 'NAN',\n 'NINF',\n 'NZERO',\n 'NaN',\n 'PINF',\n 'PZERO',\n 'RAISE',\n 'RankWarning',\n 'SHIFT_DIVIDEBYZERO',\n 'SHIFT_INVALID',\n 'SHIFT_OVERFLOW',\n 'SHIFT_UNDERFLOW',\n 'ScalarType',\n 'Tester',\n 'TooHardError',\n 'True_',\n 'UFUNC_BUFSIZE_DEFAULT',\n 'UFUNC_PYVALS_NAME',\n 'VisibleDeprecationWarning',\n 'WRAP',\n '_CopyMode',\n '_NoValue',\n '_UFUNC_API',\n '__NUMPY_SETUP__',\n '__all__',\n '__builtins__',\n '__cached__',\n '__config__',\n '__deprecated_attrs__',\n '__dir__',\n '__doc__',\n '__expired_functions__',\n '__file__',\n '__former_attrs__',\n '__future_scalars__',\n '__getattr__',\n '__git_version__',\n '__loader__',\n '__name__',\n '__package__',\n '__path__',\n '__spec__',\n '__version__',\n '_add_newdoc_ufunc',\n '_builtins',\n '_distributor_init',\n '_financial_names',\n '_get_promotion_state',\n '_globals',\n '_int_extended_msg',\n '_mat',\n '_no_nep50_warning',\n '_pyinstaller_hooks_dir',\n '_pytesttester',\n '_set_promotion_state',\n '_specific_msg',\n '_version',\n 'abs',\n 'absolute',\n 'add',\n 'add_docstring',\n 'add_newdoc',\n 'add_newdoc_ufunc',\n 'all',\n 'allclose',\n 'alltrue',\n 'amax',\n 'amin',\n 'angle',\n 'any',\n 'append',\n 'apply_along_axis',\n 'apply_over_axes',\n 'arange',\n 'arccos',\n 'arccosh',\n 'arcsin',\n 'arcsinh',\n 'arctan',\n 'arctan2',\n 'arctanh',\n 'argmax',\n 'argmin',\n 'argpartition',\n 'argsort',\n 'argwhere',\n 'around',\n 'array',\n 'array2string',\n 'array_equal',\n 'array_equiv',\n 'array_repr',\n 'array_split',\n 'array_str',\n 'asanyarray',\n 'asarray',\n 'asarray_chkfinite',\n 'ascontiguousarray',\n 'asfarray',\n 'asfortranarray',\n 'asmatrix',\n 'atleast_1d',\n 'atleast_2d',\n 'atleast_3d',\n 'average',\n 'bartlett',\n 'base_repr',\n 'binary_repr',\n 'bincount',\n 'bitwise_and',\n 'bitwise_not',\n 'bitwise_or',\n 'bitwise_xor',\n 'blackman',\n 'block',\n 'bmat',\n 'bool_',\n 'broadcast',\n 'broadcast_arrays',\n 'broadcast_shapes',\n 'broadcast_to',\n 'busday_count',\n 'busday_offset',\n 'busdaycalendar',\n 'byte',\n 'byte_bounds',\n 'bytes_',\n 'c_',\n 'can_cast',\n 'cast',\n 'cbrt',\n 'cdouble',\n 'ceil',\n 'cfloat',\n 'char',\n 'character',\n 'chararray',\n 'choose',\n 'clip',\n 'clongdouble',\n 'clongfloat',\n 'column_stack',\n 'common_type',\n 'compare_chararrays',\n 'compat',\n 'complex128',\n 'complex256',\n 'complex64',\n 'complex_',\n 'complexfloating',\n 'compress',\n 'concatenate',\n 'conj',\n 'conjugate',\n 'convolve',\n 'copy',\n 'copysign',\n 'copyto',\n 'corrcoef',\n 'correlate',\n 'cos',\n 'cosh',\n 'count_nonzero',\n 'cov',\n 'cross',\n 'csingle',\n 'ctypeslib',\n 'cumprod',\n 'cumproduct',\n 'cumsum',\n 'datetime64',\n 'datetime_as_string',\n 'datetime_data',\n 'deg2rad',\n 'degrees',\n 'delete',\n 'deprecate',\n 'deprecate_with_doc',\n 'diag',\n 'diag_indices',\n 'diag_indices_from',\n 'diagflat',\n 'diagonal',\n 'diff',\n 'digitize',\n 'disp',\n 'divide',\n 'divmod',\n 'dot',\n 'double',\n 'dsplit',\n 'dstack',\n 'dtype',\n 'e',\n 'ediff1d',\n 'einsum',\n 'einsum_path',\n 'emath',\n 'empty',\n 'empty_like',\n 'equal',\n 'errstate',\n 'euler_gamma',\n 'exp',\n 'exp2',\n 'expand_dims',\n 'expm1',\n 'extract',\n 'eye',\n 'fabs',\n 'fastCopyAndTranspose',\n 'fft',\n 'fill_diagonal',\n 'find_common_type',\n 'finfo',\n 'fix',\n 'flatiter',\n 'flatnonzero',\n 'flexible',\n 'flip',\n 'fliplr',\n 'flipud',\n 'float128',\n 'float16',\n 'float32',\n 'float64',\n 'float_',\n 'float_power',\n 'floating',\n 'floor',\n 'floor_divide',\n 'fmax',\n 'fmin',\n 'fmod',\n 'format_float_positional',\n 'format_float_scientific',\n 'format_parser',\n 'frexp',\n 'from_dlpack',\n 'frombuffer',\n 'fromfile',\n 'fromfunction',\n 'fromiter',\n 'frompyfunc',\n 'fromregex',\n 'fromstring',\n 'full',\n 'full_like',\n 'gcd',\n 'generic',\n 'genfromtxt',\n 'geomspace',\n 'get_array_wrap',\n 'get_include',\n 'get_printoptions',\n 'getbufsize',\n 'geterr',\n 'geterrcall',\n 'geterrobj',\n 'gradient',\n 'greater',\n 'greater_equal',\n 'half',\n 'hamming',\n 'hanning',\n 'heaviside',\n 'histogram',\n 'histogram2d',\n 'histogram_bin_edges',\n 'histogramdd',\n 'hsplit',\n 'hstack',\n 'hypot',\n 'i0',\n 'identity',\n 'iinfo',\n 'imag',\n 'in1d',\n 'index_exp',\n 'indices',\n 'inexact',\n 'inf',\n 'info',\n 'infty',\n 'inner',\n 'insert',\n 'int16',\n 'int32',\n 'int64',\n 'int8',\n 'int_',\n 'intc',\n 'integer',\n 'interp',\n 'intersect1d',\n 'intp',\n 'invert',\n 'is_busday',\n 'isclose',\n 'iscomplex',\n 'iscomplexobj',\n 'isfinite',\n 'isfortran',\n 'isin',\n 'isinf',\n 'isnan',\n 'isnat',\n 'isneginf',\n 'isposinf',\n 'isreal',\n 'isrealobj',\n 'isscalar',\n 'issctype',\n 'issubclass_',\n 'issubdtype',\n 'issubsctype',\n 'iterable',\n 'ix_',\n 'kaiser',\n 'kernel_version',\n 'kron',\n 'lcm',\n 'ldexp',\n 'left_shift',\n 'less',\n 'less_equal',\n 'lexsort',\n 'lib',\n 'linalg',\n 'linspace',\n 'little_endian',\n 'load',\n 'loadtxt',\n 'log',\n 'log10',\n 'log1p',\n 'log2',\n 'logaddexp',\n 'logaddexp2',\n 'logical_and',\n 'logical_not',\n 'logical_or',\n 'logical_xor',\n 'logspace',\n 'longcomplex',\n 'longdouble',\n 'longfloat',\n 'longlong',\n 'lookfor',\n 'ma',\n 'mask_indices',\n 'mat',\n 'math',\n 'matmul',\n 'matrix',\n 'max',\n 'maximum',\n 'maximum_sctype',\n 'may_share_memory',\n 'mean',\n 'median',\n 'memmap',\n 'meshgrid',\n 'mgrid',\n 'min',\n 'min_scalar_type',\n 'minimum',\n 'mintypecode',\n 'mod',\n 'modf',\n 'moveaxis',\n 'msort',\n 'multiply',\n 'nan',\n 'nan_to_num',\n 'nanargmax',\n 'nanargmin',\n 'nancumprod',\n 'nancumsum',\n 'nanmax',\n 'nanmean',\n 'nanmedian',\n 'nanmin',\n 'nanpercentile',\n 'nanprod',\n 'nanquantile',\n 'nanstd',\n 'nansum',\n 'nanvar',\n 'nbytes',\n 'ndarray',\n 'ndenumerate',\n 'ndim',\n 'ndindex',\n 'nditer',\n 'negative',\n 'nested_iters',\n 'newaxis',\n 'nextafter',\n 'nonzero',\n 'not_equal',\n 'numarray',\n 'number',\n 'obj2sctype',\n 'object_',\n 'ogrid',\n 'oldnumeric',\n 'ones',\n 'ones_like',\n 'outer',\n 'packbits',\n 'pad',\n 'partition',\n 'percentile',\n 'pi',\n 'piecewise',\n 'place',\n 'poly',\n 'poly1d',\n 'polyadd',\n 'polyder',\n 'polydiv',\n 'polyfit',\n 'polyint',\n 'polymul',\n 'polynomial',\n 'polysub',\n 'polyval',\n 'positive',\n 'power',\n 'printoptions',\n 'prod',\n 'product',\n 'promote_types',\n 'ptp',\n 'put',\n 'put_along_axis',\n 'putmask',\n 'quantile',\n 'r_',\n 'rad2deg',\n 'radians',\n 'random',\n 'ravel',\n 'ravel_multi_index',\n 'real',\n 'real_if_close',\n 'rec',\n 'recarray',\n 'recfromcsv',\n 'recfromtxt',\n 'reciprocal',\n 'record',\n 'remainder',\n 'repeat',\n 'require',\n 'reshape',\n 'resize',\n 'result_type',\n 'right_shift',\n 'rint',\n 'roll',\n 'rollaxis',\n 'roots',\n 'rot90',\n 'round',\n 'round_',\n 'row_stack',\n 's_',\n 'safe_eval',\n 'save',\n 'savetxt',\n 'savez',\n 'savez_compressed',\n 'sctype2char',\n 'sctypeDict',\n 'sctypes',\n 'searchsorted',\n 'select',\n 'set_numeric_ops',\n 'set_printoptions',\n 'set_string_function',\n 'setbufsize',\n 'setdiff1d',\n 'seterr',\n 'seterrcall',\n 'seterrobj',\n 'setxor1d',\n 'shape',\n 'shares_memory',\n 'short',\n 'show_config',\n 'show_runtime',\n 'sign',\n 'signbit',\n 'signedinteger',\n 'sin',\n 'sinc',\n 'single',\n 'singlecomplex',\n 'sinh',\n 'size',\n 'sometrue',\n 'sort',\n 'sort_complex',\n 'source',\n 'spacing',\n 'split',\n 'sqrt',\n 'square',\n 'squeeze',\n 'stack',\n 'std',\n 'str_',\n 'string_',\n 'subtract',\n 'sum',\n 'swapaxes',\n 'take',\n 'take_along_axis',\n 'tan',\n 'tanh',\n 'tensordot',\n 'test',\n 'testing',\n 'tile',\n 'timedelta64',\n 'trace',\n 'tracemalloc_domain',\n 'transpose',\n 'trapz',\n 'tri',\n 'tril',\n 'tril_indices',\n 'tril_indices_from',\n 'trim_zeros',\n 'triu',\n 'triu_indices',\n 'triu_indices_from',\n 'true_divide',\n 'trunc',\n 'typecodes',\n 'typename',\n 'ubyte',\n 'ufunc',\n 'uint',\n 'uint16',\n 'uint32',\n 'uint64',\n 'uint8',\n 'uintc',\n 'uintp',\n 'ulonglong',\n 'unicode_',\n 'union1d',\n 'unique',\n 'unpackbits',\n 'unravel_index',\n 'unsignedinteger',\n 'unwrap',\n 'use_hugepage',\n 'ushort',\n 'vander',\n 'var',\n 'vdot',\n 'vectorize',\n 'version',\n 'void',\n 'vsplit',\n 'vstack',\n 'where',\n 'who',\n 'zeros',\n 'zeros_like']\n\n\n\nnumpy.__dir__\n\n&lt;function numpy.__dir__()&gt;\n\n\n\nTo list every element in your symbol table simply call dir().\nReference: Python doc the dir function\n\n\n\nA namespace is a set of names (functions, variables, etc.). Different namespaces can co-exist at a given time but are completely isolated. In this way, you can control which function you are using.\nA namespace containing all the built-in names is created when we start the python interpreter and exists as long we don‚Äôt exit.\n\ncos(3)\n\nNameError: name 'cos' is not defined\n\n\nYou need to import a package for mathematical functions:\n\nimport math, numpy as np\nprint(math.cos(3), np.cos(3))\n\n-0.9899924966004454 -0.9899924966004454\n\n\nReference: Python Namespace and Scope tutorial\n\n\n\nWhen a module named spam is imported, the interpreter first searches for a built-in module with that name. If not found, it then searches for a file named spam.py in a list of directories given by the variable sys.path. The variable sys.path is initialized from these locations:\n\nThe directory containing the input script (or the current directory when no file is specified).\nThe environment variable PYTHONPATH (a list of directory names, with the same syntax as the shell variable PATH).\n\nReference: Python documentation, The Module Search Path\n\n\n\nFind the loader for a module, optionally within the specified path.\n\nimport importlib\nspam_spec = importlib.util.find_spec(\"spam\")\nfound = spam_spec is not None\nprint(found)\n\nFalse\n\n\nNow,\n\nimport numpy\nnumpy_spec = importlib.util.find_spec(\"numpy\")\nprint(numpy_spec)\n\nModuleSpec(name='numpy', loader=&lt;_frozen_importlib_external.SourceFileLoader object at 0x7f08fdf021a0&gt;, origin='/home/jsalmon/anaconda3/envs/peerannot/lib/python3.10/site-packages/numpy/__init__.py', submodule_search_locations=['/home/jsalmon/anaconda3/envs/peerannot/lib/python3.10/site-packages/numpy'])\n\n\nshould return more information and where the loader is.\nReferences:\n\nPython doc on find_loader\nHow to check if a Python module exists without importing it on Stackoverflow\n\n\n\n\nA module can contain executable statements as well as function definitions. These statements are intended to initialize the module. They are executed only the first time the module name is encountered in an import statement.\nTo force a module to be reloaded, you can use importlib.reload().\nReference: Python doc on reload\nRemark: when using ipython (interactive python, an ancestor of the jupyter notebook), one can use the ‚Äúmagic‚Äù command %autoreload 2\nReference: IPython autoreload\n\n\n\nTo speed up loading modules, python caches the compiled version of each module in the __pycache__ directory under the name module.version.pyc, where the version encodes the format of the compiled file; it generally contains the python version number.\nFor example, in CPython release 3.3 the compiled version of spam.py would be cached as __pycache__/spam.cpython-33.pyc. This naming convention allows compiled modules from different releases and different versions of python to coexist.\n\n\n\n\n\n\nUseful git tip\n\n\n\nYou should add __pycache__ entry in your .gitignore file to avoid adding a compiled python file to your project."
  },
  {
    "objectID": "Courses/Python-modules/tp.html#what-is-a-python-module",
    "href": "Courses/Python-modules/tp.html#what-is-a-python-module",
    "title": "Creating a python module",
    "section": "",
    "text": "You already know it: this is a set of python functions and statements, and this is what you import at the beginning of your python functions.\n\n\nIndeed, a module can simply be a single file:\n\nimport fibo\n\nThis does not enter the names of the functions defined in fibo directly in the current symbol table though; it only enters the module name fibo there. Using the module name you can access the functions:\n\nfibo.fib(1000)\n\n0 1 1 2 3 5 8 13 21 34 55 89 144 233 377 610 987 \n\n\n\nfibo.fib2(100)\n\n[0, 1, 1, 2, 3, 5, 8, 13, 21, 34, 55, 89]\n\n\nWhen importing a module, several methods are (automatically) defined. Their names are usually prefixed and suffixed by the symbol __, e.g.,\n\nfibo.__name__\n\n'fibo'\n\n\n\nfibo.__file__\n\n'/home/jsalmon/Documents/Mes_cours/Montpellier/HAX712X/Courses/Python-modules/fibo.py'\n\n\n\n\n\nYou can also import a full directory (containing many python files stored in a sub-folder). python looks for a folder located in sys.path list. You have already imported the numpy module, for numerical analysis with python:\n\nimport numpy as np\nprint(np.array([0, 1, 2, 3]).reshape(2, 2))\nprint(np.array([0, 1, 2, 3]).mean())\n\n[[0 1]\n [2 3]]\n1.5\n\n\nIn fact, you have imported the following folder:\nnp.__path__\nDepending on your installation you might obtain ['/usr/lib/python3.9/site-packages/numpy'] or ['/home/username/anaconda3/lib/python3.7/site-packages/numpy'] if you installed with Anaconda.\nMore precisely this file\n&gt;&gt;&gt; np.__file__\n'/usr/lib/python3.9/site-packages/numpy/__init__.py'\nor\n&gt;&gt;&gt; np.__file__\n['/home/username/anaconda3/lib/python3.7/site-packages/numpy/__init__.py']\nAny (sub-)directory of your python module should contain an __init__.py file!\n\n\n\n\n\n\nUseful tips\n\n\n\n\nThe __init__.py file can contain a list of functions to be loaded when the module is imported. It allows to expose functions to users in a concise way.\nYou can also import modules with relative paths, using ., .., ..., etc.\n\n\n\nReference: Absolute vs Relative Imports in Python by Mbithe Nzomo.\n\n\n\nThe built-in function dir() is used to find out which names a module defines. It returns a sorted list of strings:\n\nimport fibo, numpy\ndir(fibo)\n\n['__builtins__',\n '__cached__',\n '__doc__',\n '__file__',\n '__loader__',\n '__name__',\n '__package__',\n '__spec__',\n 'fib',\n 'fib2']\n\n\n\nfibo.__dir__\n\n&lt;function __dir__&gt;\n\n\n\ndir(numpy)\n\n['ALLOW_THREADS',\n 'AxisError',\n 'BUFSIZE',\n 'CLIP',\n 'ComplexWarning',\n 'DataSource',\n 'ERR_CALL',\n 'ERR_DEFAULT',\n 'ERR_IGNORE',\n 'ERR_LOG',\n 'ERR_PRINT',\n 'ERR_RAISE',\n 'ERR_WARN',\n 'FLOATING_POINT_SUPPORT',\n 'FPE_DIVIDEBYZERO',\n 'FPE_INVALID',\n 'FPE_OVERFLOW',\n 'FPE_UNDERFLOW',\n 'False_',\n 'Inf',\n 'Infinity',\n 'MAXDIMS',\n 'MAY_SHARE_BOUNDS',\n 'MAY_SHARE_EXACT',\n 'ModuleDeprecationWarning',\n 'NAN',\n 'NINF',\n 'NZERO',\n 'NaN',\n 'PINF',\n 'PZERO',\n 'RAISE',\n 'RankWarning',\n 'SHIFT_DIVIDEBYZERO',\n 'SHIFT_INVALID',\n 'SHIFT_OVERFLOW',\n 'SHIFT_UNDERFLOW',\n 'ScalarType',\n 'Tester',\n 'TooHardError',\n 'True_',\n 'UFUNC_BUFSIZE_DEFAULT',\n 'UFUNC_PYVALS_NAME',\n 'VisibleDeprecationWarning',\n 'WRAP',\n '_CopyMode',\n '_NoValue',\n '_UFUNC_API',\n '__NUMPY_SETUP__',\n '__all__',\n '__builtins__',\n '__cached__',\n '__config__',\n '__deprecated_attrs__',\n '__dir__',\n '__doc__',\n '__expired_functions__',\n '__file__',\n '__former_attrs__',\n '__future_scalars__',\n '__getattr__',\n '__git_version__',\n '__loader__',\n '__name__',\n '__package__',\n '__path__',\n '__spec__',\n '__version__',\n '_add_newdoc_ufunc',\n '_builtins',\n '_distributor_init',\n '_financial_names',\n '_get_promotion_state',\n '_globals',\n '_int_extended_msg',\n '_mat',\n '_no_nep50_warning',\n '_pyinstaller_hooks_dir',\n '_pytesttester',\n '_set_promotion_state',\n '_specific_msg',\n '_version',\n 'abs',\n 'absolute',\n 'add',\n 'add_docstring',\n 'add_newdoc',\n 'add_newdoc_ufunc',\n 'all',\n 'allclose',\n 'alltrue',\n 'amax',\n 'amin',\n 'angle',\n 'any',\n 'append',\n 'apply_along_axis',\n 'apply_over_axes',\n 'arange',\n 'arccos',\n 'arccosh',\n 'arcsin',\n 'arcsinh',\n 'arctan',\n 'arctan2',\n 'arctanh',\n 'argmax',\n 'argmin',\n 'argpartition',\n 'argsort',\n 'argwhere',\n 'around',\n 'array',\n 'array2string',\n 'array_equal',\n 'array_equiv',\n 'array_repr',\n 'array_split',\n 'array_str',\n 'asanyarray',\n 'asarray',\n 'asarray_chkfinite',\n 'ascontiguousarray',\n 'asfarray',\n 'asfortranarray',\n 'asmatrix',\n 'atleast_1d',\n 'atleast_2d',\n 'atleast_3d',\n 'average',\n 'bartlett',\n 'base_repr',\n 'binary_repr',\n 'bincount',\n 'bitwise_and',\n 'bitwise_not',\n 'bitwise_or',\n 'bitwise_xor',\n 'blackman',\n 'block',\n 'bmat',\n 'bool_',\n 'broadcast',\n 'broadcast_arrays',\n 'broadcast_shapes',\n 'broadcast_to',\n 'busday_count',\n 'busday_offset',\n 'busdaycalendar',\n 'byte',\n 'byte_bounds',\n 'bytes_',\n 'c_',\n 'can_cast',\n 'cast',\n 'cbrt',\n 'cdouble',\n 'ceil',\n 'cfloat',\n 'char',\n 'character',\n 'chararray',\n 'choose',\n 'clip',\n 'clongdouble',\n 'clongfloat',\n 'column_stack',\n 'common_type',\n 'compare_chararrays',\n 'compat',\n 'complex128',\n 'complex256',\n 'complex64',\n 'complex_',\n 'complexfloating',\n 'compress',\n 'concatenate',\n 'conj',\n 'conjugate',\n 'convolve',\n 'copy',\n 'copysign',\n 'copyto',\n 'corrcoef',\n 'correlate',\n 'cos',\n 'cosh',\n 'count_nonzero',\n 'cov',\n 'cross',\n 'csingle',\n 'ctypeslib',\n 'cumprod',\n 'cumproduct',\n 'cumsum',\n 'datetime64',\n 'datetime_as_string',\n 'datetime_data',\n 'deg2rad',\n 'degrees',\n 'delete',\n 'deprecate',\n 'deprecate_with_doc',\n 'diag',\n 'diag_indices',\n 'diag_indices_from',\n 'diagflat',\n 'diagonal',\n 'diff',\n 'digitize',\n 'disp',\n 'divide',\n 'divmod',\n 'dot',\n 'double',\n 'dsplit',\n 'dstack',\n 'dtype',\n 'e',\n 'ediff1d',\n 'einsum',\n 'einsum_path',\n 'emath',\n 'empty',\n 'empty_like',\n 'equal',\n 'errstate',\n 'euler_gamma',\n 'exp',\n 'exp2',\n 'expand_dims',\n 'expm1',\n 'extract',\n 'eye',\n 'fabs',\n 'fastCopyAndTranspose',\n 'fft',\n 'fill_diagonal',\n 'find_common_type',\n 'finfo',\n 'fix',\n 'flatiter',\n 'flatnonzero',\n 'flexible',\n 'flip',\n 'fliplr',\n 'flipud',\n 'float128',\n 'float16',\n 'float32',\n 'float64',\n 'float_',\n 'float_power',\n 'floating',\n 'floor',\n 'floor_divide',\n 'fmax',\n 'fmin',\n 'fmod',\n 'format_float_positional',\n 'format_float_scientific',\n 'format_parser',\n 'frexp',\n 'from_dlpack',\n 'frombuffer',\n 'fromfile',\n 'fromfunction',\n 'fromiter',\n 'frompyfunc',\n 'fromregex',\n 'fromstring',\n 'full',\n 'full_like',\n 'gcd',\n 'generic',\n 'genfromtxt',\n 'geomspace',\n 'get_array_wrap',\n 'get_include',\n 'get_printoptions',\n 'getbufsize',\n 'geterr',\n 'geterrcall',\n 'geterrobj',\n 'gradient',\n 'greater',\n 'greater_equal',\n 'half',\n 'hamming',\n 'hanning',\n 'heaviside',\n 'histogram',\n 'histogram2d',\n 'histogram_bin_edges',\n 'histogramdd',\n 'hsplit',\n 'hstack',\n 'hypot',\n 'i0',\n 'identity',\n 'iinfo',\n 'imag',\n 'in1d',\n 'index_exp',\n 'indices',\n 'inexact',\n 'inf',\n 'info',\n 'infty',\n 'inner',\n 'insert',\n 'int16',\n 'int32',\n 'int64',\n 'int8',\n 'int_',\n 'intc',\n 'integer',\n 'interp',\n 'intersect1d',\n 'intp',\n 'invert',\n 'is_busday',\n 'isclose',\n 'iscomplex',\n 'iscomplexobj',\n 'isfinite',\n 'isfortran',\n 'isin',\n 'isinf',\n 'isnan',\n 'isnat',\n 'isneginf',\n 'isposinf',\n 'isreal',\n 'isrealobj',\n 'isscalar',\n 'issctype',\n 'issubclass_',\n 'issubdtype',\n 'issubsctype',\n 'iterable',\n 'ix_',\n 'kaiser',\n 'kernel_version',\n 'kron',\n 'lcm',\n 'ldexp',\n 'left_shift',\n 'less',\n 'less_equal',\n 'lexsort',\n 'lib',\n 'linalg',\n 'linspace',\n 'little_endian',\n 'load',\n 'loadtxt',\n 'log',\n 'log10',\n 'log1p',\n 'log2',\n 'logaddexp',\n 'logaddexp2',\n 'logical_and',\n 'logical_not',\n 'logical_or',\n 'logical_xor',\n 'logspace',\n 'longcomplex',\n 'longdouble',\n 'longfloat',\n 'longlong',\n 'lookfor',\n 'ma',\n 'mask_indices',\n 'mat',\n 'math',\n 'matmul',\n 'matrix',\n 'max',\n 'maximum',\n 'maximum_sctype',\n 'may_share_memory',\n 'mean',\n 'median',\n 'memmap',\n 'meshgrid',\n 'mgrid',\n 'min',\n 'min_scalar_type',\n 'minimum',\n 'mintypecode',\n 'mod',\n 'modf',\n 'moveaxis',\n 'msort',\n 'multiply',\n 'nan',\n 'nan_to_num',\n 'nanargmax',\n 'nanargmin',\n 'nancumprod',\n 'nancumsum',\n 'nanmax',\n 'nanmean',\n 'nanmedian',\n 'nanmin',\n 'nanpercentile',\n 'nanprod',\n 'nanquantile',\n 'nanstd',\n 'nansum',\n 'nanvar',\n 'nbytes',\n 'ndarray',\n 'ndenumerate',\n 'ndim',\n 'ndindex',\n 'nditer',\n 'negative',\n 'nested_iters',\n 'newaxis',\n 'nextafter',\n 'nonzero',\n 'not_equal',\n 'numarray',\n 'number',\n 'obj2sctype',\n 'object_',\n 'ogrid',\n 'oldnumeric',\n 'ones',\n 'ones_like',\n 'outer',\n 'packbits',\n 'pad',\n 'partition',\n 'percentile',\n 'pi',\n 'piecewise',\n 'place',\n 'poly',\n 'poly1d',\n 'polyadd',\n 'polyder',\n 'polydiv',\n 'polyfit',\n 'polyint',\n 'polymul',\n 'polynomial',\n 'polysub',\n 'polyval',\n 'positive',\n 'power',\n 'printoptions',\n 'prod',\n 'product',\n 'promote_types',\n 'ptp',\n 'put',\n 'put_along_axis',\n 'putmask',\n 'quantile',\n 'r_',\n 'rad2deg',\n 'radians',\n 'random',\n 'ravel',\n 'ravel_multi_index',\n 'real',\n 'real_if_close',\n 'rec',\n 'recarray',\n 'recfromcsv',\n 'recfromtxt',\n 'reciprocal',\n 'record',\n 'remainder',\n 'repeat',\n 'require',\n 'reshape',\n 'resize',\n 'result_type',\n 'right_shift',\n 'rint',\n 'roll',\n 'rollaxis',\n 'roots',\n 'rot90',\n 'round',\n 'round_',\n 'row_stack',\n 's_',\n 'safe_eval',\n 'save',\n 'savetxt',\n 'savez',\n 'savez_compressed',\n 'sctype2char',\n 'sctypeDict',\n 'sctypes',\n 'searchsorted',\n 'select',\n 'set_numeric_ops',\n 'set_printoptions',\n 'set_string_function',\n 'setbufsize',\n 'setdiff1d',\n 'seterr',\n 'seterrcall',\n 'seterrobj',\n 'setxor1d',\n 'shape',\n 'shares_memory',\n 'short',\n 'show_config',\n 'show_runtime',\n 'sign',\n 'signbit',\n 'signedinteger',\n 'sin',\n 'sinc',\n 'single',\n 'singlecomplex',\n 'sinh',\n 'size',\n 'sometrue',\n 'sort',\n 'sort_complex',\n 'source',\n 'spacing',\n 'split',\n 'sqrt',\n 'square',\n 'squeeze',\n 'stack',\n 'std',\n 'str_',\n 'string_',\n 'subtract',\n 'sum',\n 'swapaxes',\n 'take',\n 'take_along_axis',\n 'tan',\n 'tanh',\n 'tensordot',\n 'test',\n 'testing',\n 'tile',\n 'timedelta64',\n 'trace',\n 'tracemalloc_domain',\n 'transpose',\n 'trapz',\n 'tri',\n 'tril',\n 'tril_indices',\n 'tril_indices_from',\n 'trim_zeros',\n 'triu',\n 'triu_indices',\n 'triu_indices_from',\n 'true_divide',\n 'trunc',\n 'typecodes',\n 'typename',\n 'ubyte',\n 'ufunc',\n 'uint',\n 'uint16',\n 'uint32',\n 'uint64',\n 'uint8',\n 'uintc',\n 'uintp',\n 'ulonglong',\n 'unicode_',\n 'union1d',\n 'unique',\n 'unpackbits',\n 'unravel_index',\n 'unsignedinteger',\n 'unwrap',\n 'use_hugepage',\n 'ushort',\n 'vander',\n 'var',\n 'vdot',\n 'vectorize',\n 'version',\n 'void',\n 'vsplit',\n 'vstack',\n 'where',\n 'who',\n 'zeros',\n 'zeros_like']\n\n\n\nnumpy.__dir__\n\n&lt;function numpy.__dir__()&gt;\n\n\n\nTo list every element in your symbol table simply call dir().\nReference: Python doc the dir function\n\n\n\nA namespace is a set of names (functions, variables, etc.). Different namespaces can co-exist at a given time but are completely isolated. In this way, you can control which function you are using.\nA namespace containing all the built-in names is created when we start the python interpreter and exists as long we don‚Äôt exit.\n\ncos(3)\n\nNameError: name 'cos' is not defined\n\n\nYou need to import a package for mathematical functions:\n\nimport math, numpy as np\nprint(math.cos(3), np.cos(3))\n\n-0.9899924966004454 -0.9899924966004454\n\n\nReference: Python Namespace and Scope tutorial\n\n\n\nWhen a module named spam is imported, the interpreter first searches for a built-in module with that name. If not found, it then searches for a file named spam.py in a list of directories given by the variable sys.path. The variable sys.path is initialized from these locations:\n\nThe directory containing the input script (or the current directory when no file is specified).\nThe environment variable PYTHONPATH (a list of directory names, with the same syntax as the shell variable PATH).\n\nReference: Python documentation, The Module Search Path\n\n\n\nFind the loader for a module, optionally within the specified path.\n\nimport importlib\nspam_spec = importlib.util.find_spec(\"spam\")\nfound = spam_spec is not None\nprint(found)\n\nFalse\n\n\nNow,\n\nimport numpy\nnumpy_spec = importlib.util.find_spec(\"numpy\")\nprint(numpy_spec)\n\nModuleSpec(name='numpy', loader=&lt;_frozen_importlib_external.SourceFileLoader object at 0x7f08fdf021a0&gt;, origin='/home/jsalmon/anaconda3/envs/peerannot/lib/python3.10/site-packages/numpy/__init__.py', submodule_search_locations=['/home/jsalmon/anaconda3/envs/peerannot/lib/python3.10/site-packages/numpy'])\n\n\nshould return more information and where the loader is.\nReferences:\n\nPython doc on find_loader\nHow to check if a Python module exists without importing it on Stackoverflow\n\n\n\n\nA module can contain executable statements as well as function definitions. These statements are intended to initialize the module. They are executed only the first time the module name is encountered in an import statement.\nTo force a module to be reloaded, you can use importlib.reload().\nReference: Python doc on reload\nRemark: when using ipython (interactive python, an ancestor of the jupyter notebook), one can use the ‚Äúmagic‚Äù command %autoreload 2\nReference: IPython autoreload\n\n\n\nTo speed up loading modules, python caches the compiled version of each module in the __pycache__ directory under the name module.version.pyc, where the version encodes the format of the compiled file; it generally contains the python version number.\nFor example, in CPython release 3.3 the compiled version of spam.py would be cached as __pycache__/spam.cpython-33.pyc. This naming convention allows compiled modules from different releases and different versions of python to coexist.\n\n\n\n\n\n\nUseful git tip\n\n\n\nYou should add __pycache__ entry in your .gitignore file to avoid adding a compiled python file to your project."
  },
  {
    "objectID": "Courses/Python-modules/tp.html#the-python-package-index-pypi-repository",
    "href": "Courses/Python-modules/tp.html#the-python-package-index-pypi-repository",
    "title": "Creating a python module",
    "section": "The python Package Index (Pypi) repository",
    "text": "The python Package Index (Pypi) repository\nThe python Package Index, abbreviated as PyPI, is the official third-party software repository for python. PyPI primarily hosts python packages in the form of archives called sdists (source distributions) or pre-compiled ‚Äúwheels‚Äù.\n\n\n\n\n\n\nEXERCISE: pypi\n\n\n\n\nGo to https://test.pypi.org/ and describe the aim of this repository.\n\n\n\n\nPip\npip is a de facto standard package-management system used to install and manage software packages from PyPi.\n$ pip install some-package-name\n$ pip uninstall some-package-name\n$ pip search some-package-name\n\n\n\n\n\n\nEXERCISE:\n\n\n\n\nInstall the modules pooch, setuptools, pandas, pygal and pygal_maps_fr. Beware, you should use the option --user to force the installation in your home directory.\nList all the package in your venv using pip.\n\n\n\nIt is possible to install a local module with pip\n$ pip install /path/to/my/local/module\nwhere /path/to/my/local/module is the path to the module. But if some changes occur in the /path/to/my/local/module folder, the module will not be reloaded. This might be annoying during the development stage. To force python to reload the module at each change call, consider the -e option:\n$ pip install -e /path/to/my/local/module"
  },
  {
    "objectID": "Courses/Python-modules/tp.html#creating-a-python-module",
    "href": "Courses/Python-modules/tp.html#creating-a-python-module",
    "title": "Creating a python module",
    "section": "Creating a python module",
    "text": "Creating a python module\nReference: How To Package Your Python Code\n\nPicking A Name\npython module/package names should generally follow the following constraints:\n\nAll lowercase\nUnique on PyPI, even if you do not want to make your package publicly available (you might want to specify it privately as a dependency later)\nUnderscore-separated or no word separators at all, and do not use hyphens (i.e., use _ not -).\n\nWe are going to create a module called biketrauma to visualize the bicycle_db (source here) used in the some of these lectures.\n\n\nModule structure\nThe initial directory structure for biketrauma should look like this:\npackaging_tutorial/\n    biketrauma/\n        __init__.py\n        data/\n    setup.py\n    .gitignore\nThe top-level directory is the root of our Version Control System (e.g.¬†git) repository packaging_tutorial.git. The sub-directory, biketrauma, is the actual python module.\n\n\n\n\n\n\nEXERCISE: packaging\n\n\n\nWe are going to create a new python module that can be used to visualize the bike dataset.\n\nCreate a new folder ~/packaging_tutorial/ and initialize a git in it.\nCreate a .gitignore file to ignore __pycache__, .vscode directories and files containing the string egg-info or dist in their name as well.\nPush your work into a new repository on your github.\nCreate a sub-folder ~/packaging_tutorial/biketrauma. This is where our python module will be stored.\nCreate a ~/packaging_tutorial/biketrauma/__init__.py file where a string __version__ defined at 0.0.1.\nCreate an empty sub-folder ~/packaging_tutorial/biketrauma/data locally on your computer/session. How to add it to git? (Hint: .gitkeep)\nCreate an empty ~/packaging_tutorial/setup.py file.\nCommit and push into your repository.\n\nReference: Single-sourcing the package version.\n\n\n\n\nSub-modules\nThe final directory structure of our module will look like:\n  packaging_tutorial/\n      biketrauma/\n          __init__.py\n          io/\n            __init__.py\n          preprocess/\n            __init__.py\n          vis/\n            __init__.py\n          data/\n      setup.py\n      script.py\n\n\n\n\n\n\nEXERCISE: modules\n\n\n\nAdd some python files in the modules_files folder:\n\nAdd some sub-folders to biketrauma called io (for input/output), preprocess, vis (for visualization). Copy the script.py into the root folder.\nPopulate the preprocess sub-module with the get_accident.py file (see the git repo of the course in the subfolder Courses/Python-modules/modules_files)\nPopulate the vis sub-module with the plot_location.py file\nPopulate the io sub-module with the file Load_db.py (it downloads the bike data-set). At the loading step your sub-module should create the variables\n\n\n\nurl_db = \"https://koumoul.com/s/data-fair/api/v1/datasets/accidents-velos/raw\"\npath_target = os.path.join(os.path.dirname(os.path.realpath(__file__)), \"..\", \"data\", \"bicycle_db.csv\")\n\n\nAdding additional files\nIn order to load the functions in the io, preprocess and vis sub-modules, you can add the following lines to the ~/packaging_tutorial/biketrauma/__init__.py:\nfrom .io.Load_db import Load_db\nfrom .vis.plot_location import plot_location\nfrom .preprocess.get_accident import get_accident\n\n\n\n\n\n\nEXERCISE:\n\n\n\n\nCheck that your module does work by launching the script.py script\nCreate a file format_date.py in the biketrauma.preprocess module in which a function format_date format the date of the data-set in international format.\nThis function should accessible with the command:\n\n&gt;&gt;&gt;import biketrauma\n&gt;&gt;&gt;df = biketrauma.Load_db().save_as_df()\n&gt;&gt;&gt;df_nicely_formated = biketrauma.format_date(df)\n\n\n\n\nPackage the module with setuptools\nThe main setup configuration file, setup.py, should contain a single call to setuptools.setup(), like so:\nfrom setuptools import setup\nfrom biketrauma import __version__ as current_version\n\nsetup(\n  name='biketrauma',\n  version=current_version,\n  description='Visualization of a bicycle accident db',\n  url='http://github.com/xxxxxxxxxxx.git',\n  author='xxxxxxxxxxx',\n  author_email='xxxxxxxxxx@xxxxxxxxxxxxx.xxx',\n  license='MIT',\n  packages=['biketrauma','biketrauma.io', 'biketrauma.preprocess', 'biketrauma.vis'],\n  zip_safe=False\n)\nTo create a sdist package (a source distribution):\n$ cd ~/packaging_tutorial/\n$ python setup.py sdist\nThis will create dist/biketrauma-0.0.1.tar.gz inside the top-level directory. You can now install it with\n$ pip install ~/packaging_tutorial/dist/biketrauma-0.0.1.tar.gz\nReferences::\n\nBuilding and Distributing Packages with Setuptools\nPackaging Python Projects\n\n\n\nAdd requirement file\nTo get a list of the installed packages in your current venv, you can use the following command:\n$ pip freeze &gt; requirements.txt\nUnfortunately, it may generate a huge collection of package dependencies. To get a sparser list, you can use pipreqs.\n\n\n\n\n\n\nEXERCISE: requirements\n\n\n\nCreate a minimal requirements.txt file with pipreqs. Add it to the biketrauma module.\n\n\n\n\nUpload on PyPI\ntwine is a utility for publishing python packages on PyPI. We are going to use the test repository https://test.pypi.org/.\n\n\n\n\n\n\nEXERCISE:\n\n\n\n\nCreate an account on the PyPI test repository\n\nThis is quite easy to upload a python module on PyPI:\n\nCreate some distributions in the normal way:\n\n$ python setup.py sdist bdist_wheel\n\nUpload with twine to Test PyPI and verify things look right. Twine will automatically prompt for your username and password:\n\n$ twine upload --repository-url https://test.pypi.org/legacy/ dist/*\nusername: ...\npassword: ...\n\nUpload to PyPI:\n\n$ twine upload dist/*\n\n\nReferences:\n\nPython Packaging User Guide\nTwine, uploads of source, provides additional documentation on using twine to upload packages to PyPI."
  },
  {
    "objectID": "Courses/Numpy/tp.html",
    "href": "Courses/Numpy/tp.html",
    "title": "Numpy cheat sheet",
    "section": "",
    "text": "Preliminary remark: for the random part, one is expected to run a command like\nimport numpy as np\nrng = np.random.default_rng(12)\nbefore anything, to initialize the random generator rng.\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\n\n\nResult\n\n\n\n\n\n\n x = np.zeros(9) \n\n\n\n\n\n\n\n x = np.ones(9)\n\n\n\n\n\n\n\n x = np.full(9, 0.5)\n\n\n\n\n\n\n\n x = np.zeros(9)\n x[2] = 0\n        \n\n\n\n\n\n\n\n x = np.arange(9)\n\n\n\n\n\n\n\n x[::-1]\n\n\n\n\n\n\n\n x = rng.random(9)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\n\n\nResult\n\n\n\n\n\n\n M = np.zeros((5, 9)) \n\n\n\n\n\n\n\n M = np.ones((5, 9))\n\n\n\n\n\n\n\n M = np.zeros((5, 9))\n M[0, 2] = 0.5\n M[1, 0] = 1.\n M[2, 1] = 0.4\n            \n\n\n\n\n\n\n\n M = np.arange(45).reshape((5, 9))\n\n\n\n\n\n\n\n M = rng.random((5, 9))\n\n\n\n\n\n\n\n M = np.eye(5, 9)\n\n\n\n\n\n\n\n M = np.diag(np.arange(5))\n\n\n\n\n\n\n\n\n\n M = np.diag(np.arange(3), k=2)\n\n\n\n\n\n\n\n\n\n\n\n\n\nnx, ny = (8, 3)\nx = np.linspace(0, 1, nx)\ny = np.linspace(0, 1, ny)\nxx, yy = np.meshgrid(x, y)\n\n\n\n\n\nx\n\n\ny\n\n\nxx\n\n\nyy\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\n\n\nResult\n\n\n\n\n\n\n T = np.zeros((3, 5, 9)) \n\n\n\n\n\n\n\n T = np.ones((3, 5, 9))\n\n\n\n\n\n\n\n T = np.arange(135).reshape(3, 5, 9)\n\n\n\n\n\n\n\n T = rng.random((3, rows, cols))\n\n\n\n\n\n\n\n\nn1, n2 = 5, 3\nones = np.ones((n2, n1))\nones = ones[:, :, np.newaxis]\nlnsp = np.linspace(0.01, 0.99, 8)\nT = ones * lnsp\n        \n\n\n\n\n\n\n\n\n\n\n\n\nWe start here with\nM = np.zeros((3, 4))\nM[2, 2] = 1\n\n\n\nStarting from the previous matrix, we can reshape it in different ways:\n\n\n\n\n\nCode\n\n\nResult\n\n\n\n\n\n\nM = M.reshape(4, 3)\n\n\n\n\n\n\n\nM = M.reshape(12, 1)\n\n\n\n\n\n\n\nM = M.reshape(1, 12)\n\n\n\n\n\n\n\nM = M.reshape(6, 2)\n\n\n\n\n\n\n\nM = M.reshape(2, 6)\n\n\n\n\n\n\n\n\n\n\n\nStart from a zero matrix:\nM = np.zeros((5, 9))\n\n\n\nStarting from the previous matrix, we can slice it in different ways:\n\n\n\n\n\nCode\n\n\nResult\n\n\n\n\n\n\nM[...] = 1 \n\n\n\n\n\n\n\nM[:, ::2] = 1\n\n\n\n\n\n\n\nM[::2, :] = 1\n\n\n\n\n\n\n\nM[1, 1] = 1\n\n\n\n\n\n\n\nM[:, 0] = 1\n\n\n\n\n\n\n\nM[0, :] = 1\n\n\n\n\n\n\n\nM[2:; 2:] = 1\n\n\n\n\n\n\n\nM[:-2:, :-2] = 1\n\n\n\n\n\n\n\nM[2:4, 2:4] = 1\n\n\n\n\n\n\n\nM[::2, ::2] = 1\n\n\n\n\n\n\n\nM[3::2, 3::2] = 1\n\n\n\n\n\n\n\n\n\n\n\nStart from a simple matrix:\nrows, cols = 3, 6\nM = np.linspace(0, 1, rows * cols).reshape(rows, cols)\n\n\n\nStarting from the previous matrix, we can apply the following operations:\n\n\n\n\n\nCode\n\n\nResult\n\n\n\n\n\n\n M.T \n\n\n\n\n\n\n\n\n\n M[::-1, :] \n\n\n\n\n\n\n\n\n\n M[:, ::-1] \n\n\n\n\n\n\n\n\n\nnp.where(M &gt; 0.5, 0, 1) \n\n\n\n\n\n\n\n\n\nnp.maximum(M, 0.5) \n\n\n\n\n\n\n\n\n\nnp.minimum(M, 0.5) \n\n\n\n\n\n\n\n\n\nnp.mean(M, axis=0) \n\n\n\n\n\n\n\n\n\nnp.mean(M, axis=1) \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nFor the last operations note that the dimensions of the matrices are reduced, so you create a vector as a result, with dimensions (6,) or (3,) respectively, when computing the mean along the 0-axis (column-wise mean), respectively along the 1-axis (row-wise mean).\n\n\n\n\n\nBroadcasting allows the addition of matrices of different sizes (though this is mathematically wrong), by repeating the smaller ones along the missing dimensions. The only requirement is that the trailing (i.e, rightmost) dimensions match, somehow.\n\n\n\n\n\nM\n\n\nN\n\n\nM+N\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThis work is deeply inspired and adapted from the great work by Nicolas Rougier: https://github.com/rougier/numpy-tutorial"
  },
  {
    "objectID": "Courses/Numpy/tp.html#matrix-creation",
    "href": "Courses/Numpy/tp.html#matrix-creation",
    "title": "Numpy cheat sheet",
    "section": "",
    "text": "Code\n\n\nResult\n\n\n\n\n\n\n x = np.zeros(9) \n\n\n\n\n\n\n\n x = np.ones(9)\n\n\n\n\n\n\n\n x = np.full(9, 0.5)\n\n\n\n\n\n\n\n x = np.zeros(9)\n x[2] = 0\n        \n\n\n\n\n\n\n\n x = np.arange(9)\n\n\n\n\n\n\n\n x[::-1]\n\n\n\n\n\n\n\n x = rng.random(9)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\n\n\nResult\n\n\n\n\n\n\n M = np.zeros((5, 9)) \n\n\n\n\n\n\n\n M = np.ones((5, 9))\n\n\n\n\n\n\n\n M = np.zeros((5, 9))\n M[0, 2] = 0.5\n M[1, 0] = 1.\n M[2, 1] = 0.4\n            \n\n\n\n\n\n\n\n M = np.arange(45).reshape((5, 9))\n\n\n\n\n\n\n\n M = rng.random((5, 9))\n\n\n\n\n\n\n\n M = np.eye(5, 9)\n\n\n\n\n\n\n\n M = np.diag(np.arange(5))\n\n\n\n\n\n\n\n\n\n M = np.diag(np.arange(3), k=2)\n\n\n\n\n\n\n\n\n\n\n\n\n\nnx, ny = (8, 3)\nx = np.linspace(0, 1, nx)\ny = np.linspace(0, 1, ny)\nxx, yy = np.meshgrid(x, y)\n\n\n\n\n\nx\n\n\ny\n\n\nxx\n\n\nyy\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\n\n\nResult\n\n\n\n\n\n\n T = np.zeros((3, 5, 9)) \n\n\n\n\n\n\n\n T = np.ones((3, 5, 9))\n\n\n\n\n\n\n\n T = np.arange(135).reshape(3, 5, 9)\n\n\n\n\n\n\n\n T = rng.random((3, rows, cols))\n\n\n\n\n\n\n\n\nn1, n2 = 5, 3\nones = np.ones((n2, n1))\nones = ones[:, :, np.newaxis]\nlnsp = np.linspace(0.01, 0.99, 8)\nT = ones * lnsp"
  },
  {
    "objectID": "Courses/Numpy/tp.html#matrix-reshaping",
    "href": "Courses/Numpy/tp.html#matrix-reshaping",
    "title": "Numpy cheat sheet",
    "section": "",
    "text": "We start here with\nM = np.zeros((3, 4))\nM[2, 2] = 1\n\n\n\nStarting from the previous matrix, we can reshape it in different ways:\n\n\n\n\n\nCode\n\n\nResult\n\n\n\n\n\n\nM = M.reshape(4, 3)\n\n\n\n\n\n\n\nM = M.reshape(12, 1)\n\n\n\n\n\n\n\nM = M.reshape(1, 12)\n\n\n\n\n\n\n\nM = M.reshape(6, 2)\n\n\n\n\n\n\n\nM = M.reshape(2, 6)"
  },
  {
    "objectID": "Courses/Numpy/tp.html#slicing",
    "href": "Courses/Numpy/tp.html#slicing",
    "title": "Numpy cheat sheet",
    "section": "",
    "text": "Start from a zero matrix:\nM = np.zeros((5, 9))\n\n\n\nStarting from the previous matrix, we can slice it in different ways:\n\n\n\n\n\nCode\n\n\nResult\n\n\n\n\n\n\nM[...] = 1 \n\n\n\n\n\n\n\nM[:, ::2] = 1\n\n\n\n\n\n\n\nM[::2, :] = 1\n\n\n\n\n\n\n\nM[1, 1] = 1\n\n\n\n\n\n\n\nM[:, 0] = 1\n\n\n\n\n\n\n\nM[0, :] = 1\n\n\n\n\n\n\n\nM[2:; 2:] = 1\n\n\n\n\n\n\n\nM[:-2:, :-2] = 1\n\n\n\n\n\n\n\nM[2:4, 2:4] = 1\n\n\n\n\n\n\n\nM[::2, ::2] = 1\n\n\n\n\n\n\n\nM[3::2, 3::2] = 1"
  },
  {
    "objectID": "Courses/Numpy/tp.html#operations-on-matrices",
    "href": "Courses/Numpy/tp.html#operations-on-matrices",
    "title": "Numpy cheat sheet",
    "section": "",
    "text": "Start from a simple matrix:\nrows, cols = 3, 6\nM = np.linspace(0, 1, rows * cols).reshape(rows, cols)\n\n\n\nStarting from the previous matrix, we can apply the following operations:\n\n\n\n\n\nCode\n\n\nResult\n\n\n\n\n\n\n M.T \n\n\n\n\n\n\n\n\n\n M[::-1, :] \n\n\n\n\n\n\n\n\n\n M[:, ::-1] \n\n\n\n\n\n\n\n\n\nnp.where(M &gt; 0.5, 0, 1) \n\n\n\n\n\n\n\n\n\nnp.maximum(M, 0.5) \n\n\n\n\n\n\n\n\n\nnp.minimum(M, 0.5) \n\n\n\n\n\n\n\n\n\nnp.mean(M, axis=0) \n\n\n\n\n\n\n\n\n\nnp.mean(M, axis=1) \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nFor the last operations note that the dimensions of the matrices are reduced, so you create a vector as a result, with dimensions (6,) or (3,) respectively, when computing the mean along the 0-axis (column-wise mean), respectively along the 1-axis (row-wise mean)."
  },
  {
    "objectID": "Courses/Numpy/tp.html#broadcasting",
    "href": "Courses/Numpy/tp.html#broadcasting",
    "title": "Numpy cheat sheet",
    "section": "",
    "text": "Broadcasting allows the addition of matrices of different sizes (though this is mathematically wrong), by repeating the smaller ones along the missing dimensions. The only requirement is that the trailing (i.e, rightmost) dimensions match, somehow.\n\n\n\n\n\nM\n\n\nN\n\n\nM+N"
  },
  {
    "objectID": "Courses/Numpy/tp.html#resources",
    "href": "Courses/Numpy/tp.html#resources",
    "title": "Numpy cheat sheet",
    "section": "",
    "text": "This work is deeply inspired and adapted from the great work by Nicolas Rougier: https://github.com/rougier/numpy-tutorial"
  },
  {
    "objectID": "Courses/TimeMemory/tp.html",
    "href": "Courses/TimeMemory/tp.html",
    "title": "Time & memory efficiency",
    "section": "",
    "text": "import time\nimport numpy as np\nimport matplotlib.pyplot as plt"
  },
  {
    "objectID": "Courses/TimeMemory/tp.html#timecomputation-usage-of-timeit",
    "href": "Courses/TimeMemory/tp.html#timecomputation-usage-of-timeit",
    "title": "Time & memory efficiency",
    "section": "Time/computation: usage of %timeit",
    "text": "Time/computation: usage of %timeit\nReferences:\n\nBuilt-in magic commands\nautoreload\n\nmagic commands are IPython commands such as: %timeit, %matplotlib, %autoreload. They work only in interactive cases (Ipython, Notebook, Jupyter lab etc.).\n\nn = 1000\nval = 5.4\n\n\n%timeit a = np.empty(n); a.fill(val)\n# Alternative: uncomment below\n# get_ipython().run_line_magic('timeit', 'a = np.empty(n); a.fill(val)')\n\n800 ns ¬± 17.3 ns per loop (mean ¬± std. dev. of 7 runs, 1,000,000 loops each)\n\n\n\nprint('empty')\n%timeit a = np.empty(n); a[:] = val\n\nempty\n984 ns ¬± 18.1 ns per loop (mean ¬± std. dev. of 7 runs, 1,000,000 loops each)\n\n\nprint('full')\n\n%timeit a = np.full((n,), val)\n\n2.04 ¬µs ¬± 6.07 ns per loop (mean ¬± std. dev. of 7 runs, 100,000 loops each)\n\n\n\nprint('ones')\n\nones\n\n\n\n%timeit a = np.ones(n) * val\n\n4.2 ¬µs ¬± 50.2 ns per loop (mean ¬± std. dev. of 7 runs, 100,000 loops each)\n\n\n\nprint('repeat')\n\nrepeat\n\n\n\n%timeit a = np.repeat(val, n)\n\n5.83 ¬µs ¬± 42.1 ns per loop (mean ¬± std. dev. of 7 runs, 100,000 loops each)"
  },
  {
    "objectID": "Courses/TimeMemory/tp.html#alternatives",
    "href": "Courses/TimeMemory/tp.html#alternatives",
    "title": "Time & memory efficiency",
    "section": "Alternatives",
    "text": "Alternatives\nUse the time module thanks to import time\n\nimport time\nstart = time.time()\na = np.ones(n) * val\nend = time.time()\nprint(\"Time to execute the command: {0:.5f} s.\".format(end - start))\n\nTime to execute the command: 0.00012 s."
  },
  {
    "objectID": "Courses/TimeMemory/tp.html#sparse-matrices-graphs-and-memory",
    "href": "Courses/TimeMemory/tp.html#sparse-matrices-graphs-and-memory",
    "title": "Time & memory efficiency",
    "section": "Sparse matrices, graphs and memory",
    "text": "Sparse matrices, graphs and memory\nSparse matrices are useful to handle potentially huge matrices, that have only a few non-zero coefficients:\n\nScipy Lectures: why sparse matrices\nSparse data structures in Python, by Artem Golubin\nIntroduction to Sparse Matrices in Python with SciPy, by cmdlinetips\n\nExamples:\n\nNatural language processing: We encode the presence of a word from a dictionary (let‚Äôs say the set of French words) and we put 0 / 1 in case of absence/presence of a word.\nOne-hot encoding, used to represent categorical data as sparse binary vectors.\nthe discretization of a physical system where very distant influences are set to zero (e.g.¬†heat diffusion, fluid mechanics, electro/magnetism, etc.)\nGraphs: they are naturally represented by adjacency or incidence matrices (cf. below), and therefore beyond the graphs, maps!\n\n\nMost common formats\n\ncoo_matrix(arg1[, shape, dtype, copy]): A sparse matrix in COOrdinate format.\ncsc_matrix(arg1[, shape, dtype, copy]): Compressed Sparse Column matrix\ncsr_matrix(arg1[, shape, dtype, copy]): Compressed Sparse Row matrix\n\nReferences:\n\nScipy doc on sparse matrices\n\n\nfrom scipy import sparse\nfrom scipy.sparse import isspmatrix\n\nId = sparse.eye(3)\nprint(Id.toarray())\nprint(f'Q: Is the matrix Id is sparse?\\nA: {isspmatrix(Id)}')\n\nn1 = 29\nn2 = 29\nmat_rnd = sparse.rand(n1, n2, density=0.25, format=\"csr\",\n                      random_state=42)\nprint(mat_rnd.toarray())\nprint(f'Q: Is the matrix mat_rnd is sparse?\\nA: {isspmatrix(mat_rnd)}')\n\n[[1. 0. 0.]\n [0. 1. 0.]\n [0. 0. 1.]]\nQ: Is the matrix Id is sparse?\nA: True\n[[0.         0.68298206 0.         0.         0.         0.\n  0.14312799 0.         0.         0.         0.         0.\n  0.         0.         0.         0.         0.4878098  0.\n  0.         0.35599148 0.10221266 0.         0.56550835 0.7677795\n  0.42359686 0.2253328  0.         0.53648135 0.        ]\n [0.         0.5344235  0.         0.         0.         0.\n  0.         0.39148211 0.         0.         0.84444067 0.\n  0.         0.         0.         0.         0.09229059 0.50610396\n  0.         0.         0.10424697 0.         0.         0.\n  0.         0.         0.         0.         0.        ]\n [0.77857194 0.82086147 0.77124667 0.         0.90786613 0.\n  0.         0.         0.         0.         0.13311693 0.\n  0.99769262 0.         0.         0.         0.         0.00530001\n  0.         0.         0.         0.         0.92404176 0.00259502\n  0.50228835 0.         0.08786811 0.33034848 0.        ]\n [0.         0.         0.         0.         0.         0.01220307\n  0.         0.         0.         0.         0.         0.\n  0.         0.         0.         0.         0.         0.\n  0.         0.         0.         0.         0.         0.5938831\n  0.         0.         0.         0.         0.        ]\n [0.         0.7228961  0.         0.         0.14773909 0.\n  0.         0.         0.         0.         0.05565349 0.\n  0.32158276 0.         0.         0.20454459 0.57748627 0.40851829\n  0.         0.         0.         0.01824248 0.         0.\n  0.         0.         0.23569175 0.20173046 0.        ]\n [0.13882477 0.         0.03047215 0.         0.         0.\n  0.         0.97506716 0.         0.16552051 0.         0.\n  0.         0.82679883 0.         0.36923048 0.         0.\n  0.         0.         0.         0.         0.         0.\n  0.         0.83858256 0.         0.         0.54871531]\n [0.         0.         0.         0.         0.         0.\n  0.         0.75995541 0.         0.         0.4519486  0.\n  0.         0.         0.         0.         0.9106862  0.\n  0.         0.12281078 0.         0.         0.         0.59902936\n  0.         0.         0.         0.11669606 0.        ]\n [0.16673076 0.         0.37728597 0.         0.         0.\n  0.         0.33281579 0.56396509 0.         0.         0.69696146\n  0.         0.         0.         0.         0.         0.20507756\n  0.         0.37877263 0.         0.79428945 0.         0.\n  0.         0.         0.         0.         0.        ]\n [0.         0.         0.35414667 0.         0.         0.\n  0.         0.24435316 0.         0.         0.         0.95907479\n  0.         0.         0.         0.         0.         0.\n  0.35536245 0.33009951 0.         0.         0.         0.86721498\n  0.         0.         0.         0.         0.        ]\n [0.         0.         0.23321641 0.89421726 0.         0.\n  0.         0.53126575 0.         0.         0.49542363 0.18228388\n  0.71378245 0.         0.         0.20500181 0.         0.\n  0.         0.         0.         0.         0.         0.22902539\n  0.         0.         0.         0.         0.        ]\n [0.78151448 0.08451701 0.         0.10669925 0.         0.84231404\n  0.         0.79008464 0.         0.         0.79953713 0.\n  0.         0.         0.         0.         0.         0.\n  0.         0.         0.36535682 0.         0.         0.75240312\n  0.         0.         0.         0.         0.        ]\n [0.         0.         0.         0.         0.         0.\n  0.         0.         0.         0.         0.         0.\n  0.         0.         0.84070999 0.         0.         0.\n  0.         0.         0.         0.         0.         0.\n  0.         0.         0.         0.87862912 0.        ]\n [0.         0.         0.         0.         0.         0.\n  0.         0.86830111 0.1287484  0.         0.         0.45700022\n  0.43152814 0.         0.         0.0230226  0.         0.\n  0.39716383 0.         0.         0.52984002 0.         0.71845727\n  0.         0.         0.69371761 0.         0.        ]\n [0.         0.         0.         0.         0.         0.\n  0.         0.         0.         0.         0.         0.\n  0.4982477  0.         0.         0.68778472 0.47661948 0.\n  0.7072301  0.         0.         0.58419948 0.53533556 0.\n  0.73682248 0.         0.         0.91875052 0.        ]\n [0.         0.         0.19950693 0.74146091 0.         0.\n  0.         0.         0.         0.06234136 0.         0.06661911\n  0.60395787 0.         0.70698046 0.         0.3551043  0.\n  0.4731662  0.         0.         0.34252426 0.08920433 0.\n  0.         0.72051606 0.         0.         0.        ]\n [0.         0.         0.         0.         0.         0.\n  0.         0.75463529 0.73054914 0.         0.         0.73740521\n  0.60610188 0.         0.         0.         0.         0.\n  0.37882157 0.         0.72609559 0.         0.         0.84043963\n  0.         0.         0.         0.         0.00753436]\n [0.         0.         0.         0.         0.         0.\n  0.         0.         0.         0.         0.48635748 0.\n  0.         0.23590603 0.71406408 0.92644942 0.         0.\n  0.         0.         0.         0.         0.         0.\n  0.         0.37922858 0.         0.         0.53503673]\n [0.         0.         0.         0.         0.22735098 0.\n  0.         0.         0.         0.         0.         0.\n  0.         0.         0.         0.         0.         0.\n  0.31619658 0.49398149 0.         0.         0.         0.\n  0.         0.         0.         0.56445854 0.        ]\n [0.         0.         0.74597453 0.         0.         0.\n  0.59727808 0.         0.15697768 0.         0.         0.\n  0.         0.         0.         0.13911619 0.         0.\n  0.         0.         0.         0.         0.59296291 0.\n  0.         0.45426797 0.         0.         0.        ]\n [0.         0.         0.73624718 0.         0.         0.\n  0.         0.         0.         0.         0.         0.\n  0.18632088 0.         0.         0.         0.58830668 0.82513268\n  0.72159655 0.91739561 0.         0.8996474  0.         0.\n  0.         0.         0.         0.         0.07732107]\n [0.         0.99725553 0.93369182 0.         0.         0.\n  0.         0.         0.         0.32064219 0.         0.\n  0.85081752 0.         0.         0.         0.         0.33744683\n  0.         0.         0.         0.         0.         0.89661026\n  0.         0.         0.53986064 0.         0.        ]\n [0.         0.         0.77188198 0.         0.08788762 0.\n  0.         0.         0.         0.         0.4795821  0.\n  0.         0.         0.         0.         0.03180468 0.\n  0.         0.         0.         0.         0.57599842 0.\n  0.         0.         0.96799407 0.99092948 0.        ]\n [0.         0.         0.         0.71095248 0.         0.\n  0.23611653 0.         0.51165701 0.         0.         0.\n  0.         0.         0.5984427  0.         0.         0.\n  0.48114539 0.         0.06892154 0.47396994 0.         0.\n  0.         0.         0.         0.         0.        ]\n [0.64882284 0.         0.53978106 0.75050192 0.68716551 0.82794089\n  0.         0.         0.         0.         0.         0.63375856\n  0.         0.         0.         0.         0.         0.61495026\n  0.         0.         0.         0.         0.         0.\n  0.         0.         0.         0.         0.85072746]\n [0.         0.         0.         0.         0.         0.\n  0.08729018 0.18640499 0.         0.         0.62410154 0.\n  0.         0.         0.         0.         0.         0.\n  0.         0.93293807 0.         0.         0.         0.\n  0.53185748 0.93201434 0.         0.         0.49074878]\n [0.         0.0027109  0.         0.         0.         0.\n  0.37443537 0.         0.         0.55774227 0.         0.57315085\n  0.         0.         0.         0.         0.         0.25601553\n  0.         0.         0.         0.         0.         0.\n  0.         0.         0.         0.         0.74961623]\n [0.         0.91185241 0.04809464 0.         0.         0.\n  0.         0.         0.         0.         0.80586489 0.\n  0.         0.         0.60755522 0.         0.53659065 0.10486917\n  0.         0.         0.40895518 0.1007946  0.         0.\n  0.         0.05163548 0.         0.         0.        ]\n [0.         0.         0.         0.         0.         0.\n  0.         0.         0.54860312 0.         0.         0.54892198\n  0.43874468 0.         0.         0.10291603 0.         0.\n  0.         0.         0.         0.68457155 0.         0.89966745\n  0.58653543 0.         0.71617907 0.         0.54284931]\n [0.         0.         0.986257   0.         0.         0.\n  0.         0.28792962 0.         0.         0.         0.\n  0.         0.34292686 0.         0.         0.         0.\n  0.         0.65136721 0.         0.         0.         0.\n  0.         0.         0.         0.         0.        ]]\nQ: Is the matrix mat_rnd is sparse?\nA: True\n\n\nA matrix-vector product: as usual (also can use np.dot())\n\nv = np.random.rand(n2)\nmat_rnd@v\n\narray([1.64546027, 1.27076514, 4.16197996, 0.03735966, 1.63821816,\n       1.84035122, 0.7773504 , 2.42685528, 1.69956334, 1.35964884,\n       1.89696116, 0.8904011 , 2.10388512, 2.69689762, 2.11630769,\n       2.8537671 , 1.97694095, 0.76883147, 1.33828737, 2.89356024,\n       2.59839807, 1.62282422, 1.84402481, 3.29603416, 1.21532891,\n       1.05781269, 2.12073541, 2.43820745, 1.44930497])\n\n\n\n\nGraphs and sparsity\nA classical framework for the application of sparse matrices is with graphs: although the number of nodes can be huge, each node of a graph is in general not connected to all nodes. If we represent a graph by its adjacency matrix:\n\nDefinition: adjacency matrix\nSuppose that G=(V,E) is a graph, where \\left|V\\right|=n. Suppose that the vertices of G are arbitrarily numbered v_1,\\ldots,v_n. The adjacency matrix A of G is the matrix n \\times n of general term:\n\nA_{{i,j}}=\n\\left\\{\n     \\begin{array}{rl}\n         1, & \\text{if } (v_i,v_j) \\in E \\\\\n         0, & \\text{o.w.}\n      \\end{array}\n\\right.\n\nNote that instead of 1, the value could vary on a per-edge basis (cf. Figure¬†1).\n\n\n\n\n\n\nEXERCISE: Linear models & sparse matrices\n\n\n\nCreate a function that can fit ordinary least squares for sparse matrices (or not). In particular, handle the usual pre-processing step of standardizing the columns of the design matrix (i.e., centering columns and dividing by standard deviation)?\n\n\nUsage depends on the nature and structure of the data: - csc_matrix is more efficient for slicing by column - csr_matrix is more efficient for the row case.\n\nimport networkx as nx\nnx.__version__\n\n'3.1'\n\n\nCreate a graph:\n\nG = nx.Graph()\nG.add_edge('A', 'B', weight=4)\nG.add_edge('A', 'C', weight=3)\nG.add_edge('B', 'D', weight=2)\nG.add_edge('C', 'D', weight=4)\nG.add_edge('D', 'A', weight=2)\n\nand then visualize it:\n\nmy_seed = 44\nnx.draw_networkx(\n    G, with_labels=True, node_size=1000, pos=nx.spring_layout(G, seed=my_seed)\n)\n\nlabels = nx.get_edge_attributes(G, \"weight\")\nnx.draw_networkx_edge_labels(\n    G, pos=nx.spring_layout(G, seed=my_seed), edge_labels=labels\n)\nnx.draw_networkx_edges(\n    G,\n    pos=nx.spring_layout(G, seed=my_seed),\n    width=[5 * i for i in list(labels.values())],\n)\nplt.axis(\"off\")\nplt.show()\n\n\n\n\n\n\nFigure¬†1: Plot a simple graph\n\n\n\n\n\n\n\n\n\n\n\n\nEXERCISE: Displaying graphs\n\n\n\n\nShow edges weights on the graph\n\n\n\nNote that a variant of adjacency matrix\n\nA = nx.adjacency_matrix(G)\nprint(isspmatrix(A))\nprint(A.todense())\nnx.shortest_path(G, 'C', 'B', weight='weight')\n\n\n\nTrue\n[[0 4 3 2]\n [4 0 0 2]\n [3 0 0 4]\n [2 2 4 0]]\n\n\n\n\n['C', 'D', 'B']"
  },
  {
    "objectID": "Courses/TimeMemory/tp.html#definition-incidence-matrix",
    "href": "Courses/TimeMemory/tp.html#definition-incidence-matrix",
    "title": "Time & memory efficiency",
    "section": "Definition : incidence matrix",
    "text": "Definition : incidence matrix\nLet G = (V,E) be a (non-oriented) graph with n vertices, V = [1,\\dots,n], and p edges, E = [1,\\dots,p]. The graph can be represented by its vertex-edge incidence matrix D^\\top \\in \\mathbb{R}^{p \\times n} defined by\n\n(D^\\top)_{{e,v}} =\n\\left\\{\n     \\begin{array}{rl}\n    + 1, & \\text{if } v = \\min(i,j) \\\\\n    -1, & \\text{si } v = \\max(i,j) \\\\\n    0, & \\text{sinon}\n  \\end{array}\n  \\right.\n\nwhere e = (i,j)."
  },
  {
    "objectID": "Courses/TimeMemory/tp.html#definition-laplacian-matrix",
    "href": "Courses/TimeMemory/tp.html#definition-laplacian-matrix",
    "title": "Time & memory efficiency",
    "section": "Definition : Laplacian matrix",
    "text": "Definition : Laplacian matrix\nThe matrix L=D D^\\top is the so-called graph Laplacian of G\n\nD = nx.incidence_matrix(G, oriented=True).T\nprint(isspmatrix(D))\nprint(D.todense())\n\nTrue\n[[-1.  1.  0.  0.]\n [-1.  0.  1.  0.]\n [-1.  0.  0.  1.]\n [ 0. -1.  0.  1.]\n [ 0.  0. -1.  1.]]"
  },
  {
    "objectID": "Courses/TimeMemory/tp.html#interactive-graph-visualisation",
    "href": "Courses/TimeMemory/tp.html#interactive-graph-visualisation",
    "title": "Time & memory efficiency",
    "section": "Interactive graph visualisation",
    "text": "Interactive graph visualisation\n\ng = nx.karate_club_graph()\n\nlist_degree = list(\n    g.degree()\n)  # Return a list of tuples each tuple is (node, deg)\nnodes, degree = map(\n    list, zip(*list_degree)\n)  # Build a node list and corresponding degree list\n\nfig, ax = plt.subplots(1, 1, figsize=(8, 6))\nnx.draw(\n    g,\n    ax=ax,\n    nodelist=nodes,\n    node_size=[(v * 30) + 1 for v in degree],\n    width=4,\n    alpha=0.7,\n    edgecolors=\"white\",\n    node_color=\"#1f78b4\",\n    edge_color=\"#1f78b4\",\n)\nplt.axis(\"off\")\nplt.show()\n\n\n\n\n\n\n\n\n\nfig, ax = plt.subplots()\n\nA = nx.adjacency_matrix(g).T\nprint(A.todense())\n\nax = plt.spy(A)\nprint(f\"Pourcentage of active edges: {(g.number_of_edges() / g.number_of_nodes()**2) * 100:.2f} %\")\n\n\n\n[[0 4 5 ... 2 0 0]\n [4 0 6 ... 0 0 0]\n [5 6 0 ... 0 2 0]\n ...\n [2 0 0 ... 0 4 4]\n [0 0 2 ... 4 0 5]\n [0 0 0 ... 4 5 0]]\nPourcentage of active edges: 6.75 %\n\n\n\n\n\n\n\n\n\nRemark: a possible visualization with Javascript (not so stable though, can be skipped)\n\nInteractive Networks with Networkx and D3\nner2sna: Entity Extraction and Network Analysis\n\n\nPlanar graphs and maps\nOpen Street Map interfaced with networkx, using the package osmnx.\nKnown bug: - Cannot import name ‚ÄòCRS‚Äô from ‚Äòpyproj‚Äô in osmnx\n\nTypeError: argument of type ‚ÄòCRS‚Äô is not iterable‚Äù with osmnx\n\nSo pick version 0.14 at least conda install osmnx&gt;=0.14 or pip install osmnx&gt;=0.10.\nFor Windows users, there might be some trouble with installing the fiona package, see:\n\nInstalling geopandas:‚Äù A GDAL API version must be specified (anaconda)\nInstall fiona on Windows\n\nSpecial case for osmnx on Windows follow the next step in order:\n\npip install osmnx\npip install Rtree\nconda install -c conda-forge libspatialindex=1.9.3\npip install osmnx\nInstall all packages required up to fiona.\nconda install -c conda-forge geopandas\nSay yes to everything\nOnce done, launch pip install osmnx==1.0.1 s You will also need to install the package folium\n\n\nimport folium\n\n\nmap_osm = folium.Map(location=[43.610769, 3.876716])\n\n\nmap_osm.add_child(folium.RegularPolygonMarker(location=[43.610769, 3.876716],\n                  fill_color='#132b5e', radius=5))\nmap_osm\n\nMake this Notebook Trusted to load map: File -&gt; Trust Notebook\n\n\n\nimport osmnx as ox\nox.settings.use_cache=True\nox.__version__\n\n'1.3.1.post0'\n\n\n\nG = ox.graph_from_place('Montpellier, France', network_type='bike')\nprint(f\"nb edges: {G.number_of_edges()}\")\nprint(f\"nb nodes: {G.number_of_nodes()}\")\n\nnb edges: 33992\nnb nodes: 15345\n\n\n\nfig, ax = ox.plot_graph(G)"
  },
  {
    "objectID": "Courses/TimeMemory/tp.html#visualize-the-shortest-path-between-two-points",
    "href": "Courses/TimeMemory/tp.html#visualize-the-shortest-path-between-two-points",
    "title": "Time & memory efficiency",
    "section": "Visualize the shortest path between two points",
    "text": "Visualize the shortest path between two points\nReferences:\n\nOpenStreetMap Roads Data Using osmnx\n\n\norigin = ox.geocoder.geocode('Place Eug√®ne Bataillon, Montpellier, France')\ndestination = ox.geocoder.geocode('Maison du Lez, Montpellier, France')\n\norigin_node = ox.nearest_nodes(G, origin[1], origin[0])\ndestination_node = ox.nearest_nodes(G, destination[1], destination[0])\n\nprint(origin)\nprint(destination)\nroute = ox.distance.shortest_path(G, origin_node, destination_node)\n# XXX double check if weights are taken into account.\n\n(43.6314565, 3.8607694)\n(43.61032245, 3.8966295)\n\n\n\nfig, ax = ox.plot_graph_route(G, route)\n\n\n\n\n\nax = ox.plot_route_folium(G, route, weight=5, color='#AA1111', opacity=0.7)\nax\n\nMake this Notebook Trusted to load map: File -&gt; Trust Notebook\n\n\n\nG.is_multigraph()\n\nTrue\n\n\n\nedges = ox.graph_to_gdfs(G, nodes=False, edges=True)\nnodes = ox.graph_to_gdfs(G, nodes=True, edges=False)\n# Check columns\nprint(edges.columns)\nprint(nodes.columns)\n\nIndex(['osmid', 'oneway', 'highway', 'reversed', 'length', 'geometry', 'lanes',\n       'name', 'maxspeed', 'junction', 'ref', 'bridge', 'service', 'access',\n       'width', 'tunnel'],\n      dtype='object')\nIndex(['y', 'x', 'street_count', 'highway', 'ref', 'geometry'], dtype='object')\n\n\n\nD = nx.incidence_matrix(G, oriented=True).T\n\n\nelement = np.zeros(1, dtype=float)\nmem = np.prod(D.shape) * element.data.nbytes / (1024**2)\nprint('Size of full matrix with zeros: {0:3.2f}  MB'.format(mem))\n\nprint('Size of sparse matrix: {0:3.2f}  MB'.format(D.data.nbytes/(1024**2) ))\n\nprint('Ratio  of full matrix size / sparse: {0:3.2f}%'.format(100 * D.data.nbytes / (1024**2 * mem)))\nprint(isspmatrix(D))\n\nSize of full matrix with zeros: 3979.55  MB\nSize of sparse matrix: 0.51  MB\nRatio  of full matrix size / sparse: 0.01%\nTrue\n\n\nAlternatively: you can uncomment the following line, and check that the size of a similar matrix (with a non-sparse format) would be. &gt;&gt;&gt; Size of a full matrix encoding the zeros: 4 gB\nCreate a matrix of similar size. BEWARE: This creates a huge matrix:\nM = np.random.randn(G.number_of_nodes(), G.number_of_nodes())\nprint('Size of a full encoding the zeros: {0:3.2f}  MB'.format(M.nbytes/(1024**2)))\n\nGraph sparsity\n\nprint(\" {0:.2} % of edges only are needed to represent the graph of Montpellier\".format(100 * G.number_of_edges() / G.number_of_nodes() ** 2))\n\n 0.014 % of edges only are needed to represent the graph of Montpellier\n\n\nReferences:\n\nOSMnx: Python for Street Networks\nNetwork analysis in Python\nhttps://autogis-site.readthedocs.io/en/latest/index.html"
  },
  {
    "objectID": "Courses/TimeMemory/tp.html#for-more-on-profiling",
    "href": "Courses/TimeMemory/tp.html#for-more-on-profiling",
    "title": "Time & memory efficiency",
    "section": "For more on profiling",
    "text": "For more on profiling\n\nsnakeviz, in Python\nprofvis, in R"
  },
  {
    "objectID": "Courses/TimeMemory/tp.html#debugging-package-pdb",
    "href": "Courses/TimeMemory/tp.html#debugging-package-pdb",
    "title": "Time & memory efficiency",
    "section": "Debugging: package pdb",
    "text": "Debugging: package pdb\nReferences:\n\nDebugging Jupyter notebooks by David Hamann\nAdvanced Python Debugging with pdb by Steven Kryskalla\nDebug Python with VSCode\n\nLet us use import pdb; pdb.set_trace() to enter a code and inspect it. Push the key c and then enter to go next.\nA first recommendation is to use the python debugger in your IDE.\nPure python or IPython can use the pdb package and the command pdb.set_trace(). A command prompt launches when an error is met, and you can check the current status of the environment. Useful shortcuts are available (e.g., touche c, touche j etc.); a full list is available here.s\ndef function_debile(x):\n    answer = 42\n    answer += x\n    return answer\nfunction_debile(12)\ndef illustrate_pdb(x):\n    answer = 42\n    import pdb; pdb.set_trace()\n    answer += x\n    return answer\nillustrate_pdb(12)\nA terminal is launched when a problem occurs, and one can then take over and see what‚Äôs going on.\nget_ipython().run_line_magic('pdb', '')\ndef blobl_func(x):\n    answer = 0\n    for i in range(x, -1, -1):\n        print(i)\n        answer += 1 / i\n\n    return answer\n\nblobl_func(4)"
  },
  {
    "objectID": "Courses/ClassesExceptions/tp.html",
    "href": "Courses/ClassesExceptions/tp.html",
    "title": "Classes & Exceptions",
    "section": "",
    "text": "Classes are central elements in Object-oriented programming (OOP)\nA class structure defines an object, its properties, and all the operations one can apply to it.\nIn Python, a class contains attributes (variables) and methods (functions). It is defined similarly to a function, replacing the def keyword with class. The name of a class should be either CapWords or CamelCase1.1¬†CamelCase (üá´üá∑: casse de chameau): the name comes from the ‚Äúbumpy‚Äù look of its letters as in the Wikipedia illustration below \nUsually, a class contains some class methods than can be seen as functions inside the class.\n\nThe first argument of a (non-static) method is usually called self: it is a mandatory element. This self argument is for self-reference.\nSome method names have a specific meaning, for instance:\n\n__init__: name of the method invoked when creating the object (instantiation)\n__call__: method invoked when calling the object\n__str__: method invoked when a class has a representation as a string, e.g., when passing it to the print function\nsee Python documentation for more special names.\n\n\n\n\nLet us define a simple Point class, representing a point in the plane (i.e., a point in \\mathbb{R}^2):\n\nclass Point(object):\n    \"\"\"A class to represent planar points.\"\"\"\n\n    def __init__(self, x, y):\n        \"\"\"Create a new point (x, y).\"\"\"\n        self.x = x\n        self.y = y\n\n    def translate(self, dx, dy):\n        \"\"\"Translate the point by dx and dy.\"\"\"\n        self.x += dx\n        self.y += dy\n\n    def __str__(self):\n        return f\"Point: [{self.x:.3f}, {self.y:.3f}]\"\n\n\n\n\n\n\n\nNote\n\n\n\nIf you are not familiar with printing in Python, start with the new f-strings format; see for instance: https://zetcode.com/python/fstring/.\n\n\nTo create a new instance of the class Point you run the following code:\n\np1 = Point(x=0, y=0)  # call __init__ ;\n\nNow, you can access the attributes of the object p1:\n\nprint(p1.x)\nprint(p1.y)\nprint(\"{0}\".format(p1))  # call __str__\np1\n\n0\n0\nPoint: [0.000, 0.000]\n\n\n&lt;__main__.Point at 0x7f64bd4cc790&gt;\n\n\nTo apply our translate method to the point p1:\np1.translate(dx=1, dy=1)\nprint(p1.translate)\nprint(p1)\nprint(type(p1))\nTo run a method of the object p1 (which is an instance of Point) simply use the dot notation: p1.translate(arg1, arg2) is equivalent to Point.translate(p1, arg1, arg2).\n\np2 = Point(1, 1)\np1.translate(0.25, 1.5)\nprint(p1)\nprint(p2)\n\nPoint: [0.250, 1.500]\nPoint: [1.000, 1.000]\n\n\n\n\n\n\n\n\nNote\n\n\n\nYou might have already used that syntax with the dot notation in numpy, for instance when executing numpy functions as follows\n\nimport numpy as np\nrng = np.random.default_rng(seed=12345)\na = rng.random((3, 3))\na.mean(axis=0)\n\narray([0.50063315, 0.29820069, 0.60097848])\n\n\n\n\n\n\n\nMyClass(arg1, arg2, ...) is a shorthand for MyClass.__call__(arg1, arg2, ...), so this allows writing classes where the instances behave like functions and can be called like a function\n\nclass Sum:\n    def __init__(self):\n        print(\"Instance Created\")\n\n    # Defining __call__ method\n    def __call__(self, a, b):\n        print(a + b)\n\n# Instance created\nsum_as_a_function = Sum()\n\n# __call__ method will be called\nsum_as_a_function(10, 20)\n\nInstance Created\n30\n\n\nA test function of interest is isinstance that allows to check if an object is of the correct class. For instance, one can check is sum_as_a_function is an instance of Sum:\n\nisinstance(sum_as_a_function, Sum)\n\nTrue\n\n\nsimilarly one can test if it is an instance of Point:\n\nisinstance(sum_as_a_function, Point)\n\nFalse\n\n\n\n\n\n\nA method of a class can modify the state of a particular instance. This does not alter the other instantiations of the class. \n\n\n\n\n\n\n\nEXERCISE: Gaussian class\n\n\n\nImplement a class Gaussian with attributes mean and std with a method\n\n__str__ returning a string with the expression of the density\n__eq__ testing the equality of two instances. You should use numpy.isclose()\n__add__ implementing the addition of independent Gaussian, or more precisely their pdfs (probability density functions)\n__radd__ implementing the addition of independent Gaussian, or more precisely their pdfs (probability density functions)\n\nNote: when executing a+b what really happens is that the add method of the a: object is called a.__add__(b).\n\ng1 = Gaussian(0.0, 1.0)\ng2 = Gaussian(1.0, 2.0)\ng3 = Gaussian(2.0, 2.0)\ng4 = Gaussian(3.0, 3.0)\n\nprint(g1)\nprint(g2)\nprint(g3)\nprint(g4)\nprint(g2 + g1)\nprint(sum([g1, g2, g3]))\nprint(sum([g1, g2, g3]) == g4)\n\npdf: exp(-(x - 0.000)^2 / (1.000*2^2)) / sqrt(2 * pi * 1.000^2)\npdf: exp(-(x - 1.000)^2 / (2.000*2^2)) / sqrt(2 * pi * 2.000^2)\npdf: exp(-(x - 2.000)^2 / (2.000*2^2)) / sqrt(2 * pi * 2.000^2)\npdf: exp(-(x - 3.000)^2 / (3.000*2^2)) / sqrt(2 * pi * 3.000^2)\npdf: exp(-(x - 1.000)^2 / (2.236*2^2)) / sqrt(2 * pi * 2.236^2)\npdf: exp(-(x - 3.000)^2 / (3.000*2^2)) / sqrt(2 * pi * 3.000^2)\nTrue\n\n\n\n\n\n\n\nClasses can inherit methods from other classes. You can use super (Latin word for ‚Äúabove‚Äù) to access the parent class.\nA simple test consists of checking whether a class has inherited from another class: issubclass allows to check this heritage property:\n\nclass IsoGaussian(Gaussian):\n    def __init__(self, mean):\n        super().__init__(mean, 1.0)\n\ngg1 = IsoGaussian(3)\nprint(gg1)\nissubclass(IsoGaussian, Gaussian)\n\npdf: exp(-(x - 3.000)^2 / (1.000*2^2)) / sqrt(2 * pi * 1.000^2)\n\n\nTrue\n\n\nMany examples of interest are considered in the scikit-learn package (see for instance the module Linear Model often used in machine learning or statistics).\nFor more information on super, see for instance this Real Python Tutorials."
  },
  {
    "objectID": "Courses/ClassesExceptions/tp.html#classes",
    "href": "Courses/ClassesExceptions/tp.html#classes",
    "title": "Classes & Exceptions",
    "section": "",
    "text": "Classes are central elements in Object-oriented programming (OOP)\nA class structure defines an object, its properties, and all the operations one can apply to it.\nIn Python, a class contains attributes (variables) and methods (functions). It is defined similarly to a function, replacing the def keyword with class. The name of a class should be either CapWords or CamelCase1.1¬†CamelCase (üá´üá∑: casse de chameau): the name comes from the ‚Äúbumpy‚Äù look of its letters as in the Wikipedia illustration below \nUsually, a class contains some class methods than can be seen as functions inside the class.\n\nThe first argument of a (non-static) method is usually called self: it is a mandatory element. This self argument is for self-reference.\nSome method names have a specific meaning, for instance:\n\n__init__: name of the method invoked when creating the object (instantiation)\n__call__: method invoked when calling the object\n__str__: method invoked when a class has a representation as a string, e.g., when passing it to the print function\nsee Python documentation for more special names.\n\n\n\n\nLet us define a simple Point class, representing a point in the plane (i.e., a point in \\mathbb{R}^2):\n\nclass Point(object):\n    \"\"\"A class to represent planar points.\"\"\"\n\n    def __init__(self, x, y):\n        \"\"\"Create a new point (x, y).\"\"\"\n        self.x = x\n        self.y = y\n\n    def translate(self, dx, dy):\n        \"\"\"Translate the point by dx and dy.\"\"\"\n        self.x += dx\n        self.y += dy\n\n    def __str__(self):\n        return f\"Point: [{self.x:.3f}, {self.y:.3f}]\"\n\n\n\n\n\n\n\nNote\n\n\n\nIf you are not familiar with printing in Python, start with the new f-strings format; see for instance: https://zetcode.com/python/fstring/.\n\n\nTo create a new instance of the class Point you run the following code:\n\np1 = Point(x=0, y=0)  # call __init__ ;\n\nNow, you can access the attributes of the object p1:\n\nprint(p1.x)\nprint(p1.y)\nprint(\"{0}\".format(p1))  # call __str__\np1\n\n0\n0\nPoint: [0.000, 0.000]\n\n\n&lt;__main__.Point at 0x7f64bd4cc790&gt;\n\n\nTo apply our translate method to the point p1:\np1.translate(dx=1, dy=1)\nprint(p1.translate)\nprint(p1)\nprint(type(p1))\nTo run a method of the object p1 (which is an instance of Point) simply use the dot notation: p1.translate(arg1, arg2) is equivalent to Point.translate(p1, arg1, arg2).\n\np2 = Point(1, 1)\np1.translate(0.25, 1.5)\nprint(p1)\nprint(p2)\n\nPoint: [0.250, 1.500]\nPoint: [1.000, 1.000]\n\n\n\n\n\n\n\n\nNote\n\n\n\nYou might have already used that syntax with the dot notation in numpy, for instance when executing numpy functions as follows\n\nimport numpy as np\nrng = np.random.default_rng(seed=12345)\na = rng.random((3, 3))\na.mean(axis=0)\n\narray([0.50063315, 0.29820069, 0.60097848])\n\n\n\n\n\n\n\nMyClass(arg1, arg2, ...) is a shorthand for MyClass.__call__(arg1, arg2, ...), so this allows writing classes where the instances behave like functions and can be called like a function\n\nclass Sum:\n    def __init__(self):\n        print(\"Instance Created\")\n\n    # Defining __call__ method\n    def __call__(self, a, b):\n        print(a + b)\n\n# Instance created\nsum_as_a_function = Sum()\n\n# __call__ method will be called\nsum_as_a_function(10, 20)\n\nInstance Created\n30\n\n\nA test function of interest is isinstance that allows to check if an object is of the correct class. For instance, one can check is sum_as_a_function is an instance of Sum:\n\nisinstance(sum_as_a_function, Sum)\n\nTrue\n\n\nsimilarly one can test if it is an instance of Point:\n\nisinstance(sum_as_a_function, Point)\n\nFalse\n\n\n\n\n\n\nA method of a class can modify the state of a particular instance. This does not alter the other instantiations of the class. \n\n\n\n\n\n\n\nEXERCISE: Gaussian class\n\n\n\nImplement a class Gaussian with attributes mean and std with a method\n\n__str__ returning a string with the expression of the density\n__eq__ testing the equality of two instances. You should use numpy.isclose()\n__add__ implementing the addition of independent Gaussian, or more precisely their pdfs (probability density functions)\n__radd__ implementing the addition of independent Gaussian, or more precisely their pdfs (probability density functions)\n\nNote: when executing a+b what really happens is that the add method of the a: object is called a.__add__(b).\n\ng1 = Gaussian(0.0, 1.0)\ng2 = Gaussian(1.0, 2.0)\ng3 = Gaussian(2.0, 2.0)\ng4 = Gaussian(3.0, 3.0)\n\nprint(g1)\nprint(g2)\nprint(g3)\nprint(g4)\nprint(g2 + g1)\nprint(sum([g1, g2, g3]))\nprint(sum([g1, g2, g3]) == g4)\n\npdf: exp(-(x - 0.000)^2 / (1.000*2^2)) / sqrt(2 * pi * 1.000^2)\npdf: exp(-(x - 1.000)^2 / (2.000*2^2)) / sqrt(2 * pi * 2.000^2)\npdf: exp(-(x - 2.000)^2 / (2.000*2^2)) / sqrt(2 * pi * 2.000^2)\npdf: exp(-(x - 3.000)^2 / (3.000*2^2)) / sqrt(2 * pi * 3.000^2)\npdf: exp(-(x - 1.000)^2 / (2.236*2^2)) / sqrt(2 * pi * 2.236^2)\npdf: exp(-(x - 3.000)^2 / (3.000*2^2)) / sqrt(2 * pi * 3.000^2)\nTrue\n\n\n\n\n\n\n\nClasses can inherit methods from other classes. You can use super (Latin word for ‚Äúabove‚Äù) to access the parent class.\nA simple test consists of checking whether a class has inherited from another class: issubclass allows to check this heritage property:\n\nclass IsoGaussian(Gaussian):\n    def __init__(self, mean):\n        super().__init__(mean, 1.0)\n\ngg1 = IsoGaussian(3)\nprint(gg1)\nissubclass(IsoGaussian, Gaussian)\n\npdf: exp(-(x - 3.000)^2 / (1.000*2^2)) / sqrt(2 * pi * 1.000^2)\n\n\nTrue\n\n\nMany examples of interest are considered in the scikit-learn package (see for instance the module Linear Model often used in machine learning or statistics).\nFor more information on super, see for instance this Real Python Tutorials."
  },
  {
    "objectID": "Courses/ClassesExceptions/tp.html#exceptions",
    "href": "Courses/ClassesExceptions/tp.html#exceptions",
    "title": "Classes & Exceptions",
    "section": "Exceptions",
    "text": "Exceptions\nThis section is inspired by Fabien Maussion‚Äôs lecture on Scientific Programming, and describes how to handle exceptions in python.\n\nIn python errors are handled through Exceptions\nAn error throws an Exception interrupting the normal code execution\nExecution can overpass such an issue inside a bloc with try - except\nA typical use case: stop the program when an error occurs:\n\ndef my_function(arguments):\n\n    if not verify(arguments):\n        raise Exception(\"Invalid arguments\")\n\n    # ...\n    # Keep working if the exception is not raised\nThe list of possible errors is available here: https://docs.python.org/3/library/exceptions.html#bltin-exceptions and includes NameError, ImportError, AssertionError etc.\nOne may use try, except or finally to prevent errors to stop the program:\ntry:\n    # Part 1: Normal code goes here\nexcept:\n    # Part 2: Code for error handling goes here\n    # This code is not executed unless Part 1\n    # above generated an error\nfinally:\n    # Optional: This clause is executed no matter what,\n    # and is generally used to release external resources.\n\nExample\n\ntry:\n    print(\"test_var testing:\")\n    e = 4\n    print(test_var) # raise an error: the test_var variable is not defined\nexcept NameError:\n    print(\"Caught an exception: test_var does not exist\")\nfinally:\n    print(\"This code is executed every time\")\n\nprint(\"The program keep continuing... it does not freeze!\")\nprint(f\"Beware! the affectation step: e = {e} was executed.\")\n\ntest_var testing:\nCaught an exception: test_var does not exist\nThis code is executed every time\nThe program keep continuing... it does not freeze!\nBeware! the affectation step: e = 4 was executed.\n\n\nTo obtain some information on the error: it is possible to access the instance of the Exception class thrown by the program through the syntax:\n\ntry:\n    print(\"test\")\n    print(testtt)  # Error: the variable testtt is not defined\nexcept Exception as name_exception:\n    print(\"Caught an exception:\", name_exception)\n\ntest\nCaught an exception: name 'testtt' is not defined\n\n\n\n\n\n\n\n\nNote\n\n\n\nA common use case is to test if the import of a package was successful or not. For instance, the following code will not raise an error if the package pooch is not installed on your computer.\ntry:\n    import pooch\nexcept Exception as e:\n    print(e)\n\n\nCommon exceptions can be found here: https://docs.python.org/3/library/exceptions.html\n\n\nThe with statement\n\n\n\n\n\n\nImportant\n\n\n\nYou have to run the following lines at a location where a directory called scripts/ containing a function hello-world.py exists. The one used in the lecture is available here if you have not cloned the course repository (if you have it is available in scripts/). You can of course create your own if you prefer.\n\n\n\nfname = \"./scripts/hello-world.py\"\n\nwith open(fname) as file:  # Use file to refer to the file object\n    data = file.read()\n    print(data)\n    # at the end of the code chunk, the file.__exit__() method is called (i.e., file.close() is done automatically)\n\ntatjpjepj.\n\n\n\nNow\n\nfname = \"scripts/hello-world_do_not_exist.py\"\ntry:\n    # 1/0  # Yncomment at some point and run\n    file = open(fname)\n    data = file.read()\n    print(data)\nexcept FileNotFoundError:\n    print(\"File not found!\")\nexcept (RuntimeError, TypeError, NameError, ZeroDivisionError):\n    print(\"Specific Error message 2\")\nfinally:\n    file.close()  # Important line to release access to the file!\n\nFile not found!\n\n\n\n\n\n\n\n\nEXERCISE: Improving the Gaussian class\n\n\n\nCreate a sub-class GaussianBis where you check if the user has provided float arguments (see also assert and isinstance routines). Print a custom explicit error message if it is not the case."
  },
  {
    "objectID": "Courses/ClassesExceptions/tp.html#scope",
    "href": "Courses/ClassesExceptions/tp.html#scope",
    "title": "Classes & Exceptions",
    "section": "Scope",
    "text": "Scope\ne = 0\nprint(e)\n\nfor i in range(1):\n    e = 1\n\nprint(e)\n\n\ndef f():\n    e = 2\n\nprint(e)\nConclusion: e is only ‚Äúvisible‚Äù inside the function definition. See https://realpython.com/python-scope-legb-rule/ for more information on this topic."
  },
  {
    "objectID": "Courses/ClassesExceptions/tp.html#manipulate-file-names-across-platforms",
    "href": "Courses/ClassesExceptions/tp.html#manipulate-file-names-across-platforms",
    "title": "Classes & Exceptions",
    "section": "Manipulate file names across platforms",
    "text": "Manipulate file names across platforms\nEach OS (Linux / Windows /Mac) might have a different syntax to describe a file path. The following would avoid naming conflict due to each OS syntax and could be important for your project if you work with colleagues with a different OS from yours.\nimport os\n\nprint(os.path.join('~', 'work', 'src'))\nprint(os.path.join(os.getcwd(), 'new_directory'))\nos.path.expanduser?\nprint(os.path.expanduser(os.path.join('~', 'work', 'src')))\n\n\n\n\n\n\nEXERCISE: Create a bunch of files\n\n\n\nWrite a simple script that creates, in the sub-directory scripts, the following text files: myDb_000.txt, myDb_001.txt, myDb_002.txt, ‚Ä¶, myDb_049.txt. The i-th file should contain a single line with the average of the i first digits of pi.\nHint:\n\nYou might need zero padding.\nYou can check what the following code does.\n\nfile = open(\"copy.txt\")\nfile.write(\"Your text goes here\")\nfile.close()\n\nYou might also need some precision for the digits of \\pi, hence using mpmath instead of numpy.\n\nfrom mpmath import mp\nimport numpy as np\n\nif not os.path.isdir(\"script\"):\n    os.mkdir(\"script\")\n\nfor i in range(2, 50):\n\n\nfor i in range(2, n_tot + 2):\n    val = '0' + str(i)\n    print(str(f\"{i:{val}}\"))"
  },
  {
    "objectID": "Courses/ClassesExceptions/tp.html#references",
    "href": "Courses/ClassesExceptions/tp.html#references",
    "title": "Classes & Exceptions",
    "section": "References",
    "text": "References\n\nPython official web page and its style and writing recommendation\nThink Python - A free book by Allen Downey.\nPython Essential Reference - a good reference for general Python coding\nPython Data Science Handbook - an excellent book for data science in Python by Jake VanderPlas (associated notebook available online)"
  },
  {
    "objectID": "Projects/2021-2022/README.html",
    "href": "Projects/2021-2022/README.html",
    "title": "Project guidelines: 2021-2022",
    "section": "",
    "text": "Work by groups of 3 or 4 students, assigned at random (list on the Moodle website)."
  },
  {
    "objectID": "Projects/2021-2022/README.html#timing",
    "href": "Projects/2021-2022/README.html#timing",
    "title": "Project guidelines: 2021-2022",
    "section": "Timing",
    "text": "Timing\n\nMid-term project snapshot: Due date Monday November 15, 23:59. This will include the creation of a github repository (README.md, etc.), a short description of how the work is split and a detailed work program for the project including how the task are attributed (coding).\nDue date (final project): The github repository should be completed before Thursday 9 December (23:59). Nothing pushed after the deadline will be taken into account. The oral presentation (max: 20mn) will be in-person Monday 13 December 8:00AM (room 36.02)."
  },
  {
    "objectID": "Projects/2021-2022/README.html#elements-expected-grading",
    "href": "Projects/2021-2022/README.html#elements-expected-grading",
    "title": "Project guidelines: 2021-2022",
    "section": "Elements expected / Grading",
    "text": "Elements expected / Grading\n\nSummary\n\n\n\n\n\n\n\n\nGeneral\nDetails\nPoints (out of 20)\n\n\n\n\nMid-term\nGit / branches\n1.5\n\n\n\nTask affectation\n1\n\n\n\nDataset creation\n1\n\n\nCode\nScience Technical Problem Resolution\n4.5\n\n\n\nReadme/Comments/Pep8\n1\n\n\n\nUnit Tests/CI/Deploy : wheel\n1\n\n\n\nClass (create at least 1 class)\n0.5\n\n\n\nReproducibility/Dataset loading\n1\n\n\n\nGraphical aspects: Widgets, clickable map, etc‚Ä¶\n2.5\n\n\n\nTime/Memory efficiency\n1\n\n\n\nDocumentation\n1.5\n\n\nOral\nBeamer (structure, spelling)\n1.5\n\n\n\nClarity / lively presentation / Rhythm / Show\n2\n\n\nTotal\n\n20\n\n\n\n\n\nDetails\n\nThe ultimate goal is to provide a Python module that can be imported with pip and contains your work. A description of the procedure will be needed (imagine you are addressing to a user not aware of your package). An example of a project, made in 2020, is available at https://github.com/tanglef/chaoseverywhere.\nThe project must be stored on a github repository.\nYou have to choose a name for your project. Hereafter, it is denoted by my_module_name.\nIt should contain all the aspects described below.\n\n\n\nScience\nSolve (even partially) the problem raised in your project description.\n\n\nProject structure\n\nAll the code will be placed in a sub-directory called /my_module_name (choosing your module name accordingly).\nA presentation (in an open source format: like Beamer, with TeX, see for instance some templates here https://github.com/josephsalmon/OrganizationFiles, or LibreOffice Impress) will be put in a /beamer directory. The latter will be a short presentation of the work that will be orally presented during 15mn in front of a jury.\nA documentation (using sphinx) will be stored in a /doc sub-directory.\n\n\n\nGit aspects\n\na (markdown) readme.md file introducing your work and the team member (first/last name + email).\nA .gitignore that prevents garbage files to be included in your project.\nequilibrated commits in two branches should be done (e.g., in the development branch and the master one), and merged for the milestone day.\n\n\n\nObject programming aspects\n\nyou should code at least one Python class.\n\n\n\nDataset(s)\n\nThe data used should be available in a way that the end user does not need to perform a manual download of any kind.\n\n\n\nGraphical aspects\nThe repository will contain code of the following nature:\n\na code producing a (possibly interactive) map.\nhistograms/kde/swarm/etc. plots illustrating the data.\n\n\n\nTime/memory evaluation\n\nA full study of the time and memory footprint of the code produced will be provided.\n\n\n\nDocumentation\n\nDocumentation should be added correctly for the functions written. Please use sphinx.\n\n\n\nTest and CI\n\nProvide unitary tests to check that the function you proposed satisfies the requirement you target.\nImplement a Continuous Integration solution with github that runs your unitary test at each commit.\n\n\n\nDeploy\n\nIt should be possible to package your Python module using wheel (i.e., you need to provide a setup.py, file)."
  },
  {
    "objectID": "Projects/2023-2024/README.html",
    "href": "Projects/2023-2024/README.html",
    "title": "Project guidelines: 2023-2024",
    "section": "",
    "text": "For this course, the grading consists of two projects:\n\nMain project: a long-term group project on air pollution in Occitanie (duration 2.5 months),\nSide project: a personal project to create a Weather Forecast App for Montpellier (duration 1.5 months).\n\nYou will need to work all along the semester to achieve these projects. Please start to work on it as soon as possible. You need to use your GitHub account (see Git lecture) as the expected outputs for this course are GitHub repositories.\n\n\n\n\n    gantt\n        title HAX712X projects\n        axisFormat %d-%m\n        section Personal project \n            Weather Forecast App    :active,                2023-09-22, 2023-11-15\n            Evaluation              :active, milestone,           2023-11-16, 2023-11-16\n        section Team project \n            Research & Outlining    :done,         2023-09-29, 2023-10-23\n            Midterm evaluation      :done,milestone,      2023-10-23, 2023-10-23\n            Development             :done,         2023-10-24, 2023-12-10\n            Final evaluation        :done,milestone,      2023-12-15, 2023-12-15"
  },
  {
    "objectID": "Projects/2023-2024/README.html#setting-and-objectives",
    "href": "Projects/2023-2024/README.html#setting-and-objectives",
    "title": "Project guidelines: 2023-2024",
    "section": "2.1 Setting and objectives",
    "text": "2.1 Setting and objectives\nThis is a personal project. This part corresponds to 20% of the final grade. The due date is November 16 (23:59).\nThe main objective of this project is to create:\n\na GitHub repository containing all the code and documentation of your project\na GitHub web page displaying images representing the weather forecast for the 5 next days (in Montpellier) that automatically updates. The website URL should be accessible in the README.md at the root of your Git repository.\na short description of the methodology used, below the forecast itself.\n\nPlease provide this URL in the following survey https://framaforms.org/hax712x-depot-git-personnel-1693995810."
  },
  {
    "objectID": "Projects/2023-2024/README.html#guidelines",
    "href": "Projects/2023-2024/README.html#guidelines",
    "title": "Project guidelines: 2023-2024",
    "section": "2.2 Guidelines",
    "text": "2.2 Guidelines\n\nFor this project, you need to create a GitHub repository with your code, and we suggest using GitHub action for the deployment phase (weather forecast update and website generation).\nThe data to be used for your project is to be obtained from open-meteo.com.\nYou have to create a simple webpage using a GitHub page and a GitHub action with Quarto; see https://quarto.org/docs/publishing/github-pages.html for details, and also the associated yml here. The webpage created will display the weather forecast in Montpellier for the next 5 days. For instance, it could display something like this:\n\n\n\n\nWeather Forecast (source: meteoblue.com)\n\n\n\n\n\n\n\n\nNote\n\n\n\nYou should display the forecast together with the highest/lowest temperature for the day, wind average, and amount of precipitation. The closer you can reproduce something in the spirit of the previous illustration, the higher the grade.\n\n\n\nAn additional constraint is that the app should be autonomous once created, and should be automatically refreshed every day (like a real weather forecast website!). An example to help you in this task is available here (and the associated source code), updating time series on a monthly basis. For the automatic update and scheduling, see the schedule event description.\nThe only image format accepted is SVG. See examples from freesvg.org, creativecommons, clker, openclipart, etc.\nThe code must be structured, commented and properly formatted with the black linter and follow pep8 convention. Guidance on this can be obtained here https://www.freecodecamp.org/news/auto-format-your-python-code-with-black/ or here for VSCode.\n\n\n2.2.1 Grading details\n\n\n\n\nGeneral\nDetails\nPoints\n\n\n\n\nGit\nGitHub page functional\n3\n\n\n\nDisplay the expected information\n4\n\n\n\nGiHub page refreshed daily\n3\n\n\nWork description\nClarity / Details\n2\n\n\n\nEasy to reproduce with text\n2\n\n\nCode\nComments/Pep8 or Black\n2\n\n\n\nStructure of the code\n2\n\n\n\nGraphical aspects and esthetic\n2\n\n\nTotal\n\n20"
  },
  {
    "objectID": "Projects/2023-2024/README.html#setting-and-objectives-1",
    "href": "Projects/2023-2024/README.html#setting-and-objectives-1",
    "title": "Project guidelines: 2023-2024",
    "section": "3.1 Setting and objectives",
    "text": "3.1 Setting and objectives\nThe group composition is available on Moodle.\n\n\n\n\n\n\nNo free-rider tolerated\n\n\n\nThe project repository must show a balanced contribution between group members and intra-group grade variation could be made to reflect issues on the intra-group workload balance.\n\n\nThe project consists of an investigation of the pollution in Occitanie, through the analysis of the following datasets at least:\n\nWeather forecast: SYNOP data\nOccitanie pollution datasets: Atmo Occitanie\n\nIt will be mostly a visualization project, hopefully an interactive one, with the creation of a website (as for the personal project), helping to navigate your work. The study could focus at least on the following time resolution: last month, last year and last 5 years, for several cities, and several pollutants."
  },
  {
    "objectID": "Projects/2023-2024/README.html#timing",
    "href": "Projects/2023-2024/README.html#timing",
    "title": "Project guidelines: 2023-2024",
    "section": "3.2 Timing",
    "text": "3.2 Timing\n\nMid-term project snapshot: This part consists of starting the group project, explaining the main question of interest chosen to investigate. You should show preliminary work and organization of the workload, git first steps for the group project, etc. See details below Section¬†3.2.1. This part corresponds to 10% of the final grade. The due date is October 23 (23:59)\nThe GitHub repository with the presentations slides should be completed before Sunday 10 December (23:59). Nothing pushed after the deadline will be taken into account.\nThe oral presentation (15mn + 5mn questions) December 15 (8:00) (room: SC36.04).\n\n\n3.2.1 Mid-term project snapshot\nPlease provide the URL of the group repository and the group composition (do not forget your student number) in the following survey https://framaforms.org/hax712x-groupes-1694612082.\nThe main point for this step is to create a README.qmd (maximum length: approximately 4 pages) in a roadmap directory at the root of your project. We will provide you feedback in the form of GitHub issues on your project repository. Your file should give the outline of the project with the following ingredients:\n\nYou have to choose a name for your project. Hereafter, it is denoted by my_module_name.\ndescription of a minimum viable project, showing the architecture (website, files, classes, etc.). It does not have to be functional at this stage but must have the main files needed, details of the coding pipeline, choice of the packages/technologies used, etc.\nCreate simple pictures (possibly camera pictures of handmade drawings) showing the results you want to create (time series, maps, etc.).\nProvide several git branches (at least 2) so the project can move forward independently.\nRetro planning with a Gantt diagram as follows (see for instance Quarto and Mermaid):\n\n\n\n\n\n    gantt\n        title Preparing Polyglot Notebooks Talk for Stir Trek 2023\n        axisFormat %m-%d\n        section Proposal &lt;br&gt; & &lt;br&gt; Evaluation\n            Submit Abstract         :done,                2023-01-15, 2023-02-18\n            Session Evaluation      :done, EVAL           2023-02-18, 2023-03-05\n            Talk Accepted           :milestone, done,     after EVAL\n        section Talk &lt;br&gt; Preparation\n            Research & Outlining    :done, OUTLINE,       2023-03-12, 9d\n            Create Mermaid Examples :done, MER_EXAMPLE,   after OUTLINE, 5d\n            Write Mermaid Articles  :active, MER_ART,     after MER_EXAMPLE, 7d\n            Write Jupyter Articles  :                     after MER_ART, 3d\n        section Delivery\n            Final Notebook          :crit, NOTEBOOK,      2023-04-19, 7d\n            Rehearsal               :crit,                after NOTEBOOK, 2023-05-04\n            Stir Trek 2023          :milestone, crit,     2023-05-05, 1d\n\n\n\n\n\n\n\n3.2.1.1 Elements expected / Grading\n\n\n\n\nGeneral\nDetails\nPoints (out of 20)\n\n\n\n\nMid-term\nGit / branches\n4\n\n\n\nTask affectation / Gantt chart\n4\n\n\n\nDataset choices / Download / Description\n4\n\n\n\nPackages/software description for the project\n4\n\n\n\nFigure of interest/narration\n4\n\n\nTotal\n\n20\n\n\n\n\n\n\n3.2.2 Final project\n\n3.2.2.1 General guidelines\n\nThe ultimate goal is to provide a Python project that builds a website with quarto and presents your project. This website should be deployed automatically through GitHub actions. A description of the procedure will be needed (imagine you are addressing a user not aware of your package). An example of a project made in 2020, is available at https://github.com/tanglef/chaoseverywhere.\nIt should contain all the aspects described below.\n\n\n\n3.2.2.2 Website\n\nYou have to create a simple website using GitHub pages and a GitHub action with Quarto for displaying your results\nAt least one of the pages should contain an interactive element (maps, widgets, etc.)\n\n\n\n3.2.2.3 Project structure\n\nAll the code will be placed in a subdirectory called /my_module_name (choosing your module name accordingly).\nA slide deck in quarto  will be put in a /slide directory of the repository. The latter will be a short presentation of the work that will be orally presented during 15mn in front of a jury, at the end of the project.\n\n\n\n\n3.2.2.4 Git aspects\n\nA .gitignore that prevents garbage files from being included in your project.\nEquilibrated commits in two branches should be done (e.g., in the development branch and the master one), and merged for the milestone day.\nYour repository should contain a README.md:\n\ncontaining the title and a short description of the project\nthe link to the website\na code snippet to build the website\nauthors list and a license description. See this website. A default choice could be MIT Licence.\n\n\n\n\n3.2.2.5 Object programming aspects\n\nYou should code at least one Python class.\nYour python project should contain submodules. Each submodule will be devoted to a specific sub-task of your project.  #### Dataset(s)\nThe data used should be available in a way that the end user does not need to perform a manual download of any kind (use the pooch package or variants for instance).\n\n\n\n3.2.2.6 Time/memory evaluation\n\nA full study of the time and memory footprint of the code produced will be provided for the whole pipeline used. Elements showing speed-up / memory savings you could find along the way would be also appreciated.\n\n\n\n3.2.2.7 Documentation\n\nDocstrings should be populated for every python class and function.\nBonus points will be given if you create an API documentation using sphinx for instance.\n\n\n\n3.2.2.8 Test and CI\n\nProvide unitary tests to check that the function you proposed satisfies the requirement you target.\nImplement a Continuous Integration solution with GitHub that runs your unitary test at each commit. \n\n\n\n\n\n\n\n\n\n\n\nGeneral\nDetails\nPoints (out of 20)\n\n\n\n\nCode\nProblem Resolution\n6\n\n\n\nReadme/Comments/Pep8\n1\n\n\n\nUnit Tests/CI/Deploy: wheel\n1\n\n\n\nClass (create at least 1 class)\n0.5\n\n\n\nReproducibility/Dataset loading\n1\n\n\n\nGraphical aspects: Widgets, clickable map, etc.\n2.5\n\n\n\nTime/Memory efficiency\n1\n\n\n\nDocumentation\n2\n\n\nOral\nSlides (structure, spelling)\n2\n\n\n\nClarity / lively presentation / Rhythm / Show\n3\n\n\nTotal\n\n20"
  }
]